{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "194cfa78-9713-44e0-bbba-ab0a302c48c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parrot import Parrot\n",
    "import json\n",
    "import torch\n",
    "import warnings\n",
    "import read_and_write_docs\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28749375-c4ba-41ef-b3e4-7828286264ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "#Init models (make sure you init ONLY once if you integrate this to your code)\n",
    "parrot = Parrot(model_tag=\"prithivida/parrot_paraphraser_on_T5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c33b6c11-ce78-4961-956c-9d1a7458f39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parrot import Parrot\n",
    "import json\n",
    "import torch\n",
    "import warnings\n",
    "import read_and_write_docs\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Init models (make sure you init ONLY once if you integrate this to your code)\n",
    "parrot = Parrot(model_tag=\"prithivida/parrot_paraphraser_on_T5\")\n",
    "\n",
    "def parrot_paraphrase(phrase, n_iterations, model, diverse=False):\n",
    "    \"\"\"\n",
    "    Generates paraphrases for a given phrase using the Parrot paraphraser.\n",
    "\n",
    "    Args:\n",
    "        phrase (str): The phrase to be paraphrased.\n",
    "        n_iterations (int): Number of iterations to generate paraphrases.\n",
    "        diverse (bool, optional): Flag to enable diverse paraphrasing. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of unique paraphrases.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If `diverse` is not a boolean value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set thresholds based on the diversity flag\n",
    "    if diverse == False:\n",
    "        diverse = False\n",
    "        ad_thresh = 0.99\n",
    "        fl_thresh = 0.9\n",
    "    elif diverse == True:\n",
    "        diverse = True\n",
    "        ad_thresh = 0.7\n",
    "        fl_thresh = 0.7\n",
    "    else:\n",
    "        raise ValueError(\"The 'diverse' argument must be a boolean value.\")\n",
    "\n",
    "    # Initialize the list to store paraphrases\n",
    "    stored_phrases = []\n",
    "\n",
    "    # Generate paraphrases for the given number of iterations\n",
    "    for i in range(1, n_iterations):\n",
    "        paraphrases = parrot.augment(input_phrase=phrase,\n",
    "                                     use_gpu=True,\n",
    "                                     diversity_ranker=\"levenshtein\",\n",
    "                                     do_diverse=diverse,\n",
    "                                     max_return_phrases=100,\n",
    "                                     max_length=1000,\n",
    "                                     adequacy_threshold=ad_thresh,\n",
    "                                     fluency_threshold=fl_thresh)\n",
    "\n",
    "        # If paraphrases are generated, add them to the stored phrases list\n",
    "        if paraphrases is not None:\n",
    "            num_phrases = len(paraphrases)\n",
    "            for j in range(1, num_phrases):\n",
    "                paraphrase = paraphrases[j][0]\n",
    "                stored_phrases.append(paraphrase)\n",
    "        else:\n",
    "            stored_phrases = []\n",
    "\n",
    "    # Remove duplicates by converting the list to a set and back to a list\n",
    "    result = list(set(stored_phrases))\n",
    "\n",
    "    return result\n",
    "\n",
    "def paraphrase_dataframe(df, save_location, n_iterations=10):\n",
    "    \"\"\"\n",
    "    Paraphrases the text in the DataFrame and saves the results to JSONL files by document ID.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the text to be paraphrased.\n",
    "        save_location (str): The location to save the JSONL files.\n",
    "        n_iterations (int, optional): Number of iterations to generate paraphrases. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Get unique document IDs\n",
    "    unique_doc_ids = df['doc_id'].unique()\n",
    "\n",
    "    # Loop through each document ID\n",
    "    for doc_id in unique_doc_ids:\n",
    "        # Filter the DataFrame by the current document ID\n",
    "        doc_df = df[df['doc_id'] == doc_id]\n",
    "        \n",
    "        new_rows = []\n",
    "        \n",
    "        # Loop through each row in the filtered DataFrame\n",
    "        for index, row in doc_df.iterrows():\n",
    "            print(f\"Paraphrasing sentence {index + 1} out of {len(doc_df)} for doc_id {doc_id}\")  # Added print statement\n",
    "            result = parrot_paraphrase(row['text'], n_iterations)\n",
    "            \n",
    "            # Add the paraphrases to the new rows list\n",
    "            for paraphrase in result:\n",
    "                new_row = {\n",
    "                    'index': index,\n",
    "                    'doc_id': row['doc_id'],\n",
    "                    'author_id': row['author_id'],\n",
    "                    'chunk_id': row['chunk_id'],\n",
    "                    'gender': row['gender'],\n",
    "                    'age': row['age'],\n",
    "                    'topic': row['topic'],\n",
    "                    'sign': row['sign'],\n",
    "                    'date': row['date'],\n",
    "                    'text': paraphrase\n",
    "                }\n",
    "                new_rows.append(new_row)\n",
    "        \n",
    "        # Save the paraphrased results to a JSONL file for the current document ID\n",
    "        jsonl_path = f\"{save_location}/doc_{doc_id}.jsonl\"\n",
    "        read_and_write_docs.save_as_jsonl(new_rows, jsonl_path)\n",
    "\n",
    "    print(\"Paraphrasing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5002134e-39f3-4531-b991-e359c1c6f308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paraphrase_dataframe(df, save_location, n_iterations=10):\n",
    "  new_rows = []\n",
    "  for index, row in df.iterrows():\n",
    "    print(f\"Paraphrasing sentence {index + 1} out of {len(df)}\") # Added print statement\n",
    "    result = parrot_paraphrase(row['text'], n_iterations)\n",
    "    for paraphrase in result:\n",
    "      new_row = {\n",
    "          'index': index,\n",
    "          'id': row['id'],\n",
    "          'author_id': row['author_id'],\n",
    "          'chunk_id': row['chunk_id'],\n",
    "          'subchunk_id': row['subchunk_id'],\n",
    "          'gender': row['gender'],\n",
    "          'age': row['age'],\n",
    "          'topic': row['topic'],\n",
    "          'sign': row['sign'],\n",
    "          'date': row['date'],\n",
    "          'paraphrase': paraphrase\n",
    "      }\n",
    "      new_rows.append(new_row)\n",
    "\n",
    "    # Save the DataFrame to a CSV file after each iteration\n",
    "    pd.DataFrame(new_rows).to_csv(save_location, index=False)\n",
    "\n",
    "  new_df = pd.DataFrame(new_rows)\n",
    "  return new_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c2e7569-df5c-41f7-b1f1-bc9657181d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paraphrase_dataframe(df, save_location, n_iterations=10):\n",
    "    \"\"\"\n",
    "    Paraphrases the text in the DataFrame and saves the results to JSONL files by document ID.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the text to be paraphrased.\n",
    "        save_location (str): The location to save the JSONL files.\n",
    "        n_iterations (int, optional): Number of iterations to generate paraphrases. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Get unique document IDs\n",
    "    unique_doc_ids = df['doc_id'].unique()\n",
    "\n",
    "    # Loop through each document ID\n",
    "    for doc_id in unique_doc_ids:\n",
    "        # Filter the DataFrame by the current document ID\n",
    "        doc_df = df[df['doc_id'] == doc_id]\n",
    "        \n",
    "        new_rows = []\n",
    "        \n",
    "        # Loop through each row in the filtered DataFrame\n",
    "        for index, row in doc_df.iterrows():\n",
    "            print(f\"Paraphrasing sentence {index + 1} out of {len(doc_df)} for doc_id {doc_id}\")  # Added print statement\n",
    "            result = parrot_paraphrase(row['text'], n_iterations)\n",
    "            \n",
    "            # Add the paraphrases to the new rows list\n",
    "            for paraphrase in result:\n",
    "                new_row = {\n",
    "                    'index': index,\n",
    "                    'doc_id': row['doc_id'],\n",
    "                    'author_id': row['author_id'],\n",
    "                    'chunk_id': row['chunk_id'],\n",
    "                    'gender': row['gender'],\n",
    "                    'age': row['age'],\n",
    "                    'topic': row['topic'],\n",
    "                    'sign': row['sign'],\n",
    "                    'date': row['date'],\n",
    "                    'text': paraphrase\n",
    "                }\n",
    "                new_rows.append(new_row)\n",
    "        \n",
    "        # Save the paraphrased results to a JSONL file for the current document ID\n",
    "        jsonl_path = f\"{save_location}/doc_{doc_id}.jsonl\"\n",
    "        read_and_write_docs.save_as_jsonl(new_rows, jsonl_path)\n",
    "\n",
    "    print(\"Paraphrasing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6182148-5e08-408c-aaa1-0ac3af5b986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_drive_base = \"/Users/user/Library/CloudStorage/GoogleDrive-benjcross1995@gmail.com/My Drive/datasets/blogger_new_algorithm/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa55bc8e-deba-4668-add5-ed3039edcf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_file_loc = f\"{g_drive_base}rephrased_preprocessed.jsonl\"\n",
    "save_folder = f\"{g_drive_base}parrot_rephrased_diverse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35ca96d2-a39a-43ab-9371-0b5ecf2e8e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_df = read_and_write_docs.read_jsonl_file(base_file_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43f34fa3-6438-422a-ac75-bd8e370a4b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>chunk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18516</td>\n",
       "      <td>4160528</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>09,August,2004</td>\n",
       "      <td>Kelz~ We really got close this summer..</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18516</td>\n",
       "      <td>4160528</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>09,August,2004</td>\n",
       "      <td>its gonna be kewl when u stay with me and i st...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18516</td>\n",
       "      <td>4160528</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>09,August,2004</td>\n",
       "      <td>Newayz..</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18516</td>\n",
       "      <td>4160528</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>09,August,2004</td>\n",
       "      <td>races are the bomb especially that one day whe...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18516</td>\n",
       "      <td>4160528</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>09,August,2004</td>\n",
       "      <td>Itll all turn out for the best.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>676573</td>\n",
       "      <td>2876684</td>\n",
       "      <td>male</td>\n",
       "      <td>24</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Scorpio</td>\n",
       "      <td>02,March,2004</td>\n",
       "      <td>Hello, my ID wasnt even CHECKED when I booked ...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>676573</td>\n",
       "      <td>2876684</td>\n",
       "      <td>male</td>\n",
       "      <td>24</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Scorpio</td>\n",
       "      <td>02,March,2004</td>\n",
       "      <td>I felt like kicking up a fuss but the weird fe...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>676573</td>\n",
       "      <td>2876684</td>\n",
       "      <td>male</td>\n",
       "      <td>24</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Scorpio</td>\n",
       "      <td>02,March,2004</td>\n",
       "      <td>Besides, I like to consider myself a patient p...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>676573</td>\n",
       "      <td>2876684</td>\n",
       "      <td>male</td>\n",
       "      <td>24</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Scorpio</td>\n",
       "      <td>02,March,2004</td>\n",
       "      <td>Anyways, the testing officer wasnt too concern...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>676573</td>\n",
       "      <td>2876684</td>\n",
       "      <td>male</td>\n",
       "      <td>24</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Scorpio</td>\n",
       "      <td>02,March,2004</td>\n",
       "      <td>So we do the test and the result when I come b...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>557 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     doc_id  author_id  gender  age       topic     sign            date  \\\n",
       "0     18516    4160528  female   16     Student      Leo  09,August,2004   \n",
       "1     18516    4160528  female   16     Student      Leo  09,August,2004   \n",
       "2     18516    4160528  female   16     Student      Leo  09,August,2004   \n",
       "3     18516    4160528  female   16     Student      Leo  09,August,2004   \n",
       "4     18516    4160528  female   16     Student      Leo  09,August,2004   \n",
       "..      ...        ...     ...  ...         ...      ...             ...   \n",
       "552  676573    2876684    male   24  Technology  Scorpio   02,March,2004   \n",
       "553  676573    2876684    male   24  Technology  Scorpio   02,March,2004   \n",
       "554  676573    2876684    male   24  Technology  Scorpio   02,March,2004   \n",
       "555  676573    2876684    male   24  Technology  Scorpio   02,March,2004   \n",
       "556  676573    2876684    male   24  Technology  Scorpio   02,March,2004   \n",
       "\n",
       "                                                  text  chunk_id  \n",
       "0              Kelz~ We really got close this summer..         1  \n",
       "1    its gonna be kewl when u stay with me and i st...         2  \n",
       "2                                             Newayz..         3  \n",
       "3    races are the bomb especially that one day whe...         4  \n",
       "4                      Itll all turn out for the best.         5  \n",
       "..                                                 ...       ...  \n",
       "552  Hello, my ID wasnt even CHECKED when I booked ...        15  \n",
       "553  I felt like kicking up a fuss but the weird fe...        16  \n",
       "554  Besides, I like to consider myself a patient p...        17  \n",
       "555  Anyways, the testing officer wasnt too concern...        18  \n",
       "556  So we do the test and the result when I come b...        19  \n",
       "\n",
       "[557 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57c05df0-81fa-4c92-baf2-bda746e09750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paraphrasing sentence 1 out of 57 for doc_id 18516\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mparaphrase_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 26\u001b[0m, in \u001b[0;36mparaphrase_dataframe\u001b[0;34m(df, save_location, n_iterations)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m doc_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParaphrasing sentence \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m out of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(doc_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for doc_id \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Added print statement\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mparrot_paraphrase\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iterations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# Add the paraphrases to the new rows list\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m paraphrase \u001b[38;5;129;01min\u001b[39;00m result:\n",
      "Cell \u001b[0;32mIn[3], line 34\u001b[0m, in \u001b[0;36mparrot_paraphrase\u001b[0;34m(phrase, n_iterations, diverse)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Generate paraphrases for the given number of iterations\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_iterations):\n\u001b[0;32m---> 34\u001b[0m     paraphrases \u001b[38;5;241m=\u001b[39m \u001b[43mparrot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_phrase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mphrase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mdiversity_ranker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlevenshtein\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mdo_diverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiverse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmax_return_phrases\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43madequacy_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mad_thresh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mfluency_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfl_thresh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# If paraphrases are generated, add them to the stored phrases list\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m paraphrases \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/my_env/lib/python3.10/site-packages/parrot/parrot.py:84\u001b[0m, in \u001b[0;36mParrot.augment\u001b[0;34m(self, input_phrase, use_gpu, diversity_ranker, do_diverse, max_return_phrases, max_length, adequacy_threshold, fluency_threshold)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m   device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel     \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m     88\u001b[0m save_phrase \u001b[38;5;241m=\u001b[39m input_phrase\n",
      "File \u001b[0;32m~/my_env/lib/python3.10/site-packages/transformers/modeling_utils.py:2556\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2551\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   2552\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2553\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2554\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2555\u001b[0m         )\n\u001b[0;32m-> 2556\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1152\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my_env/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/my_env/lib/python3.10/site-packages/torch/nn/modules/module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/my_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1150\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/my_env/lib/python3.10/site-packages/torch/cuda/__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    291\u001b[0m     )\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    296\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "paraphrase_dataframe(initial_df, save_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paraphrase_llm",
   "language": "python",
   "name": "paraphrase_llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
