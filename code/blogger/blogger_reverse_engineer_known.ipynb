{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6481da6b-b91a-422d-b106-eb1eb403f42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../read_and_write_docs.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "99f8e952-7cf0-42da-9dc1-8069481fa7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: preprocessing.py [-h] --file_path FILE_PATH --output_file_path\n",
      "                        OUTPUT_FILE_PATH [--num_words NUM_WORDS]\n",
      "preprocessing.py: error: the following arguments are required: --file_path, --output_file_path\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "%run \"../preprocessing.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e65462a0-7204-4dfc-bfb0-fe92f7af934d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: combine_sentences.py [-h] --file_path FILE_PATH --output_file_path\n",
      "                            OUTPUT_FILE_PATH\n",
      "                            [--length_threshold LENGTH_THRESHOLD]\n",
      "                            [--threshold_type {char,word}]\n",
      "combine_sentences.py: error: the following arguments are required: --file_path, --output_file_path\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "%run \"../combine_sentences.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59f39da-0bae-482c-896b-9d57ea200432",
   "metadata": {},
   "source": [
    "## Read Files\n",
    "\n",
    "First we read the new temporary metadata file and the raw file. The aim being to filter out the doc_id, author_id combo from the raw file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "91061c9a-3fa5-4dc4-8350-b2d132a8d513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d6634fc2-42e0-4faa-8a3b-283fd93ce81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "blogger_loc = \"../../../../datasets/blogger/raw_error_fix/\"\n",
    "\n",
    "raw_loc = f\"{blogger_loc}raw.jsonl\"\n",
    "temp_metadata_loc = f\"{blogger_loc}metadata_temp.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a37640cb-2059-4de1-aaf7-aa286a7921ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_meta = read_jsonl_file(temp_metadata_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "15e1e150-439f-4290-a1c9-e3f69043396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = read_jsonl_file(raw_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b55530-a01c-477a-89fc-8440542b28ec",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "\n",
    "Initially filter for doc and author combo and then for word count > 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "fe376745-5ef8-4952-ace1-35e15edc6c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract unique combinations of doc_id and author_id from metadata\n",
    "unique_combinations = temp_meta[['doc_id_y', 'author_id_y']].copy()\n",
    "unique_combinations.rename(columns={'doc_id_y': 'doc_id', 'author_id_y': 'author_id'}, inplace=True)\n",
    "\n",
    "# Rename columns in unique_combinations to match those in raw\n",
    "raw.rename(columns={'id': 'doc_id'}, inplace=True)\n",
    "\n",
    "# Step 2: Merge unique_combinations with raw DataFrame to find the rows to exclude\n",
    "merged_df = raw.merge(unique_combinations, on=['doc_id', 'author_id'], how='left', indicator=True)\n",
    "\n",
    "# Step 3: Filter out rows from raw where the combination of id and author_id exists in metadata\n",
    "filtered_raw = merged_df[merged_df['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\n",
    "filtered_raw = filtered_raw[filtered_raw['word_count'] >= 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4309bc8c-c265-4edf-8ff7-9e6ffe614dd3",
   "metadata": {},
   "source": [
    "## Create Metadata Table - Same Author\n",
    "\n",
    "First we want to create the metadata for the same authors by creating a temp metadata file for those with more than one doc in the data before sampling and returning a single same author doc each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a6815911-0bcf-49d4-8190-67d80455632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract unique author_id_x values from temp_meta\n",
    "author_id_y_list = temp_meta['author_id_y'].unique()\n",
    "\n",
    "# Step 2: Filter filtered_raw based on author_id_x\n",
    "matching_raw = filtered_raw[filtered_raw['author_id'].isin(author_id_y_list)]\n",
    "\n",
    "# Step 3: Get the unique author_id values from matching_raw\n",
    "matching_author_ids = matching_raw['author_id'].unique()\n",
    "\n",
    "n_same = round(len(temp_meta) / 2)\n",
    "\n",
    "# Step 4: Filter temp_meta to include only rows with author_id_x in the list of matching_author_ids\n",
    "same_author_temp_meta = temp_meta[temp_meta['author_id_y'].isin(matching_author_ids)].head(n = n_same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3a8f5410-76af-485c-929f-5f48f8d7454a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Initialize an empty list to store the updated rows\n",
    "updated_rows = []\n",
    "\n",
    "# Loop through each row in temp_meta\n",
    "for _, row in same_author_temp_meta.iterrows():\n",
    "    sample_id = row['sample_id']\n",
    "    author_id_y = row['author_id_y']\n",
    "\n",
    "    # Filter the raw DataFrame based on author_id_y\n",
    "    filtered_df = filtered_raw[filtered_raw['author_id'] == author_id_y]\n",
    "    \n",
    "    # Randomly sample a row from the filtered DataFrame\n",
    "    sampled_row = filtered_df.sample(n=1)\n",
    "        \n",
    "    # Extract the relevant information\n",
    "    doc_id_x = sampled_row['doc_id'].values[0]\n",
    "    author_id_x = sampled_row['author_id'].values[0]\n",
    "    topic_x = sampled_row['topic'].values[0]\n",
    "        \n",
    "    # Update the temp_meta DataFrame with new values\n",
    "    updated_row = row.copy()\n",
    "    updated_row['doc_id_x'] = doc_id_x\n",
    "    updated_row['author_id_x'] = author_id_x\n",
    "    updated_row['topic_x'] = topic_x\n",
    "        \n",
    "    # Append the updated row to the list\n",
    "    updated_rows.append(updated_row)\n",
    "\n",
    "\n",
    "# Convert the list of updated rows to a DataFrame\n",
    "updated_same_author_temp_meta = pd.DataFrame(updated_rows)\n",
    "\n",
    "updated_same_author_temp_meta = updated_same_author_temp_meta[['sample_id', 'doc_id_x', 'doc_id_y', 'author_id_x', 'author_id_y', 'topic_x', 'topic_y']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e974bd2-26d1-421b-9b83-4dac074dc36b",
   "metadata": {},
   "source": [
    "## Create Metadata Table - Diff Author\n",
    "\n",
    "Now we create the different author but same topic table by removing all authors from the raw data which are already in the metadata and then sampling a row making sure the topic is the same each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "fe04cf77-996d-43a3-88be-4d538073cd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_author_temp_meta = temp_meta[~temp_meta['sample_id'].isin(same_author_temp_meta['sample_id'])]\n",
    "temp_filtered_raw = filtered_raw[~filtered_raw['author_id'].isin(temp_meta['author_id_y'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9049e4f7-85d0-4951-a943-85dc5c997a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Initialize an empty list to store the updated rows\n",
    "updated_rows = []\n",
    "\n",
    "# Create a copy of temp_filtered_raw to avoid modifying the original DataFrame\n",
    "temp_filtered_raw_copy = temp_filtered_raw.copy()\n",
    "\n",
    "# Loop through each row in diff_author_temp_meta\n",
    "for _, row in diff_author_temp_meta.iterrows():\n",
    "    sample_id = row['sample_id']\n",
    "    topic_y = row['topic_y']\n",
    "    \n",
    "    # Filter temp_filtered_raw_copy based on topic\n",
    "    filtered_df = temp_filtered_raw_copy[temp_filtered_raw_copy['topic'] == topic_y]\n",
    "    \n",
    "    # Randomly sample one row from the filtered DataFrame\n",
    "    sampled_row = filtered_df.sample(n=1)\n",
    "        \n",
    "    # Extract the relevant information\n",
    "    doc_id_x = sampled_row['doc_id'].values[0]\n",
    "    author_id_x = sampled_row['author_id'].values[0]\n",
    "    topic_x = sampled_row['topic'].values[0]\n",
    "        \n",
    "    # Update the original row with new values\n",
    "    updated_row = row.copy()\n",
    "    updated_row['doc_id_x'] = doc_id_x\n",
    "    updated_row['author_id_x'] = author_id_x\n",
    "    updated_row['topic_x'] = topic_x\n",
    "        \n",
    "    # Append the updated row to the list\n",
    "    updated_rows.append(updated_row)\n",
    "        \n",
    "    # Remove the sampled row from the temp_filtered_raw_copy to avoid reselection\n",
    "    temp_filtered_raw_copy = temp_filtered_raw_copy.drop(sampled_row.index)\n",
    "\n",
    "# Convert the list of updated rows to a DataFrame\n",
    "updated_diff_author_temp_meta = pd.DataFrame(updated_rows)\n",
    "\n",
    "updated_diff_author_temp_meta = updated_diff_author_temp_meta[['sample_id', 'doc_id_x', 'doc_id_y', 'author_id_x', 'author_id_y', 'topic_x', 'topic_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9068959e-86d6-4dc0-be8e-b84ba2acd4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>doc_id_x</th>\n",
       "      <th>doc_id_y</th>\n",
       "      <th>author_id_x</th>\n",
       "      <th>author_id_y</th>\n",
       "      <th>topic_x</th>\n",
       "      <th>topic_y</th>\n",
       "      <th>same_author</th>\n",
       "      <th>same_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>618134</td>\n",
       "      <td>16188</td>\n",
       "      <td>1516660</td>\n",
       "      <td>3952922</td>\n",
       "      <td>Student</td>\n",
       "      <td>Student</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>17857</td>\n",
       "      <td>17850</td>\n",
       "      <td>3321827</td>\n",
       "      <td>3321827</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Technology</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>18512</td>\n",
       "      <td>18516</td>\n",
       "      <td>4160528</td>\n",
       "      <td>4160528</td>\n",
       "      <td>Student</td>\n",
       "      <td>Student</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>184544</td>\n",
       "      <td>26252</td>\n",
       "      <td>2258198</td>\n",
       "      <td>4169442</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>37301</td>\n",
       "      <td>37303</td>\n",
       "      <td>3084647</td>\n",
       "      <td>3084647</td>\n",
       "      <td>Student</td>\n",
       "      <td>Student</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>202101</td>\n",
       "      <td>623524</td>\n",
       "      <td>3405693</td>\n",
       "      <td>2927895</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Technology</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>161192</td>\n",
       "      <td>669029</td>\n",
       "      <td>1278138</td>\n",
       "      <td>3093335</td>\n",
       "      <td>Education</td>\n",
       "      <td>Education</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>45629</td>\n",
       "      <td>671397</td>\n",
       "      <td>2002478</td>\n",
       "      <td>3419072</td>\n",
       "      <td>Science</td>\n",
       "      <td>Science</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>590738</td>\n",
       "      <td>676573</td>\n",
       "      <td>3678120</td>\n",
       "      <td>2876684</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Technology</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>186756</td>\n",
       "      <td>678838</td>\n",
       "      <td>2222697</td>\n",
       "      <td>1241231</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Technology</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sample_id  doc_id_x  doc_id_y  author_id_x  author_id_y      topic_x  \\\n",
       "0           1    618134     16188      1516660      3952922      Student   \n",
       "1           2     17857     17850      3321827      3321827   Technology   \n",
       "2           3     18512     18516      4160528      4160528      Student   \n",
       "3           4    184544     26252      2258198      4169442  Engineering   \n",
       "4           5     37301     37303      3084647      3084647      Student   \n",
       "..        ...       ...       ...          ...          ...          ...   \n",
       "95         96    202101    623524      3405693      2927895   Technology   \n",
       "96         97    161192    669029      1278138      3093335    Education   \n",
       "97         98     45629    671397      2002478      3419072      Science   \n",
       "98         99    590738    676573      3678120      2876684   Technology   \n",
       "99        100    186756    678838      2222697      1241231   Technology   \n",
       "\n",
       "        topic_y  same_author  same_topic  \n",
       "0       Student        False        True  \n",
       "1    Technology         True        True  \n",
       "2       Student         True        True  \n",
       "3   Engineering        False        True  \n",
       "4       Student         True        True  \n",
       "..          ...          ...         ...  \n",
       "95   Technology        False        True  \n",
       "96    Education        False        True  \n",
       "97      Science        False        True  \n",
       "98   Technology        False        True  \n",
       "99   Technology        False        True  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Concatenate the DataFrames\n",
    "final_metadata = pd.concat([updated_diff_author_temp_meta, updated_same_author_temp_meta], ignore_index=True)\n",
    "\n",
    "# Step 2: Add new columns for same_author and same_topic\n",
    "final_metadata['same_author'] = final_metadata['author_id_x'] == final_metadata['author_id_y']\n",
    "final_metadata['same_topic'] = final_metadata['topic_x'] == final_metadata['topic_y']\n",
    "\n",
    "# Step 3: Sort by sample_id\n",
    "final_metadata = final_metadata.sort_values(by='sample_id').reset_index(drop=True)\n",
    "\n",
    "final_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4de4a120-72af-4ee6-9a02-9608d24aef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_jsonl(final_metadata, f\"{blogger_loc}metadata.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ea1a01-189a-4bf3-a592-0ecce0c60701",
   "metadata": {},
   "source": [
    "## Create the Known Raw Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "08030b77-66e0-4ea6-a2d2-73ef88024c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract unique combinations of doc_id and author_id from metadata\n",
    "unique_combinations_known = final_metadata[['doc_id_x', 'author_id_x']].copy()\n",
    "unique_combinations_known.rename(columns={'doc_id_x': 'doc_id', 'author_id_x': 'author_id'}, inplace=True)\n",
    "\n",
    "# Rename columns in unique_combinations to match those in raw\n",
    "raw.rename(columns={'id': 'doc_id'}, inplace=True)\n",
    "\n",
    "# Step 2: Merge unique_combinations with raw DataFrame to find the rows to exclude\n",
    "known_raw = raw.merge(unique_combinations_known, on=['doc_id', 'author_id'], how='left', indicator=True)\n",
    "\n",
    "# # Step 3: Filter out rows from raw where the combination of id and author_id exists in metadata\n",
    "known_raw = known_raw[known_raw['_merge'] == 'both'].drop(columns=['_merge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7a3ca8b7-c22c-4106-b85c-d6bf245b0046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17857</th>\n",
       "      <td>17857</td>\n",
       "      <td>3321827</td>\n",
       "      <td>male</td>\n",
       "      <td>38</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>Is it just me, or are liberals unab...</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18512</th>\n",
       "      <td>18512</td>\n",
       "      <td>4160528</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>09,August,2004</td>\n",
       "      <td>MaNy NiTeS i'Ve CrIeD fRoM ...</td>\n",
       "      <td>11502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29123</th>\n",
       "      <td>29123</td>\n",
       "      <td>3011326</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>Maritime</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>17,March,2004</td>\n",
       "      <td>Readings   I'm a Democrat. I'm a...</td>\n",
       "      <td>1237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36608</th>\n",
       "      <td>36608</td>\n",
       "      <td>3347922</td>\n",
       "      <td>female</td>\n",
       "      <td>23</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Virgo</td>\n",
       "      <td>01,August,2004</td>\n",
       "      <td>First thing first how i'm fe...</td>\n",
       "      <td>2806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37301</th>\n",
       "      <td>37301</td>\n",
       "      <td>3084647</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>10,July,2004</td>\n",
       "      <td>The next morning arrived, bringing with it ...</td>\n",
       "      <td>1367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618134</th>\n",
       "      <td>618134</td>\n",
       "      <td>1516660</td>\n",
       "      <td>male</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>30,May,2004</td>\n",
       "      <td>hrm...I'm bored. Yup,you got that r...</td>\n",
       "      <td>1038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653547</th>\n",
       "      <td>653547</td>\n",
       "      <td>3444305</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>23,July,2004</td>\n",
       "      <td>Well I have been really busy lately...</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656699</th>\n",
       "      <td>656699</td>\n",
       "      <td>3347383</td>\n",
       "      <td>male</td>\n",
       "      <td>39</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Aries</td>\n",
       "      <td>21,May,2004</td>\n",
       "      <td>Part one of my 'Millionaire' experience...</td>\n",
       "      <td>1087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659396</th>\n",
       "      <td>659396</td>\n",
       "      <td>2587254</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Libra</td>\n",
       "      <td>14,February,2004</td>\n",
       "      <td>2/14/04   Happy Valentine's Day!...</td>\n",
       "      <td>1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673161</th>\n",
       "      <td>673161</td>\n",
       "      <td>2162182</td>\n",
       "      <td>male</td>\n",
       "      <td>24</td>\n",
       "      <td>Communications-Media</td>\n",
       "      <td>Libra</td>\n",
       "      <td>11,January,2004</td>\n",
       "      <td>urlLink Email   urlLink     Before I g...</td>\n",
       "      <td>2494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        doc_id  author_id  gender  age                 topic         sign  \\\n",
       "17857    17857    3321827    male   38            Technology  Sagittarius   \n",
       "18512    18512    4160528  female   16               Student          Leo   \n",
       "29123    29123    3011326    male   23              Maritime       Taurus   \n",
       "36608    36608    3347922  female   23                indUnk        Virgo   \n",
       "37301    37301    3084647    male   15               Student       Pisces   \n",
       "...        ...        ...     ...  ...                   ...          ...   \n",
       "618134  618134    1516660    male   17               Student       Cancer   \n",
       "653547  653547    3444305    male   15               Student     Aquarius   \n",
       "656699  656699    3347383    male   39              Internet        Aries   \n",
       "659396  659396    2587254    male   15               Student        Libra   \n",
       "673161  673161    2162182    male   24  Communications-Media        Libra   \n",
       "\n",
       "                    date                                               text  \\\n",
       "17857        13,May,2004             Is it just me, or are liberals unab...   \n",
       "18512     09,August,2004                     MaNy NiTeS i'Ve CrIeD fRoM ...   \n",
       "29123      17,March,2004                Readings   I'm a Democrat. I'm a...   \n",
       "36608     01,August,2004                    First thing first how i'm fe...   \n",
       "37301       10,July,2004     The next morning arrived, bringing with it ...   \n",
       "...                  ...                                                ...   \n",
       "618134       30,May,2004             hrm...I'm bored. Yup,you got that r...   \n",
       "653547      23,July,2004             Well I have been really busy lately...   \n",
       "656699       21,May,2004         Part one of my 'Millionaire' experience...   \n",
       "659396  14,February,2004                2/14/04   Happy Valentine's Day!...   \n",
       "673161   11,January,2004          urlLink Email   urlLink     Before I g...   \n",
       "\n",
       "        word_count  \n",
       "17857         2012  \n",
       "18512        11502  \n",
       "29123         1237  \n",
       "36608         2806  \n",
       "37301         1367  \n",
       "...            ...  \n",
       "618134        1038  \n",
       "653547        1201  \n",
       "656699        1087  \n",
       "659396        1034  \n",
       "673161        2494  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "fac43e71-ec2e-4529-8d9a-8a6af8c7fbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_jsonl(known_raw, f\"{blogger_loc}known_raw.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c982150-6029-411a-a276-f81bc8486d15",
   "metadata": {},
   "source": [
    "## Preprocess the Known Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8241526e-3e13-4226-a35a-af7aead71a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_raw = known_raw.drop('word_count', axis = 1)\n",
    "known_raw.rename(columns={'doc_id': 'id'}, inplace=True)\n",
    "known_preprocessed = apply_sentence_split(known_raw)\n",
    "known_preprocessed = split_rows_by_word_count(known_preprocessed, num_words=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "659fc827-d536-484c-bee6-55f5a133f07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_jsonl(known_preprocessed, f\"{blogger_loc}known_preprocessed.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162dbe67-d6e2-4985-a8b2-13939db078f3",
   "metadata": {},
   "source": [
    "## Concatenate to Chunk Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2bf14399-14f3-4ee5-8a92-4459decc53e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_concat = concatenate_sentences(known_preprocessed, length_threshold=500, threshold_type='word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ed5a9fe0-4337-4232-a397-0b69c1e9965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_jsonl(known_concat, f\"{blogger_loc}known_combined.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61647e0c-4efe-4808-808b-7a3322e219c1",
   "metadata": {},
   "source": [
    "## Final Known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d23d6a11-3618-4cd8-8dc9-279dc257f585",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_final = known_concat.drop_duplicates(subset='id', keep='first')\n",
    "\n",
    "# Keep the specified columns\n",
    "known_final = known_final[['id', 'author_id', 'gender', 'word_count', 'age', 'topic', 'sign', 'date', 'text']]\n",
    "\n",
    "# Rename 'id' to 'doc_id'\n",
    "known_final.rename(columns={'id': 'doc_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b10c734f-b0ff-423f-bfb7-3b8d13deebd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>word_count</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17857</td>\n",
       "      <td>3321827</td>\n",
       "      <td>male</td>\n",
       "      <td>517</td>\n",
       "      <td>38</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Sagittarius</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>Is it just me, or are liberals unable to make ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>18512</td>\n",
       "      <td>4160528</td>\n",
       "      <td>female</td>\n",
       "      <td>556</td>\n",
       "      <td>16</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>09,August,2004</td>\n",
       "      <td>MaNy NiTeS iVe CrIeD fRoM tHe ThInGs U dO, fEl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>29123</td>\n",
       "      <td>3011326</td>\n",
       "      <td>male</td>\n",
       "      <td>503</td>\n",
       "      <td>23</td>\n",
       "      <td>Maritime</td>\n",
       "      <td>Taurus</td>\n",
       "      <td>17,March,2004</td>\n",
       "      <td>Readings   Im a Democrat. Im a liberal. And Iv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>36608</td>\n",
       "      <td>3347922</td>\n",
       "      <td>female</td>\n",
       "      <td>521</td>\n",
       "      <td>23</td>\n",
       "      <td>indUnk</td>\n",
       "      <td>Virgo</td>\n",
       "      <td>01,August,2004</td>\n",
       "      <td>First thing first how im feeling... shorty som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>37301</td>\n",
       "      <td>3084647</td>\n",
       "      <td>male</td>\n",
       "      <td>510</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Pisces</td>\n",
       "      <td>10,July,2004</td>\n",
       "      <td>The next morning arrived, bringing with it col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11378</th>\n",
       "      <td>618134</td>\n",
       "      <td>1516660</td>\n",
       "      <td>male</td>\n",
       "      <td>524</td>\n",
       "      <td>17</td>\n",
       "      <td>Student</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>30,May,2004</td>\n",
       "      <td>hrm...Im bored. Yup,you got that right, Im bor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11432</th>\n",
       "      <td>653547</td>\n",
       "      <td>3444305</td>\n",
       "      <td>male</td>\n",
       "      <td>515</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>23,July,2004</td>\n",
       "      <td>Well I have been really busy lately so sorry I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11509</th>\n",
       "      <td>656699</td>\n",
       "      <td>3347383</td>\n",
       "      <td>male</td>\n",
       "      <td>500</td>\n",
       "      <td>39</td>\n",
       "      <td>Internet</td>\n",
       "      <td>Aries</td>\n",
       "      <td>21,May,2004</td>\n",
       "      <td>Part one of my Millionaire experience aired la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11592</th>\n",
       "      <td>659396</td>\n",
       "      <td>2587254</td>\n",
       "      <td>male</td>\n",
       "      <td>510</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Libra</td>\n",
       "      <td>14,February,2004</td>\n",
       "      <td>2/14/04   Happy Valentines Day!...Pretty fun d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11667</th>\n",
       "      <td>673161</td>\n",
       "      <td>2162182</td>\n",
       "      <td>male</td>\n",
       "      <td>505</td>\n",
       "      <td>24</td>\n",
       "      <td>Communications-Media</td>\n",
       "      <td>Libra</td>\n",
       "      <td>11,January,2004</td>\n",
       "      <td>urlLink Email   urlLink     Before I get into ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       doc_id  author_id  gender  word_count  age                 topic  \\\n",
       "0       17857    3321827    male         517   38            Technology   \n",
       "132     18512    4160528  female         556   16               Student   \n",
       "881     29123    3011326    male         503   23              Maritime   \n",
       "933     36608    3347922  female         521   23                indUnk   \n",
       "1122    37301    3084647    male         510   15               Student   \n",
       "...       ...        ...     ...         ...  ...                   ...   \n",
       "11378  618134    1516660    male         524   17               Student   \n",
       "11432  653547    3444305    male         515   15               Student   \n",
       "11509  656699    3347383    male         500   39              Internet   \n",
       "11592  659396    2587254    male         510   15               Student   \n",
       "11667  673161    2162182    male         505   24  Communications-Media   \n",
       "\n",
       "              sign              date  \\\n",
       "0      Sagittarius       13,May,2004   \n",
       "132            Leo    09,August,2004   \n",
       "881         Taurus     17,March,2004   \n",
       "933          Virgo    01,August,2004   \n",
       "1122        Pisces      10,July,2004   \n",
       "...            ...               ...   \n",
       "11378       Cancer       30,May,2004   \n",
       "11432     Aquarius      23,July,2004   \n",
       "11509        Aries       21,May,2004   \n",
       "11592        Libra  14,February,2004   \n",
       "11667        Libra   11,January,2004   \n",
       "\n",
       "                                                    text  \n",
       "0      Is it just me, or are liberals unable to make ...  \n",
       "132    MaNy NiTeS iVe CrIeD fRoM tHe ThInGs U dO, fEl...  \n",
       "881    Readings   Im a Democrat. Im a liberal. And Iv...  \n",
       "933    First thing first how im feeling... shorty som...  \n",
       "1122   The next morning arrived, bringing with it col...  \n",
       "...                                                  ...  \n",
       "11378  hrm...Im bored. Yup,you got that right, Im bor...  \n",
       "11432  Well I have been really busy lately so sorry I...  \n",
       "11509  Part one of my Millionaire experience aired la...  \n",
       "11592  2/14/04   Happy Valentines Day!...Pretty fun d...  \n",
       "11667  urlLink Email   urlLink     Before I get into ...  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e8f627ca-6fc2-4521-ad54-3a98e2583558",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_jsonl(known_final, f\"{blogger_loc}known_final.jsonl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paraphrase_llm",
   "language": "python",
   "name": "paraphrase_llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
