{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "22a863af-9108-4221-8424-5ba37c44a2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import read_and_write_docs\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from llama_cpp import Llama, LlamaGrammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "eaa64952-808e-472d-9380-16e85601b60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../../../local models/Phi-3-mini-4k-instruct-q4.gguf\"\n",
    "# model_path = \"../../../local models/Phi-3-mini-4k-instruct-fp16.gguf\"\n",
    "grammar_path = \"../../../langchain_grammars/list.gbnf\"\n",
    "data_loc = \"../../../datasets/blogger_new_algorithm/rephrased_preprocessed.jsonl\"\n",
    "save_loc = \"../../../datasets/blogger_new_algorithm/phi_rephrased\"\n",
    "error_loc = \"../../../datasets/blogger_new_algorithm/phi_errors/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "bcb054b1-7270-4089-8158-a0fc76059cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dataframe_by_folder(df_path, folder_path):\n",
    "    \"\"\"Filters a DataFrame by removing rows with doc_ids that already exist as files in a specified folder.\n",
    "    \n",
    "    Args:\n",
    "        df_path (str): Path to the JSONL file containing the DataFrame.\n",
    "        folder_path (str): Path to the folder containing files named in the format \"doc_{doc_id}.jsonl\".\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered DataFrame with rows removed where doc_ids already exist in the folder.\n",
    "    \"\"\"\n",
    "    # Read the dataframe from the provided location\n",
    "    df = read_and_write_docs.read_jsonl_file(df_path)\n",
    "\n",
    "    # List all files in the provided folder\n",
    "    files_in_folder = os.listdir(folder_path)\n",
    "\n",
    "    # Extract doc_ids from file names (assuming files are named as \"doc_{doc_id}\")\n",
    "    existing_doc_ids = set()\n",
    "    for filename in files_in_folder:\n",
    "        if filename.startswith(\"doc_\") and filename.endswith(\".jsonl\"):\n",
    "            try:\n",
    "                doc_id = int(filename[4:-6])  # 'doc_' is 4 characters and '.jsonl' is 6 characters\n",
    "                existing_doc_ids.add(doc_id)\n",
    "            except ValueError:\n",
    "                continue  # Skip files that don't follow the naming pattern\n",
    "\n",
    "    # Filter the dataframe to keep only rows where doc_id is not in existing_doc_ids\n",
    "    filtered_df = df[~df['doc_id'].isin(existing_doc_ids)]\n",
    "    \n",
    "    # Calculate the number of unique doc_ids removed\n",
    "    unique_doc_ids_removed = len(set(df['doc_id']) & existing_doc_ids)\n",
    "    \n",
    "    # Print the number of unique doc_ids filtered out if more than 1\n",
    "    if unique_doc_ids_removed > 1:\n",
    "        print(f'{unique_doc_ids_removed} unique doc_ids removed as already exist')\n",
    "\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "e1c3613e-5d42-4ed9-b436-7c668718edca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_starting_bracket(llm_output):\n",
    "    \"\"\"\n",
    "    Ensures the string starts with '[' if it doesn't already.\n",
    "    \"\"\"\n",
    "    if not llm_output.startswith('['):\n",
    "        llm_output = '[' + llm_output\n",
    "    return llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "da8c5f52-f86c-48f6-a03e-e704b21b7036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_trailing_bracket(llm_output):\n",
    "    \"\"\"\n",
    "    Ensures the string ends with ']' and handles incomplete entries by removing them.\n",
    "    \"\"\"\n",
    "    llm_output = llm_output.strip()\n",
    "    if not llm_output.endswith(']'):\n",
    "        # Find the last comma\n",
    "        last_comma_index = llm_output.rfind(',')\n",
    "        if last_comma_index != -1:\n",
    "            # Get the substring after the last comma\n",
    "            after_last_comma = llm_output[last_comma_index + 1:].strip()\n",
    "            # Check if the length of the substring after the last comma is less than 3 characters\n",
    "            if len(after_last_comma) < 3:\n",
    "                # Remove the substring after the last comma\n",
    "                llm_output = llm_output[:last_comma_index].strip()\n",
    "            # Remove any incomplete entries by checking for open quotes\n",
    "            while after_last_comma.count('\"') % 2 != 0:\n",
    "                llm_output = llm_output[:last_comma_index].strip()\n",
    "                last_comma_index = llm_output.rfind(',')\n",
    "                if last_comma_index == -1:\n",
    "                    break\n",
    "                after_last_comma = llm_output[last_comma_index + 1:].strip()\n",
    "        # Append the closing bracket\n",
    "        llm_output += ']'\n",
    "\n",
    "    return llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "fe0b50b1-76cb-4ec4-b4e5-c938b5ea7aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_output(llm_output, error_loc):\n",
    "    \"\"\"\n",
    "    Formats the LLM output to ensure it is a valid JSON list.\n",
    "    Tries to parse it as a JSON list and returns the parsed list if successful.\n",
    "    If parsing fails, attempts to replace single quotes with double quotes and try again.\n",
    "    If parsing still fails, prints the result and returns an empty list.\n",
    "    \"\"\"\n",
    "\n",
    "    result = check_starting_bracket(llm_output)\n",
    "    result = check_trailing_bracket(result)\n",
    "    try:\n",
    "        # Attempt to parse the JSON string\n",
    "        parsed_result = json.loads(result)\n",
    "        return parsed_result\n",
    "    except json.JSONDecodeError as e:\n",
    "        # Print detailed error information\n",
    "        print(\"JSONDecodeError:\")\n",
    "        read_and_write_docs.save_error_as_txt(result, error_loc)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "c381a080-a790-488a-be13-ec4be10958cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_local_llm(llm, messages, sentence, grammar=None, temperature=0.7):\n",
    "\n",
    "    # Create a copy of the messages list\n",
    "    messages_copy = copy.deepcopy(messages)\n",
    "    \n",
    "    # Append the new message to the copied list\n",
    "    new_message = {\"role\": \"user\", \"content\": sentence}\n",
    "    messages_copy.append(new_message)\n",
    "\n",
    "    response = llm.create_chat_completion(messages=messages_copy, grammar=grammar, temperature=temperature)\n",
    "    \n",
    "    # Extract the answer and finish reason\n",
    "    answer = response['choices'][0]['message']['content']\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "72803cfc-1f2a-4302-b226-97aad95f703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paraphrase_llm(read_loc, write_loc, error_loc, llm, messages, grammar_path=None, temperature=0.7, num_iterations=10):\n",
    "    \"\"\"\n",
    "    Paraphrases documents using an LLM and saves the results.\n",
    "\n",
    "    Args:\n",
    "        read_loc (str): File path to the input data.\n",
    "        write_loc (str): Folder path to save the output data.\n",
    "        error_loc (str): Folder path to save error logs.\n",
    "        llm (object): LLM object used for paraphrasing.\n",
    "        messages (list): Input messages list for the LLM.\n",
    "        temperature (float, optional): Temperature setting for the LLM. Defaults to 0.7.\n",
    "        num_iterations (int, optional): Number of iterations to generate paraphrases for each sentence. Defaults to 10.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    filtered_df = filter_dataframe_by_folder(read_loc, write_loc)\n",
    "    \n",
    "    if len(filtered_df) > 0:\n",
    "\n",
    "        if grammar_path:\n",
    "            print(\"Grammar Path Found\")\n",
    "            grammar=LlamaGrammar.from_file(grammar_path, verbose=False)\n",
    "        \n",
    "        # Get the remaining docs as a list to loop through\n",
    "        remaining_docs = filtered_df['doc_id'].unique()\n",
    "        total_docs = len(remaining_docs)\n",
    "        print(f\"{total_docs} Documents Left to Paraphrase\")\n",
    "\n",
    "        for doc_id in remaining_docs:\n",
    "            # Initialize an empty list to store dictionaries\n",
    "            result_data = []\n",
    "\n",
    "            # Filter rows for the current document\n",
    "            doc_rows = filtered_df[filtered_df['doc_id'] == doc_id]\n",
    "            num_chunks = len(doc_rows)\n",
    "\n",
    "            for chunk_id, sentence in enumerate(doc_rows['text']):\n",
    "                print(f\"Processing Document ID: {doc_id}, Chunk ID: {chunk_id} Out Of {num_chunks}\")\n",
    "\n",
    "                for i in range(num_iterations):\n",
    "                    print(f\"Iteration: {i + 1}\")\n",
    "                    if grammar_path:\n",
    "                        result = call_local_llm(llm, messages, sentence, grammar, temperature)\n",
    "                    else:\n",
    "                        result = call_local_llm(llm, messages, sentence, temperature=temperature)\n",
    "                        \n",
    "                    formatted_result = format_output(result, error_loc)\n",
    "\n",
    "                    # Append each result as a new dictionary to result_data\n",
    "                    for item in formatted_result:\n",
    "                        result_data.append({'doc_id': doc_id, 'chunk_id': chunk_id, 'result': item})\n",
    "\n",
    "            # Create DataFrame from list of dictionaries for the current doc_id\n",
    "            result_df = pd.DataFrame(result_data)\n",
    "\n",
    "            # Save results for current doc_id to JSON Lines file\n",
    "            read_and_write_docs.save_as_jsonl(result_df, f\"{write_loc}/doc_{doc_id}.jsonl\")\n",
    "\n",
    "        print(\"All documents processed.\")\n",
    "\n",
    "    else:\n",
    "        print(\"No documents to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "390278b5-9a4a-448b-86bb-bd43a942aeee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are a paraphrasing assistant, given a sentence generate as many paraphrased \"\n",
    "    \"sentences as possible while preserving the original semantic meaning and style. \"\n",
    "    \"Return the rephrased sentences as a Python list. Aim for AT LEAST TWENTY sentences. \"\n",
    "    \"DO NOT INCLUDE ANY NOTE OR ADDITIONAL TEXT IN THE OUTPUT. \"\n",
    "    \"Make sure to WRAP ALL SENTENCES IN DOUBLE QUOTES AND USE ESCAPED SINGLE QUOTES INSIDE THEM. \"\n",
    "    \"If there are NAMED ENTITIES in the sentence DO NOT change the name.\"\n",
    ")\n",
    "\n",
    "# Convert the text to a single line string\n",
    "system_prompt = repr(system_prompt)\n",
    "\n",
    "example_input = \"Known for being very delicate, the skill could take a lifetime to master.\"\n",
    "\n",
    "# List of paraphrased sentences\n",
    "paraphrased_sentences = [\n",
    "    \"Famed for its delicacy, mastering the skill could take a lifetime.\",\n",
    "    \"Renowned for its fragility, the skill might require a lifetime to perfect.\",\n",
    "    \"Recognized for being extremely delicate, mastering this skill could take an entire lifetime.\",\n",
    "    \"Known for its delicate nature, the skill might take a lifetime to master.\",\n",
    "    \"Esteemed for its delicate nature, it could take a lifetime to master this skill.\",\n",
    "    \"Noted for its delicateness, the skill could take a whole lifetime to master.\",\n",
    "    \"Celebrated for being very delicate, mastering the skill might take a lifetime.\",\n",
    "    \"Admired for its fragility, the skill could take an entire lifetime to perfect.\",\n",
    "    \"Acclaimed for its delicate quality, mastering this skill might take a lifetime.\",\n",
    "    \"Distinguished by its delicacy, it could take a lifetime to master the skill.\",\n",
    "    \"Famous for being very delicate, the skill might take a lifetime to perfect.\",\n",
    "    \"Acknowledged for its delicate nature, mastering the skill could take a whole lifetime.\",\n",
    "    \"Well-known for its fragility, the skill might require a lifetime to master.\",\n",
    "    \"Recognized for its delicate quality, it could take a lifetime to master the skill.\",\n",
    "    \"Notable for being very delicate, the skill could require a lifetime to master.\",\n",
    "    \"Renowned for its delicateness, mastering the skill might take a whole lifetime.\",\n",
    "    \"Famed for its fragile nature, the skill could take a lifetime to master.\",\n",
    "    \"Celebrated for its delicate nature, mastering the skill could take an entire lifetime.\",\n",
    "    \"Noted for being extremely delicate, the skill might take a lifetime to master.\",\n",
    "    \"Esteemed for its fragility, the skill might require an entire lifetime to perfect.\",\n",
    "    \"Acclaimed for being very delicate, mastering this skill could take a whole lifetime.\",\n",
    "    \"Admired for its delicate quality, it might take a lifetime to master the skill.\"\n",
    "]\n",
    "\n",
    "# Convert the list to a single line string\n",
    "example_output = repr(paraphrased_sentences)\n",
    "\n",
    "input_messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": example_input},\n",
    "    {\"role\": \"assistant\", \"content\": example_output}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "3cc37a8c-93f5-42dd-ac73-240eb750cca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_ctx=4096,\n",
    "    n_threads=10,\n",
    "    n_gpu_layers=-1,\n",
    "    verbose=False,\n",
    "    # flash_attn=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "2c2982b2-83b9-47e5-ad46-8f9432e46dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 unique doc_ids removed as already exist\n",
      "No documents to process.\n"
     ]
    }
   ],
   "source": [
    "paraphrase_llm(data_loc, save_loc, error_loc, llm, input_messages, grammar_path=grammar_path, num_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "24c06044-651c-403c-ad3b-911c2feeb57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_and_write_docs.read_jsonl_file(data_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c2cbf5a8-be68-4497-af5c-0ed34eaad122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 unique doc_ids removed as already exist\n"
     ]
    }
   ],
   "source": [
    "filtered_df = filter_dataframe_by_folder(data_loc, save_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "29a9cb83-cee9-4bd7-842a-42fd6c61f32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well I was just about at the part where Id gone to stay with Cousin Amanda wasnt I?'"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_sentence = filtered_df.iloc[0, 7]\n",
    "example_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "7cdb4402-9689-4b72-ad36-660884faf00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = call_local_llm(llm, input_messages, example_sentence, grammar_path=grammar_path, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "839d2056-fb47-430b-ac7f-50cc08e11c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"I seemingly reached the point in my narrative where I had planned to reside with Cousin Amanda for some time wasnn\" , \"It appears that I am nearing the segment of my story involving a stay at Cousin Amanda\", \"Apparently we are approaching the part where I intended to live with Cousin Amanda\", \"I find myself on the verge of discussing my intention to reside with Cousin Amanda for a period\", \"The narrative is leading me towards the section about going to stay with Cousin Amanda\", \"Nearing the portion of my story where I was supposed to be living with Cousin Amanda\", \"I am coming close to detailing the part in which I intended to spend time at Cousin Amanda\", \"Approaching the segment of my account that involves a planned stay with Cousin Amanda\", \"We are about to touch upon the section where I had plans for an extended visit with Cousin Amanda\", \"The storyline is bringing us near the part describing my plan to reside with Cousin Amanda\"]\\n'"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "167ae5b0-4014-451b-a10e-174f30a2de27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unformatted Result: [\"I seemingly reached the point in my narrative where I had planned to reside with Cousin Amanda for some time wasnn\" , \"It appears that I am nearing the segment of my story involving a stay at Cousin Amanda\", \"Apparently we are approaching the part where I intended to live with Cousin Amanda\", \"I find myself on the verge of discussing my intention to reside with Cousin Amanda for a period\", \"The narrative is leading me towards the section about going to stay with Cousin Amanda\", \"Nearing the portion of my story where I was supposed to be living with Cousin Amanda\", \"I am coming close to detailing the part in which I intended to spend time at Cousin Amanda\", \"Approaching the segment of my account that involves a planned stay with Cousin Amanda\", \"We are about to touch upon the section where I had plans for an extended visit with Cousin Amanda\", \"The storyline is bringing us near the part describing my plan to reside with Cousin Amanda\"]\n",
      "\n",
      "Single Quote Placeholder: [\"I seemingly reached the point in my narrative where I had planned to reside with Cousin Amanda for some time wasnn\" , \"It appears that I am nearing the segment of my story involving a stay at Cousin Amanda\", \"Apparently we are approaching the part where I intended to live with Cousin Amanda\", \"I find myself on the verge of discussing my intention to reside with Cousin Amanda for a period\", \"The narrative is leading me towards the section about going to stay with Cousin Amanda\", \"Nearing the portion of my story where I was supposed to be living with Cousin Amanda\", \"I am coming close to detailing the part in which I intended to spend time at Cousin Amanda\", \"Approaching the segment of my account that involves a planned stay with Cousin Amanda\", \"We are about to touch upon the section where I had plans for an extended visit with Cousin Amanda\", \"The storyline is bringing us near the part describing my plan to reside with Cousin Amanda\"]\n",
      "\n",
      "Single Quote Replace: [\"I seemingly reached the point in my narrative where I had planned to reside with Cousin Amanda for some time wasnn\" , \"It appears that I am nearing the segment of my story involving a stay at Cousin Amanda\", \"Apparently we are approaching the part where I intended to live with Cousin Amanda\", \"I find myself on the verge of discussing my intention to reside with Cousin Amanda for a period\", \"The narrative is leading me towards the section about going to stay with Cousin Amanda\", \"Nearing the portion of my story where I was supposed to be living with Cousin Amanda\", \"I am coming close to detailing the part in which I intended to spend time at Cousin Amanda\", \"Approaching the segment of my account that involves a planned stay with Cousin Amanda\", \"We are about to touch upon the section where I had plans for an extended visit with Cousin Amanda\", \"The storyline is bringing us near the part describing my plan to reside with Cousin Amanda\"]\n",
      "\n",
      "Result: [\"I seemingly reached the point in my narrative where I had planned to reside with Cousin Amanda for some time wasnn\" , \"It appears that I am nearing the segment of my story involving a stay at Cousin Amanda\", \"Apparently we are approaching the part where I intended to live with Cousin Amanda\", \"I find myself on the verge of discussing my intention to reside with Cousin Amanda for a period\", \"The narrative is leading me towards the section about going to stay with Cousin Amanda\", \"Nearing the portion of my story where I was supposed to be living with Cousin Amanda\", \"I am coming close to detailing the part in which I intended to spend time at Cousin Amanda\", \"Approaching the segment of my account that involves a planned stay with Cousin Amanda\", \"We are about to touch upon the section where I had plans for an extended visit with Cousin Amanda\", \"The storyline is bringing us near the part describing my plan to reside with Cousin Amanda\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I seemingly reached the point in my narrative where I had planned to reside with Cousin Amanda for some time wasnn',\n",
       " 'It appears that I am nearing the segment of my story involving a stay at Cousin Amanda',\n",
       " 'Apparently we are approaching the part where I intended to live with Cousin Amanda',\n",
       " 'I find myself on the verge of discussing my intention to reside with Cousin Amanda for a period',\n",
       " 'The narrative is leading me towards the section about going to stay with Cousin Amanda',\n",
       " 'Nearing the portion of my story where I was supposed to be living with Cousin Amanda',\n",
       " 'I am coming close to detailing the part in which I intended to spend time at Cousin Amanda',\n",
       " 'Approaching the segment of my account that involves a planned stay with Cousin Amanda',\n",
       " 'We are about to touch upon the section where I had plans for an extended visit with Cousin Amanda',\n",
       " 'The storyline is bringing us near the part describing my plan to reside with Cousin Amanda']"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_output(result, error_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "3faef30d-8af2-4936-b528-1521676ef935",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.create_chat_completion(\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": example_input},\n",
    "        {\"role\": \"assistant\", \"content\": example_output},\n",
    "        {\"role\": \"user\", \"content\": \"'Well I was just about at the part where Id gone to stay with Cousin Amanda wasnt I?'\"},\n",
    "    ],\n",
    "    response_format={\n",
    "        \"type\": \"json_object\",\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\"rephrased\": {\"type\": \"array\"}},\n",
    "            \"required\": [\"rephrased\"],\n",
    "        },\n",
    "    },\n",
    "    temperature=0.5,\n",
    "    max_tokens=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "2fc9ddc0-cb8e-44ef-933f-ab4768dfd1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-363c1fd8-53ae-4315-a28f-6a5596ad5e8e',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1721478645,\n",
       " 'model': '../../../local models/Phi-3-mini-4k-instruct-q4.gguf',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': '{ \"rephrased\": [ \"I had reached the point in my narrative where I intended to spend time with my cousin, Amanda, correct?\", \"I was nearing that section of my story which involved me going to live with my cousin, Amanda; is that right?\", \"Had I arrived at the segment detailing my plan to stay with Cousin Amanda, wouldn\\'t you say so?\", \"I had almost gotten there in my recount where I was about to reside with my relative, Cousin Amanda. Isn\\'t it accurate?\" ] }'},\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 499,\n",
       "  'completion_tokens': 124,\n",
       "  'total_tokens': 623}}"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "603149fb-7955-4cbc-ab2b-43f41e1d5d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I had reached the point in my narrative where I intended to spend time with my cousin, Amanda, correct?',\n",
       " 'I was nearing that section of my story which involved me going to live with my cousin, Amanda; is that right?',\n",
       " \"Had I arrived at the segment detailing my plan to stay with Cousin Amanda, wouldn't you say so?\",\n",
       " \"I had almost gotten there in my recount where I was about to reside with my relative, Cousin Amanda. Isn't it accurate?\"]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(result['choices'][0]['message']['content'])['rephrased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "d892f1e8-8087-4d95-a650-86c0a4d4b2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "from_string grammar:\n",
      "root ::= [[] items []] EOF \n",
      "items ::= item items_7 \n",
      "EOF ::= [<U+000A>] \n",
      "item ::= string \n",
      "items_4 ::= [,] items_6 item \n",
      "ws ::= [ ] \n",
      "items_6 ::= ws items_6 | \n",
      "items_7 ::= items_4 items_7 | \n",
      "string ::= [\"] word string_12 [\"] string_13 \n",
      "word ::= word_14 \n",
      "string_10 ::= string_11 word \n",
      "string_11 ::= ws string_11 | ws \n",
      "string_12 ::= string_10 string_12 | \n",
      "string_13 ::= ws string_13 | \n",
      "word_14 ::= [a-zA-Z0-9.,!?;:'()] word_14 | [a-zA-Z0-9.,!?;:'()] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "grammar =LlamaGrammar.from_file(grammar_path, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "d3b9135e-f79b-4498-9ca5-4ee1e847348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.create_chat_completion(\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": example_input},\n",
    "        {\"role\": \"assistant\", \"content\": example_output},\n",
    "        {\"role\": \"user\", \"content\": \"'Well I was just about at the part where Id gone to stay with Cousin Amanda wasnt I?'\"},\n",
    "    ],\n",
    "    grammar=grammar,\n",
    "    temperature=0.5,\n",
    "    max_tokens=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "228e380d-4c55-4e87-8c2e-29ea3aed0625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-a7d6f8b2-a098-4be1-8234-cfc7fb31fb5c',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1721479898,\n",
       " 'model': '../../../local models/Phi-3-mini-4k-instruct-q4.gguf',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': '[\"I recall being nearly ready to head over and spend time with my cousin, Amanda, wasn\\'t I?\", \"Just on the verge of mentioning that I intended to visit Cousin Amanda, right?\", \"Approaching the moment when I would discuss staying at Cousin Amanda\\'s place, correct?\", \"I was about to bring up my plans to stay with my cousin, Amanda; isn\\'t it true?\", \"Nearly ready to mention that I had planned a visit to Cousin Amanda\\'s, wasn\\'t I?\", \"Heading towards the part where I would discuss going to live with Cousin Amanda, right?\", \"On the cusp of talking about my upcoming stay at Cousin Amanda\\'s house, isn\\'t it correct?\", \"I was close to recalling that I intended to spend time with my cousin, Amanda. Isn\\'t this accurate?\"]\\n'},\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 499,\n",
       "  'completion_tokens': 202,\n",
       "  'total_tokens': 701}}"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "f03a6311-6fe0-499b-ac04-f084173e1bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I recall being nearly ready to head over and spend time with my cousin, Amanda, wasn't I?\",\n",
       " 'Just on the verge of mentioning that I intended to visit Cousin Amanda, right?',\n",
       " \"Approaching the moment when I would discuss staying at Cousin Amanda's place, correct?\",\n",
       " \"I was about to bring up my plans to stay with my cousin, Amanda; isn't it true?\",\n",
       " \"Nearly ready to mention that I had planned a visit to Cousin Amanda's, wasn't I?\",\n",
       " 'Heading towards the part where I would discuss going to live with Cousin Amanda, right?',\n",
       " \"On the cusp of talking about my upcoming stay at Cousin Amanda's house, isn't it correct?\",\n",
       " \"I was close to recalling that I intended to spend time with my cousin, Amanda. Isn't this accurate?\"]"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(result['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d005a92-1c6b-4285-83c0-e76f17ff1fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
