{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "e6aa1dc4-745d-454b-a505-780a6fd80aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "3ba1209d-493e-4d0e-8377-5e7d62e85486",
   "metadata": {},
   "outputs": [],
   "source": [
    "credential_loc = \"../../credentials.json\"\n",
    "\n",
    "data_type = \"training\"\n",
    "corpus = \"The Telegraph\"\n",
    "\n",
    "base_loc = f\"/Volumes/BCross/datasets/author_verification/\"\n",
    "data_loc = f\"{base_loc}{data_type}/{corpus}/\"\n",
    "\n",
    "raw_data_loc = f\"{data_loc}known_raw.jsonl\"\n",
    "processed_data_loc = f\"{data_loc}known_processed.jsonl\"\n",
    "batch_complete_loc = f\"{data_loc}batch_sentence_complete/\"\n",
    "\n",
    "# ParaScore save location\n",
    "post_process_loc = f\"{data_loc}batch_postprocessed/\"\n",
    "os.makedirs(post_process_loc, exist_ok=True)\n",
    "\n",
    "# Phone number for WhatsApp notifications\n",
    "phone_number = \"+447756976114\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf6d9d8-5152-4e02-b2ee-c1a3f0918513",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "ba2605b5-1dcb-47eb-a4bd-28ae4359988f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Parse the line as JSON\n",
    "            parsed_line = json.loads(line)\n",
    "            # If the line is a single-element list, extract the first element\n",
    "            if isinstance(parsed_line, list) and len(parsed_line) == 1:\n",
    "                data.append(parsed_line[0])\n",
    "            else:\n",
    "                data.append(parsed_line)\n",
    "    \n",
    "    # Convert to a DataFrame\n",
    "    data = pd.DataFrame(data)\n",
    "    return data\n",
    "\n",
    "def write_jsonl(data, output_file_path):\n",
    "    with open(output_file_path, 'w') as file:\n",
    "        for _, row in data.iterrows():\n",
    "            json.dump(row.to_dict(), file)\n",
    "            file.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "25758043-d1ca-41f7-bd72-32c0ee397fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents to process in raw data: 220\n",
      "Files Complete in Batch location: 220\n",
      "Files Post Processed: 205\n",
      "Files to be Processed: 15\n"
     ]
    }
   ],
   "source": [
    "raw_df = read_jsonl(raw_data_loc)\n",
    "\n",
    "batch_completed_files = [\n",
    "    f for f in os.listdir(batch_complete_loc)\n",
    "    if os.path.isfile(os.path.join(batch_complete_loc, f)) and f.endswith('.jsonl')\n",
    "]\n",
    "\n",
    "files_processed = [\n",
    "    f for f in os.listdir(post_process_loc)\n",
    "    if os.path.isfile(os.path.join(post_process_loc, f)) and f.endswith('.jsonl')\n",
    "]\n",
    "\n",
    "# Replace \"batch_\" with \"doc_\" in each element of files_processed\n",
    "files_processed = [file.replace(\"doc_\", \"batch_\") for file in files_processed]\n",
    "\n",
    "files_to_be_processed = list(set(batch_completed_files) - set(files_processed))\n",
    "\n",
    "print(f\"Number of documents to process in raw data: {len(raw_df['doc_id'])}\")\n",
    "print(f\"Files Complete in Batch location: {len(batch_completed_files)}\")\n",
    "print(f\"Files Post Processed: {len(files_processed)}\")\n",
    "print(f\"Files to be Processed: {len(files_to_be_processed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "14b84203-93a2-409a-ba99-43453bc6a154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_custon_id(custon_id):\n",
    "    parts = custon_id.split('_')\n",
    "    doc_id = parts[2] + \"_\" + parts[3] + \"_\" + parts[4]\n",
    "    chunk_id = parts[-2]\n",
    "    repetition = parts[-1]\n",
    "    return pd.Series([doc_id, chunk_id, repetition])\n",
    "\n",
    "def parse_response(response_str):\n",
    "    # Convert the JSON string to a Python dictionary\n",
    "    response_dict = json.loads(response_str)\n",
    "    \n",
    "    # Extract the 'original' sentence\n",
    "    original_sentence = response_dict.get('original', '')\n",
    "    \n",
    "    # Extract other keys and add them to the list with 'repetition_i' format\n",
    "    rephrased = []\n",
    "    for key, value in response_dict.items():\n",
    "        if key != 'original':\n",
    "            rephrased.append(value)\n",
    "    \n",
    "    return original_sentence, rephrased\n",
    "\n",
    "def process_dataframe(df):\n",
    "\n",
    "    if 'custom_id' not in df.columns:\n",
    "        df['doc_id'] = df['doc_id'].str.replace(\"batch_\", \"\")\n",
    "\n",
    "        df = df[['doc_id', 'chunk_id', 'original', 'rephrased']]\n",
    "\n",
    "    else:\n",
    "        df[['doc_id', 'chunk_id', 'repetition']] = df['custom_id'].apply(split_custon_id)\n",
    "        \n",
    "        # Apply the parse_response function to each row of the dataframe\n",
    "        df['original_sentence'], df['rephrased'] = zip(*df['response'].apply(parse_response))\n",
    "\n",
    "        df = df[['doc_id', 'chunk_id', 'original_sentence', 'rephrased']]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def combine_and_unique(group):\n",
    "    # Combine all lists in the 'rephrased' column into one list\n",
    "    combined_list = sum(group['rephrased'], [])\n",
    "    \n",
    "    # Remove duplicates by converting to a set and back to a list\n",
    "    unique_list = list(set(combined_list))\n",
    "    \n",
    "    # Return a DataFrame where each unique rephrased sentence is a new row\n",
    "    return pd.DataFrame({\n",
    "        'doc_id': group['doc_id'].iloc[0],\n",
    "        'chunk_id': group['chunk_id'].iloc[0],\n",
    "        'original': group['original_sentence'].iloc[0],\n",
    "        'rephrased': unique_list\n",
    "    })\n",
    "\n",
    "def process_rephrased_sentences(df):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
    "        # Group by 'doc_id' and 'chunk_id' and apply the combine_and_unique function\n",
    "        result_df = df.groupby(['doc_id', 'chunk_id']).apply(combine_and_unique).reset_index(drop=True)\n",
    "        \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "d4e85894-1102-4c3c-98e4-29f571aeb0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file_list(files, base_read_loc, base_write_loc):\n",
    "\n",
    "    files = sorted(files)\n",
    "    total_files = len(files)  # Total number of files to process\n",
    "    for i, file in enumerate(files, start=1):  # Add index to track file number\n",
    "        complete_combine_step = False\n",
    "        try:\n",
    "            print(f\"Processing file {i} of {total_files}: {file}\")  # Tracker message\n",
    "            \n",
    "            # Step 1: Read the JSONL file\n",
    "            response = read_jsonl(f\"{base_read_loc}{file}\")\n",
    "\n",
    "            if 'custom_id' in response.columns:\n",
    "                complete_combine_step = True\n",
    "            \n",
    "            # Step 2: Process the DataFrame\n",
    "            processed_dataframe = process_dataframe(response)\n",
    "\n",
    "            if complete_combine_step:\n",
    "                # Step 3: Split the list into separate rows\n",
    "                final_df = process_rephrased_sentences(processed_dataframe)\n",
    "            else:\n",
    "                final_df = processed_dataframe\n",
    "            \n",
    "            # Step 4: Save the processed DataFrame to a new location\n",
    "            save_loc = f\"{base_write_loc}{file.replace('batch', 'doc')}\"\n",
    "            write_jsonl(final_df, save_loc)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"    Error processing {file}: {e}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "640dc1c8-3389-42c1-8bb6-a8c5b2ff0fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1 of 15: batch_andrewcritchlow_text_1.jsonl\n",
      "    Error processing batch_andrewcritchlow_text_1.jsonl: Unterminated string starting at: line 14 column 3 (char 1901)\n",
      "Processing file 2 of 15: batch_andrewcritchlow_text_3.jsonl\n",
      "    Error processing batch_andrewcritchlow_text_3.jsonl: Unterminated string starting at: line 13 column 20 (char 2448)\n",
      "Processing file 3 of 15: batch_bunnyguinness_text_2.jsonl\n",
      "    Error processing batch_bunnyguinness_text_2.jsonl: Unterminated string starting at: line 2 column 15 (char 16)\n",
      "Processing file 4 of 15: batch_cameronmacphail_text_1.jsonl\n",
      "    Error processing batch_cameronmacphail_text_1.jsonl: Unterminated string starting at: line 10 column 19 (char 1399)\n",
      "Processing file 5 of 15: batch_camillaturner_text_2.jsonl\n",
      "    Error processing batch_camillaturner_text_2.jsonl: Unterminated string starting at: line 3 column 19 (char 172)\n",
      "Processing file 6 of 15: batch_catalinastogdon_text_3.jsonl\n",
      "    Error processing batch_catalinastogdon_text_3.jsonl: Unterminated string starting at: line 8 column 19 (char 1632)\n",
      "Processing file 7 of 15: batch_christopherbooker_text_1.jsonl\n",
      "    Error processing batch_christopherbooker_text_1.jsonl: Unterminated string starting at: line 18 column 20 (char 3930)\n",
      "Processing file 8 of 15: batch_clivejames_text_3.jsonl\n",
      "    Error processing batch_clivejames_text_3.jsonl: Unterminated string starting at: line 2 column 15 (char 16)\n",
      "Processing file 9 of 15: batch_colemoreton_text_2.jsonl\n",
      "    Error processing batch_colemoreton_text_2.jsonl: Unterminated string starting at: line 12 column 20 (char 1356)\n",
      "Processing file 10 of 15: batch_colinfreeman_text_3.jsonl\n",
      "    Error processing batch_colinfreeman_text_3.jsonl: Unterminated string starting at: line 13 column 20 (char 2420)\n",
      "Processing file 11 of 15: batch_concoughlin_text_2.jsonl\n",
      "    Error processing batch_concoughlin_text_2.jsonl: Unterminated string starting at: line 4 column 19 (char 518)\n",
      "Processing file 12 of 15: batch_erinbaker_text_2.jsonl\n",
      "    Error processing batch_erinbaker_text_2.jsonl: Unterminated string starting at: line 7 column 19 (char 693)\n",
      "Processing file 13 of 15: batch_gregorywalton_text_2.jsonl\n",
      "    Error processing batch_gregorywalton_text_2.jsonl: Unterminated string starting at: line 10 column 19 (char 896)\n",
      "Processing file 14 of 15: batch_hannahfurness_text_2.jsonl\n",
      "    Error processing batch_hannahfurness_text_2.jsonl: Unterminated string starting at: line 8 column 3 (char 1058)\n",
      "Processing file 15 of 15: batch_hannahstrange_text_3.jsonl\n",
      "    Error processing batch_hannahstrange_text_3.jsonl: Unterminated string starting at: line 2 column 15 (char 16)\n"
     ]
    }
   ],
   "source": [
    "process_file_list(files_to_be_processed, batch_complete_loc, post_process_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "403b2f69-eb64-47c2-abbf-1ae02959069c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>custom_id</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batch_req_677dbeb53f848190b68fbd7ebe0aa2d4</td>\n",
       "      <td>22122024_doc_andrewcritchlow_text_1_chunk_1_1</td>\n",
       "      <td>{\\n  \"original\": \"Echoing the thoughts of Karl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>batch_req_677dbeb54ea4819084de7e98fded0283</td>\n",
       "      <td>22122024_doc_andrewcritchlow_text_1_chunk_1_2</td>\n",
       "      <td>{\\n  \"original\": \"Echoing the thoughts of Karl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>batch_req_677dbeb55c9081909d8c2f0da6bb1908</td>\n",
       "      <td>22122024_doc_andrewcritchlow_text_1_chunk_1_3</td>\n",
       "      <td>{\\n  \"original\": \"Echoing the thoughts of Karl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>batch_req_677dbeb569d081908e191c9ad18f40a7</td>\n",
       "      <td>22122024_doc_andrewcritchlow_text_1_chunk_1_4</td>\n",
       "      <td>{\\n  \"original\": \"Echoing the thoughts of Karl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>batch_req_677dbeb57860819090b737b6d2b06441</td>\n",
       "      <td>22122024_doc_andrewcritchlow_text_1_chunk_1_5</td>\n",
       "      <td>{\\n  \"original\": \"Echoing the thoughts of Karl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>batch_req_677dbebe49288190a174182a08a0d40c</td>\n",
       "      <td>22122024_doc_andrewcritchlow_text_1_chunk_17_6</td>\n",
       "      <td>{\\n  \"original\": \"Then, in 2011, the cost spik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>batch_req_677dbebe57d08190976f4a0b2e0e68b1</td>\n",
       "      <td>22122024_doc_andrewcritchlow_text_1_chunk_17_7</td>\n",
       "      <td>{\\n  \"original\": \"Then, in 2011, the cost spik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>batch_req_677dbebe6970819092e0fdc7c89879c9</td>\n",
       "      <td>22122024_doc_andrewcritchlow_text_1_chunk_17_8</td>\n",
       "      <td>{\\n  \"original\": \"Then, in 2011, the cost spik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>batch_req_677dbebe78cc81909ee983ea00bbbb95</td>\n",
       "      <td>22122024_doc_andrewcritchlow_text_1_chunk_17_9</td>\n",
       "      <td>{\\n  \"original\": \"Then, in 2011, the cost spik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>batch_req_677dbebe86608190816cd5fe46f2c62f</td>\n",
       "      <td>22122024_doc_andrewcritchlow_text_1_chunk_17_10</td>\n",
       "      <td>{\\n  \"original\": \"Then, in 2011, the cost spik...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             id  \\\n",
       "0    batch_req_677dbeb53f848190b68fbd7ebe0aa2d4   \n",
       "1    batch_req_677dbeb54ea4819084de7e98fded0283   \n",
       "2    batch_req_677dbeb55c9081909d8c2f0da6bb1908   \n",
       "3    batch_req_677dbeb569d081908e191c9ad18f40a7   \n",
       "4    batch_req_677dbeb57860819090b737b6d2b06441   \n",
       "..                                          ...   \n",
       "165  batch_req_677dbebe49288190a174182a08a0d40c   \n",
       "166  batch_req_677dbebe57d08190976f4a0b2e0e68b1   \n",
       "167  batch_req_677dbebe6970819092e0fdc7c89879c9   \n",
       "168  batch_req_677dbebe78cc81909ee983ea00bbbb95   \n",
       "169  batch_req_677dbebe86608190816cd5fe46f2c62f   \n",
       "\n",
       "                                           custom_id  \\\n",
       "0      22122024_doc_andrewcritchlow_text_1_chunk_1_1   \n",
       "1      22122024_doc_andrewcritchlow_text_1_chunk_1_2   \n",
       "2      22122024_doc_andrewcritchlow_text_1_chunk_1_3   \n",
       "3      22122024_doc_andrewcritchlow_text_1_chunk_1_4   \n",
       "4      22122024_doc_andrewcritchlow_text_1_chunk_1_5   \n",
       "..                                               ...   \n",
       "165   22122024_doc_andrewcritchlow_text_1_chunk_17_6   \n",
       "166   22122024_doc_andrewcritchlow_text_1_chunk_17_7   \n",
       "167   22122024_doc_andrewcritchlow_text_1_chunk_17_8   \n",
       "168   22122024_doc_andrewcritchlow_text_1_chunk_17_9   \n",
       "169  22122024_doc_andrewcritchlow_text_1_chunk_17_10   \n",
       "\n",
       "                                              response  \n",
       "0    {\\n  \"original\": \"Echoing the thoughts of Karl...  \n",
       "1    {\\n  \"original\": \"Echoing the thoughts of Karl...  \n",
       "2    {\\n  \"original\": \"Echoing the thoughts of Karl...  \n",
       "3    {\\n  \"original\": \"Echoing the thoughts of Karl...  \n",
       "4    {\\n  \"original\": \"Echoing the thoughts of Karl...  \n",
       "..                                                 ...  \n",
       "165  {\\n  \"original\": \"Then, in 2011, the cost spik...  \n",
       "166  {\\n  \"original\": \"Then, in 2011, the cost spik...  \n",
       "167  {\\n  \"original\": \"Then, in 2011, the cost spik...  \n",
       "168  {\\n  \"original\": \"Then, in 2011, the cost spik...  \n",
       "169  {\\n  \"original\": \"Then, in 2011, the cost spik...  \n",
       "\n",
       "[170 rows x 3 columns]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_jsonl(f\"{batch_complete_loc}{files_to_be_processed[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "257c836c-4fae-4987-8344-a9dd5c5640b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>custom_id</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>batch_req_6768aab829348190931e49a4de06d72a</td>\n",
       "      <td>22122024_doc_gillianreynolds_text_2_chunk_1_1</td>\n",
       "      <td>{\\n  \"original\": \"It is a well-known fact that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>batch_req_6768aab83e208190b208153ba9b76834</td>\n",
       "      <td>22122024_doc_gillianreynolds_text_2_chunk_1_2</td>\n",
       "      <td>{\\n  \"original\": \"It is a well-known fact that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>batch_req_6768aab85f448190b0714a644bf25968</td>\n",
       "      <td>22122024_doc_gillianreynolds_text_2_chunk_1_3</td>\n",
       "      <td>{\\n  \"original\": \"It is a well-known fact that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>batch_req_6768aab8786081909e8d70c23fa33139</td>\n",
       "      <td>22122024_doc_gillianreynolds_text_2_chunk_1_4</td>\n",
       "      <td>{\\n  \"original\": \"It is a well-known fact that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>batch_req_6768aab893a48190ba4638e136755b1c</td>\n",
       "      <td>22122024_doc_gillianreynolds_text_2_chunk_1_5</td>\n",
       "      <td>{\\n  \"original\": \"It is a well-known fact that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>batch_req_6768aaccf3608190a24c907dc13194ba</td>\n",
       "      <td>22122024_doc_gillianreynolds_text_2_chunk_23_6</td>\n",
       "      <td>{\\n  \"original\": \"Elizabeth and Roy have slept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>batch_req_6768aacd0ebc8190a849610a2ffeef11</td>\n",
       "      <td>22122024_doc_gillianreynolds_text_2_chunk_23_7</td>\n",
       "      <td>{\\n  \"original\": \"Elizabeth and Roy have slept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>batch_req_6768aacd285c81909830bdfa46cd94b4</td>\n",
       "      <td>22122024_doc_gillianreynolds_text_2_chunk_23_8</td>\n",
       "      <td>{\\n  \"original\": \"Elizabeth and Roy have slept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>batch_req_6768aacd40c48190b1e6af9943d8639f</td>\n",
       "      <td>22122024_doc_gillianreynolds_text_2_chunk_23_9</td>\n",
       "      <td>{\\n  \"original\": \"Elizabeth and Roy have slept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>batch_req_6768aacd52608190b6634f9b68f97356</td>\n",
       "      <td>22122024_doc_gillianreynolds_text_2_chunk_23_10</td>\n",
       "      <td>{\\n  \"original\": \"Elizabeth and Roy have slept...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             id  \\\n",
       "0    batch_req_6768aab829348190931e49a4de06d72a   \n",
       "1    batch_req_6768aab83e208190b208153ba9b76834   \n",
       "2    batch_req_6768aab85f448190b0714a644bf25968   \n",
       "3    batch_req_6768aab8786081909e8d70c23fa33139   \n",
       "4    batch_req_6768aab893a48190ba4638e136755b1c   \n",
       "..                                          ...   \n",
       "225  batch_req_6768aaccf3608190a24c907dc13194ba   \n",
       "226  batch_req_6768aacd0ebc8190a849610a2ffeef11   \n",
       "227  batch_req_6768aacd285c81909830bdfa46cd94b4   \n",
       "228  batch_req_6768aacd40c48190b1e6af9943d8639f   \n",
       "229  batch_req_6768aacd52608190b6634f9b68f97356   \n",
       "\n",
       "                                           custom_id  \\\n",
       "0      22122024_doc_gillianreynolds_text_2_chunk_1_1   \n",
       "1      22122024_doc_gillianreynolds_text_2_chunk_1_2   \n",
       "2      22122024_doc_gillianreynolds_text_2_chunk_1_3   \n",
       "3      22122024_doc_gillianreynolds_text_2_chunk_1_4   \n",
       "4      22122024_doc_gillianreynolds_text_2_chunk_1_5   \n",
       "..                                               ...   \n",
       "225   22122024_doc_gillianreynolds_text_2_chunk_23_6   \n",
       "226   22122024_doc_gillianreynolds_text_2_chunk_23_7   \n",
       "227   22122024_doc_gillianreynolds_text_2_chunk_23_8   \n",
       "228   22122024_doc_gillianreynolds_text_2_chunk_23_9   \n",
       "229  22122024_doc_gillianreynolds_text_2_chunk_23_10   \n",
       "\n",
       "                                              response  \n",
       "0    {\\n  \"original\": \"It is a well-known fact that...  \n",
       "1    {\\n  \"original\": \"It is a well-known fact that...  \n",
       "2    {\\n  \"original\": \"It is a well-known fact that...  \n",
       "3    {\\n  \"original\": \"It is a well-known fact that...  \n",
       "4    {\\n  \"original\": \"It is a well-known fact that...  \n",
       "..                                                 ...  \n",
       "225  {\\n  \"original\": \"Elizabeth and Roy have slept...  \n",
       "226  {\\n  \"original\": \"Elizabeth and Roy have slept...  \n",
       "227  {\\n  \"original\": \"Elizabeth and Roy have slept...  \n",
       "228  {\\n  \"original\": \"Elizabeth and Roy have slept...  \n",
       "229  {\\n  \"original\": \"Elizabeth and Roy have slept...  \n",
       "\n",
       "[230 rows x 3 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_jsonl(f\"{batch_complete_loc}{files_processed[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paraphrase_llm",
   "language": "python",
   "name": "paraphrase_llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
