{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "5ef0b017-f41b-4b4a-8974-398bbd0a7f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "3d60913a-0b88-44e7-ae44-889c6b474156",
   "metadata": {},
   "outputs": [],
   "source": [
    "credential_loc = \"../../credentials.json\"\n",
    "\n",
    "data_type = \"training\"\n",
    "corpus = \"Enron\"\n",
    "\n",
    "base_loc = f\"/Volumes/BCross/datasets/author_verification/\"\n",
    "data_loc = f\"{base_loc}{data_type}/{corpus}/\"\n",
    "batch_loc = f\"{data_loc}batch_sentence_preprocessed/\"\n",
    "raw_data_loc = f\"{data_loc}known_raw.jsonl\"\n",
    "processed_data_loc = f\"{data_loc}known_processed.jsonl\"\n",
    "\n",
    "temp_local_location = f\"/Users/user/Documents/temp_datasets/author_verification/{data_type}/{corpus}/\"\n",
    "os.makedirs(temp_local_location, exist_ok=True)\n",
    "\n",
    "# Location for data when sent to batch\n",
    "batch_sent_loc = f\"{data_loc}batch_sentence_sent/\"\n",
    "os.makedirs(batch_sent_loc, exist_ok=True)\n",
    "\n",
    "# Location once batch complete\n",
    "batch_complete_loc = f\"{data_loc}batch_sentence_complete/\"\n",
    "os.makedirs(batch_complete_loc, exist_ok=True)\n",
    "\n",
    "# Location once batch complete\n",
    "batch_fail_loc = f\"{data_loc}batch_sentence_fail/\"\n",
    "os.makedirs(batch_fail_loc, exist_ok=True)\n",
    "\n",
    "# Location to save the reasons for failure\n",
    "batch_fail_reason_loc = f\"{data_loc}batch_fail_reasons/\"\n",
    "os.makedirs(batch_fail_reason_loc, exist_ok=True)\n",
    "\n",
    "# Phone number for WhatsApp notifications\n",
    "phone_number = \"+447756976114\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655ea315-ed59-43ae-b8dc-558acbcff981",
   "metadata": {},
   "source": [
    "### Initialise OpenAI Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "fc1df3c8-a274-4934-b046-0f3db96db422",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(credential_loc, 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "os.environ[\"OPENAI_API_KEY\"] = data['OPENAI_API_KEY']\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68ea97e-bc3e-4982-bb23-f6b9a0d2122c",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "3f92150d-4546-4c6d-b7fa-01df40506a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl(file_path):\n",
    "    \"\"\"\n",
    "    Reads a JSONL file and converts it into a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: Path to the JSONL file to read.\n",
    "\n",
    "    Returns:\n",
    "    - A pandas DataFrame containing the data from the JSONL file.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Parse the line as JSON\n",
    "            parsed_line = json.loads(line)\n",
    "            # If the line is a single-element list, extract the first element\n",
    "            if isinstance(parsed_line, list) and len(parsed_line) == 1:\n",
    "                data.append(parsed_line[0])\n",
    "            else:\n",
    "                data.append(parsed_line)\n",
    "    \n",
    "    # Convert to a DataFrame\n",
    "    data = pd.DataFrame(data)\n",
    "    return data\n",
    "\n",
    "def write_jsonl(data, output_file_path):\n",
    "    with open(output_file_path, 'w') as file:\n",
    "        for _, row in data.iterrows():\n",
    "            json.dump(row.to_dict(), file)\n",
    "            file.write('\\n')\n",
    "\n",
    "def create_temp_doc_id(input_text):\n",
    "    # Extract everything between the brackets\n",
    "    match = re.search(r'\\[(.*?)\\]', input_text)\n",
    "    if match:\n",
    "        extracted_text = match.group(1)\n",
    "        # Replace all punctuation and spaces with \"_\"\n",
    "        cleaned_text = re.sub(r'[^\\w]', '_', extracted_text)\n",
    "        # Replace multiple underscores with a single \"_\"\n",
    "        final_text = re.sub(r'_{2,}', '_', cleaned_text)\n",
    "        final_text = 'batch_' + final_text\n",
    "        return final_text.lower()\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "cfa77ba5-993f-4ac3-8225-848bf9888f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_fail_reasons(batch_fail_reason_loc):\n",
    "\n",
    "    fail_reasons = os.listdir(batch_fail_reason_loc)\n",
    "\n",
    "    # Sort in descending order by timestamp\n",
    "    sorted_files = sorted(fail_reasons, key=lambda x: int(x.split('_')[-1].split('.')[0]), reverse=True)\n",
    "\n",
    "    # Read the latest created document\n",
    "    df = read_jsonl(f\"{batch_fail_reason_loc}{sorted_files[0]}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_files_list(loc):\n",
    "\n",
    "    files = [\n",
    "        f for f in os.listdir(loc)\n",
    "        if os.path.isfile(os.path.join(loc, f)) and f.endswith('.jsonl')\n",
    "    ]\n",
    "\n",
    "    strings_before_filetype = [file.split('.json')[0] for file in files]\n",
    "    \n",
    "    return strings_before_filetype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "68c412a2-6d86-4083-b85b-d7263dc1f183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_known_for_fails(processed_data_loc, batch_fail_loc, batch_complete_loc, temp_local_location):\n",
    "\n",
    "    # Load data and create new id which is the same as batch id's\n",
    "    df = read_jsonl(processed_data_loc)\n",
    "    \n",
    "    df['temp_doc_id'] = df['doc_id'].apply(lambda x: create_temp_doc_id(x))\n",
    "    df['temp_doc_id'] = df['temp_doc_id'].fillna('batch_' + df['corpus'] + '_' + df['author'])\n",
    "\n",
    "    failed_files = get_files_list(batch_fail_loc)\n",
    "    failed_files = [re.sub(r'[^\\w\\s]', '_', s) for s in failed_files]\n",
    "    \n",
    "    complete_files = get_files_list(batch_complete_loc)\n",
    "    complete_files = [re.sub(r'[^\\w\\s]', '_', s) for s in complete_files]\n",
    "\n",
    "    temp_local_files = get_files_list(temp_local_location)\n",
    "    temp_local_files = [re.sub(r'[^\\w\\s]', '_', s) for s in temp_local_files]\n",
    "    # df = df[df['temp_doc_id'].isin(failed_files)]\n",
    "\n",
    "    df = df[~(df['temp_doc_id'].isin(complete_files))]\n",
    "    df = df[~(df['temp_doc_id'].isin(temp_local_files))]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "16967591-62af-4756-8d1c-3c59a1dc243c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=filter_known_for_fails(processed_data_loc, batch_fail_loc, batch_complete_loc, temp_local_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "fb9d7890-c231-4db4-8e50-fb76b982bad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>author</th>\n",
       "      <th>texttype</th>\n",
       "      <th>sentence</th>\n",
       "      <th>temp_doc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3632</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>1</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>Within his profession, Mr. Vaughan was foundin...</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3633</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>2</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>He is chairman and has served as a director si...</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3634</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>3</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>Mr. Vaughan has been a trustee of Vanderbilt U...</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3635</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>4</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>He is a director since 1990 and on the Executi...</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3636</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>5</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>He is Chairman of the Center for Houston's Fut...</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3637</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>6</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>Mr. Vaughan is a director of the Houston Grand...</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>7</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>He was founding chairman of Presbyterian Schoo...</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3639</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>8</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>00 am I hope you choose to join us for this an...</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3640</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>9</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>Reservations accepted until noon on May 4, 2001.</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3641</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>10</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>Thank you for your help.</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3642</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>11</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>meeting on June 12 at the Venetian Resort in L...</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3643</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>12</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>Thank you for setting aside time to meet with me.</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3644</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>13</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>I have attached my resume to help bring you up...</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3645</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>14</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>As you will see, I have been providing advisor...</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3646</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>15</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>During these years, I have done some of my bes...</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3647</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>16</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>I am proud of the service that I have rendered...</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3648</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>17</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>Now, I feel it is time to move to a new chapte...</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>18</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>I look forward to sitting down with you to thi...</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>19</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>I respect you tremendously, and wherever the n...</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>20</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>I found it during a profoundly challenging per...</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3652</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>21</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>Your historic words of support helped me keep ...</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3653</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>22</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>Don't miss this exceptional speaker with great...</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3654</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>23</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>Dr. Bernard Harris will discuss the business s...</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3655</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>24</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>I've asked that the sedan stand by and take yo...</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3656</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>25</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>Ok, I'll tell you what I've told everyone else...</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3657</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>26</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>So, pledge with your heart, keeping your pocke...</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3658</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>27</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>By the way, Jeff finished the ride in just ove...</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3659</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>28</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>No matter how much I have, its never enough.</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     corpus                              doc_id  chunk_id         author  \\\n",
       "3632  Enron  known [Jeff.skilling - Mail_4].txt         1  Jeff.skilling   \n",
       "3633  Enron  known [Jeff.skilling - Mail_4].txt         2  Jeff.skilling   \n",
       "3634  Enron  known [Jeff.skilling - Mail_4].txt         3  Jeff.skilling   \n",
       "3635  Enron  known [Jeff.skilling - Mail_4].txt         4  Jeff.skilling   \n",
       "3636  Enron  known [Jeff.skilling - Mail_4].txt         5  Jeff.skilling   \n",
       "3637  Enron  known [Jeff.skilling - Mail_4].txt         6  Jeff.skilling   \n",
       "3638  Enron  known [Jeff.skilling - Mail_4].txt         7  Jeff.skilling   \n",
       "3639  Enron  known [Jeff.skilling - Mail_4].txt         8  Jeff.skilling   \n",
       "3640  Enron  known [Jeff.skilling - Mail_4].txt         9  Jeff.skilling   \n",
       "3641  Enron  known [Jeff.skilling - Mail_4].txt        10  Jeff.skilling   \n",
       "3642  Enron  known [Jeff.skilling - Mail_4].txt        11  Jeff.skilling   \n",
       "3643  Enron  known [Jeff.skilling - Mail_4].txt        12  Jeff.skilling   \n",
       "3644  Enron  known [Jeff.skilling - Mail_4].txt        13  Jeff.skilling   \n",
       "3645  Enron  known [Jeff.skilling - Mail_4].txt        14  Jeff.skilling   \n",
       "3646  Enron  known [Jeff.skilling - Mail_4].txt        15  Jeff.skilling   \n",
       "3647  Enron  known [Jeff.skilling - Mail_4].txt        16  Jeff.skilling   \n",
       "3648  Enron  known [Jeff.skilling - Mail_4].txt        17  Jeff.skilling   \n",
       "3649  Enron  known [Jeff.skilling - Mail_4].txt        18  Jeff.skilling   \n",
       "3650  Enron  known [Jeff.skilling - Mail_4].txt        19  Jeff.skilling   \n",
       "3651  Enron  known [Jeff.skilling - Mail_4].txt        20  Jeff.skilling   \n",
       "3652  Enron  known [Jeff.skilling - Mail_4].txt        21  Jeff.skilling   \n",
       "3653  Enron  known [Jeff.skilling - Mail_4].txt        22  Jeff.skilling   \n",
       "3654  Enron  known [Jeff.skilling - Mail_4].txt        23  Jeff.skilling   \n",
       "3655  Enron  known [Jeff.skilling - Mail_4].txt        24  Jeff.skilling   \n",
       "3656  Enron  known [Jeff.skilling - Mail_4].txt        25  Jeff.skilling   \n",
       "3657  Enron  known [Jeff.skilling - Mail_4].txt        26  Jeff.skilling   \n",
       "3658  Enron  known [Jeff.skilling - Mail_4].txt        27  Jeff.skilling   \n",
       "3659  Enron  known [Jeff.skilling - Mail_4].txt        28  Jeff.skilling   \n",
       "\n",
       "     texttype                                           sentence  \\\n",
       "3632    known  Within his profession, Mr. Vaughan was foundin...   \n",
       "3633    known  He is chairman and has served as a director si...   \n",
       "3634    known  Mr. Vaughan has been a trustee of Vanderbilt U...   \n",
       "3635    known  He is a director since 1990 and on the Executi...   \n",
       "3636    known  He is Chairman of the Center for Houston's Fut...   \n",
       "3637    known  Mr. Vaughan is a director of the Houston Grand...   \n",
       "3638    known  He was founding chairman of Presbyterian Schoo...   \n",
       "3639    known  00 am I hope you choose to join us for this an...   \n",
       "3640    known   Reservations accepted until noon on May 4, 2001.   \n",
       "3641    known                           Thank you for your help.   \n",
       "3642    known  meeting on June 12 at the Venetian Resort in L...   \n",
       "3643    known  Thank you for setting aside time to meet with me.   \n",
       "3644    known  I have attached my resume to help bring you up...   \n",
       "3645    known  As you will see, I have been providing advisor...   \n",
       "3646    known  During these years, I have done some of my bes...   \n",
       "3647    known  I am proud of the service that I have rendered...   \n",
       "3648    known  Now, I feel it is time to move to a new chapte...   \n",
       "3649    known  I look forward to sitting down with you to thi...   \n",
       "3650    known  I respect you tremendously, and wherever the n...   \n",
       "3651    known  I found it during a profoundly challenging per...   \n",
       "3652    known  Your historic words of support helped me keep ...   \n",
       "3653    known  Don't miss this exceptional speaker with great...   \n",
       "3654    known  Dr. Bernard Harris will discuss the business s...   \n",
       "3655    known  I've asked that the sedan stand by and take yo...   \n",
       "3656    known  Ok, I'll tell you what I've told everyone else...   \n",
       "3657    known  So, pledge with your heart, keeping your pocke...   \n",
       "3658    known  By the way, Jeff finished the ride in just ove...   \n",
       "3659    known       No matter how much I have, its never enough.   \n",
       "\n",
       "                     temp_doc_id  \n",
       "3632  batch_jeff_skilling_mail_4  \n",
       "3633  batch_jeff_skilling_mail_4  \n",
       "3634  batch_jeff_skilling_mail_4  \n",
       "3635  batch_jeff_skilling_mail_4  \n",
       "3636  batch_jeff_skilling_mail_4  \n",
       "3637  batch_jeff_skilling_mail_4  \n",
       "3638  batch_jeff_skilling_mail_4  \n",
       "3639  batch_jeff_skilling_mail_4  \n",
       "3640  batch_jeff_skilling_mail_4  \n",
       "3641  batch_jeff_skilling_mail_4  \n",
       "3642  batch_jeff_skilling_mail_4  \n",
       "3643  batch_jeff_skilling_mail_4  \n",
       "3644  batch_jeff_skilling_mail_4  \n",
       "3645  batch_jeff_skilling_mail_4  \n",
       "3646  batch_jeff_skilling_mail_4  \n",
       "3647  batch_jeff_skilling_mail_4  \n",
       "3648  batch_jeff_skilling_mail_4  \n",
       "3649  batch_jeff_skilling_mail_4  \n",
       "3650  batch_jeff_skilling_mail_4  \n",
       "3651  batch_jeff_skilling_mail_4  \n",
       "3652  batch_jeff_skilling_mail_4  \n",
       "3653  batch_jeff_skilling_mail_4  \n",
       "3654  batch_jeff_skilling_mail_4  \n",
       "3655  batch_jeff_skilling_mail_4  \n",
       "3656  batch_jeff_skilling_mail_4  \n",
       "3657  batch_jeff_skilling_mail_4  \n",
       "3658  batch_jeff_skilling_mail_4  \n",
       "3659  batch_jeff_skilling_mail_4  "
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "dbf2400e-b87f-4d56-850f-fd55c4ca60f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['temp_doc_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "1c273196-af4c-49c3-b165-91c2cf80a551",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are a paraphrasing assistant. Your task is to generate paraphrased sentences that retain the original meaning, tone, and style but demonstrate maximum lexical and structural variety.\n",
    "Each paraphrase should use distinct vocabulary and sentence structures, prioritizing as much lexical difference as possible.\n",
    "\n",
    "Guidelines:\n",
    "- Create AT LEAST TWENTY unique paraphrases.\n",
    "- Avoid repeating words or phrases across paraphrases, unless they are critical to meaning (e.g., names or specific technical terms).\n",
    "- Use varied synonyms, alter phrasing, and experiment with different sentence structures to ensure each paraphrase feels fresh and unique.\n",
    "- Examples of strategies to achieve this include: using metaphors or idioms, reordering clauses, shifting perspectives, and exploring different grammatical constructions.\n",
    "- Preserve the original intent and style without adding new information or altering names.\n",
    "\n",
    "DO NOT INCLUDE ANY NOTES OR ADDITIONAL TEXT IN THE OUTPUT.\n",
    "\n",
    "Example in JSON format:\n",
    "\n",
    "input: \"Although the skill appears easy at first, it can take a long time to master.\"\n",
    "\n",
    "Output:\n",
    "{\n",
    "  \"original\": \"Although the skill appears easy at first, it can take a long time to master.\",\n",
    "  \"paraphrase_1\": \"Initially, the skill may seem effortless, yet true mastery demands a lengthy commitment.\",\n",
    "  \"paraphrase_2\": \"What begins as a simple-looking skill often turns into a time-consuming mastery process.\",\n",
    "  \"paraphrase_3\": \"While appearing simple at the outset, mastering this skill typically requires extended effort.\",\n",
    "  \"paraphrase_4\": \"Despite an easy start, reaching mastery in this skill can be a prolonged journey.\",\n",
    "  \"paraphrase_5\": \"This skill, while seemingly straightforward at first glance, requires considerable time to excel in.\",\n",
    "  \"paraphrase_6\": \"Even if it looks easy at the beginning, achieving expertise in this skill may be time-intensive.\",\n",
    "  \"paraphrase_7\": \"Though simple in appearance, the skill demands time and practice to truly master.\",\n",
    "  \"paraphrase_8\": \"Achieving proficiency in this skill can take substantial time, even if it seems easy initially.\",\n",
    "  \"paraphrase_9\": \"While the skill might look easy at the start, honing it to perfection can require considerable time.\",\n",
    "  \"paraphrase_10\": \"It might seem straightforward to pick up, yet mastering this skill is often a slow process.\",\n",
    "  \"paraphrase_11\": \"Perfecting this seemingly easy skill can actually be a long and demanding task.\",\n",
    "  \"paraphrase_12\": \"Though it appears simple to learn, achieving mastery in this skill often takes a significant amount of time.\",\n",
    "  \"paraphrase_13\": \"Initially, the skill may come across as effortless, but true proficiency is typically time-consuming.\",\n",
    "  \"paraphrase_14\": \"Mastering this skill is a lengthy pursuit, despite its initial simplicity.\",\n",
    "  \"paraphrase_15\": \"While it looks uncomplicated at first, gaining full mastery of this skill can be a long journey.\",\n",
    "  \"paraphrase_16\": \"Even though this skill seems straightforward, becoming proficient usually takes an extended period.\",\n",
    "  \"paraphrase_17\": \"Mastery of this seemingly simple skill often requires more time than one might expect.\",\n",
    "  \"paraphrase_18\": \"Though it may appear easy at first glance, mastering this skill can be a drawn-out process.\",\n",
    "  \"paraphrase_19\": \"Although appearing effortless at first, this skill demands time and patience for true mastery.\",\n",
    "  \"paraphrase_20\": \"While this skill may look easy initially, true expertise often requires a great deal of time to develop.\"\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "85d1fd07-9902-420a-8b38-e012e7ad7da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'doc_id': 'orig_doc_id',\n",
    "                        'temp_doc_id': 'doc_id',\n",
    "                        'sentence': 'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "54673e62-9cb0-43dc-a24b-ac69a0572314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>orig_doc_id</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>author</th>\n",
       "      <th>texttype</th>\n",
       "      <th>text</th>\n",
       "      <th>doc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3632</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>1</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>Within his profession, Mr. Vaughan was foundin...</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3633</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>2</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>He is chairman and has served as a director si...</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3634</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>3</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>Mr. Vaughan has been a trustee of Vanderbilt U...</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3635</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>4</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>He is a director since 1990 and on the Executi...</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3636</th>\n",
       "      <td>Enron</td>\n",
       "      <td>known [Jeff.skilling - Mail_4].txt</td>\n",
       "      <td>5</td>\n",
       "      <td>Jeff.skilling</td>\n",
       "      <td>known</td>\n",
       "      <td>He is Chairman of the Center for Houston's Fut...</td>\n",
       "      <td>batch_jeff_skilling_mail_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     corpus                         orig_doc_id  chunk_id         author  \\\n",
       "3632  Enron  known [Jeff.skilling - Mail_4].txt         1  Jeff.skilling   \n",
       "3633  Enron  known [Jeff.skilling - Mail_4].txt         2  Jeff.skilling   \n",
       "3634  Enron  known [Jeff.skilling - Mail_4].txt         3  Jeff.skilling   \n",
       "3635  Enron  known [Jeff.skilling - Mail_4].txt         4  Jeff.skilling   \n",
       "3636  Enron  known [Jeff.skilling - Mail_4].txt         5  Jeff.skilling   \n",
       "\n",
       "     texttype                                               text  \\\n",
       "3632    known  Within his profession, Mr. Vaughan was foundin...   \n",
       "3633    known  He is chairman and has served as a director si...   \n",
       "3634    known  Mr. Vaughan has been a trustee of Vanderbilt U...   \n",
       "3635    known  He is a director since 1990 and on the Executi...   \n",
       "3636    known  He is Chairman of the Center for Houston's Fut...   \n",
       "\n",
       "                          doc_id  \n",
       "3632  batch_jeff_skilling_mail_4  \n",
       "3633  batch_jeff_skilling_mail_4  \n",
       "3634  batch_jeff_skilling_mail_4  \n",
       "3635  batch_jeff_skilling_mail_4  \n",
       "3636  batch_jeff_skilling_mail_4  "
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "dbb95519-e286-4aed-9ca8-23360d171d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paraphrase_call(text, system_prompt, client, n=10):\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": text}\n",
    "    ],\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "    n = n\n",
    "    )\n",
    "\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "42edf19c-b381-422e-84f6-9731bb235cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_paraphrase_generation(text, system_prompt, client, n=10):\n",
    "    try:\n",
    "        # Call the paraphrase generation function\n",
    "        result = paraphrase_call(text, system_prompt, client, n=n)\n",
    "        \n",
    "        # Initialize the final result with defaults\n",
    "        final_result = {\n",
    "            'original_sentence': text,  # Use the input text as the default original\n",
    "            'rephrased': []  # Default to an empty list\n",
    "        }\n",
    "        \n",
    "        # Check if result.choices exists and contains valid choices\n",
    "        if not result or not hasattr(result, 'choices') or not result.choices:\n",
    "            return final_result  # Return the default if the response is invalid\n",
    "        \n",
    "        # Use a set to collect unique paraphrases\n",
    "        unique_paraphrases = set()\n",
    "        \n",
    "        for choice in result.choices:\n",
    "            # Parse the JSON content from each choice\n",
    "            try:\n",
    "                json_object = json.loads(choice.message.content)\n",
    "            except (json.JSONDecodeError, AttributeError):\n",
    "                continue  # Skip invalid JSON or missing content\n",
    "            \n",
    "            # Set the original text (only set once)\n",
    "            if not final_result['original_sentence']:\n",
    "                final_result['original_sentence'] = json_object.get('original', text)\n",
    "            \n",
    "            # Collect paraphrases\n",
    "            for key, value in json_object.items():\n",
    "                if key.startswith('paraphrase_'):\n",
    "                    unique_paraphrases.add(value)\n",
    "        \n",
    "        # Update the final result\n",
    "        final_result['rephrased'] = list(unique_paraphrases)\n",
    "        return final_result\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Handle unexpected errors and return a default result\n",
    "        print(f\"Error during paraphrase generation: {e}\")\n",
    "        return {\n",
    "            'original_sentence': text,\n",
    "            'rephrased': []\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "e1ca7bea-6d32-4552-9394-eb2651af0ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(df, system_prompt, client, n=10):\n",
    "    \n",
    "    # Define a wrapper function to process each row with openai_paraphrase_generation\n",
    "    def process_response(row):\n",
    "        response = openai_paraphrase_generation(row['text'], system_prompt, client, n=n)\n",
    "        original_sentence = response.get('original_sentence', '')\n",
    "        rephrased = response.get('rephrased', [])\n",
    "        return original_sentence, rephrased\n",
    "\n",
    "    # Apply the processing function to each row and unpack the results into new columns\n",
    "    df['original_sentence'], df['rephrased'] = zip(*df.apply(process_response, axis=1))\n",
    "    \n",
    "    # Select relevant columns\n",
    "    df = df[['doc_id', 'chunk_id', 'original_sentence', 'rephrased']]\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "6bace01e-4e43-4132-97bb-dfab4a8c1cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_by_doc_id(df, system_prompt, client, save_loc=batch_complete_loc, n=10, delay=1):\n",
    "\n",
    "    df['custom_id'] = df['doc_id'].astype(str) + '_' + df['chunk_id'].astype(str)\n",
    "    \n",
    "    # Group by doc_id to process each document individually\n",
    "    grouped = df.groupby('doc_id')\n",
    "    \n",
    "    for doc_id, group in grouped:\n",
    "        print(f\"Processing doc_id: {doc_id}\")\n",
    "        \n",
    "        # Initialize a list to collect expanded rows for this document\n",
    "        expanded_rows = []\n",
    "        \n",
    "        for _, row in group.iterrows():\n",
    "            try:\n",
    "                # Generate paraphrases for each row\n",
    "                response = openai_paraphrase_generation(row['text'], system_prompt, client, n=n)\n",
    "                original_sentence = response.get('original_sentence', row['text'])  # Default to text if no response\n",
    "                rephrased_sentences = response.get('rephrased', [])\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing row {row['custom_id']}: {e}\")\n",
    "                original_sentence = row['text']\n",
    "                rephrased_sentences = []\n",
    "            \n",
    "            # Add one row per rephrased sentence\n",
    "            for rephrased in rephrased_sentences:\n",
    "                expanded_rows.append({\n",
    "                    'doc_id': row['doc_id'],\n",
    "                    'chunk_id': row['chunk_id'],\n",
    "                    'original': original_sentence,\n",
    "                    'rephrased': rephrased\n",
    "                })\n",
    "\n",
    "            print(f\"    Completed chunk_id: {row['chunk_id']} for doc_id: {doc_id}\")\n",
    "\n",
    "            # Optional delay between API calls\n",
    "            time.sleep(delay)\n",
    "        \n",
    "        # Create a DataFrame for the current doc_id\n",
    "        doc_df = pd.DataFrame(expanded_rows)\n",
    "        \n",
    "        # Save the results to a JSONL file\n",
    "        save_path = f\"{save_loc}{doc_id}.jsonl\"\n",
    "        try:\n",
    "            write_jsonl(doc_df, save_path)\n",
    "            print(f\"Saved results for doc_id: {doc_id} to {save_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving doc_id: {doc_id} to {save_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "dec9e655-06e1-443e-981e-8b9d0267cd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_by_doc_id(df, system_prompt, client, save_loc=batch_complete_loc, n=10, delay=1):\n",
    "    \n",
    "    df['custom_id'] = df['doc_id'].astype(str) + '_' + df['chunk_id'].astype(str)\n",
    "    \n",
    "    # Group by doc_id to process each document individually\n",
    "    grouped = df.groupby('doc_id')\n",
    "    \n",
    "    for doc_id, group in grouped:\n",
    "        print(f\"Processing doc_id: {doc_id}\")\n",
    "        \n",
    "        # Initialize a list to collect expanded rows for this document\n",
    "        expanded_rows = []\n",
    "        \n",
    "        # Get total chunks for progress tracking\n",
    "        total_chunks = len(group)\n",
    "        \n",
    "        for i, (_, row) in enumerate(group.iterrows(), start=1):  # `i` starts at 1 for 1-based indexing\n",
    "            print(f\"    Processing chunk {i} out of {total_chunks} for doc_id: {doc_id}\")\n",
    "            try:\n",
    "                # Generate paraphrases for each row\n",
    "                response = openai_paraphrase_generation(row['text'], system_prompt, client, n=n)\n",
    "                original_sentence = response.get('original_sentence', row['text'])  # Default to text if no response\n",
    "                rephrased_sentences = response.get('rephrased', [])\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing row {row['custom_id']}: {e}\")\n",
    "                original_sentence = row['text']\n",
    "                rephrased_sentences = []\n",
    "            \n",
    "            # Add one row per rephrased sentence\n",
    "            for rephrased in rephrased_sentences:\n",
    "                expanded_rows.append({\n",
    "                    'doc_id': row['doc_id'],\n",
    "                    'chunk_id': row['chunk_id'],\n",
    "                    'original': original_sentence,\n",
    "                    'rephrased': rephrased\n",
    "                })\n",
    "            \n",
    "            # Optional delay between API calls\n",
    "            time.sleep(delay)\n",
    "        \n",
    "        # Create a DataFrame for the current doc_id\n",
    "        doc_df = pd.DataFrame(expanded_rows)\n",
    "        \n",
    "        # Save the results to a JSONL file\n",
    "        save_path = f\"{save_loc}{doc_id}.jsonl\"\n",
    "        try:\n",
    "            write_jsonl(doc_df, save_path)\n",
    "            print(f\"Saved results for doc_id: {doc_id} to {save_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving doc_id: {doc_id} to {save_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "77744c6f-e6c1-4946-9c63-5834f329308f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing doc_id: batch_jeff_skilling_mail_4\n",
      "    Processing chunk 1 out of 28 for doc_id: batch_jeff_skilling_mail_4\n",
      "    Processing chunk 2 out of 28 for doc_id: batch_jeff_skilling_mail_4\n",
      "    Processing chunk 3 out of 28 for doc_id: batch_jeff_skilling_mail_4\n",
      "    Processing chunk 4 out of 28 for doc_id: batch_jeff_skilling_mail_4\n",
      "    Processing chunk 5 out of 28 for doc_id: batch_jeff_skilling_mail_4\n",
      "    Processing chunk 6 out of 28 for doc_id: batch_jeff_skilling_mail_4\n",
      "    Processing chunk 7 out of 28 for doc_id: batch_jeff_skilling_mail_4\n",
      "    Processing chunk 8 out of 28 for doc_id: batch_jeff_skilling_mail_4\n",
      "    Processing chunk 9 out of 28 for doc_id: batch_jeff_skilling_mail_4\n",
      "    Processing chunk 10 out of 28 for doc_id: batch_jeff_skilling_mail_4\n",
      "    Processing chunk 11 out of 28 for doc_id: batch_jeff_skilling_mail_4\n",
      "    Processing chunk 12 out of 28 for doc_id: batch_jeff_skilling_mail_4\n",
      "    Processing chunk 13 out of 28 for doc_id: batch_jeff_skilling_mail_4\n",
      "    Processing chunk 14 out of 28 for doc_id: batch_jeff_skilling_mail_4\n",
      "    Processing chunk 15 out of 28 for doc_id: batch_jeff_skilling_mail_4\n",
      "    Processing chunk 16 out of 28 for doc_id: batch_jeff_skilling_mail_4\n",
      "    Processing chunk 17 out of 28 for doc_id: batch_jeff_skilling_mail_4\n",
      "    Processing chunk 18 out of 28 for doc_id: batch_jeff_skilling_mail_4\n",
      "    Processing chunk 19 out of 28 for doc_id: batch_jeff_skilling_mail_4\n",
      "    Processing chunk 20 out of 28 for doc_id: batch_jeff_skilling_mail_4\n",
      "    Processing chunk 21 out of 28 for doc_id: batch_jeff_skilling_mail_4\n",
      "    Processing chunk 22 out of 28 for doc_id: batch_jeff_skilling_mail_4\n",
      "    Processing chunk 23 out of 28 for doc_id: batch_jeff_skilling_mail_4\n",
      "    Processing chunk 24 out of 28 for doc_id: batch_jeff_skilling_mail_4\n",
      "    Processing chunk 25 out of 28 for doc_id: batch_jeff_skilling_mail_4\n",
      "    Processing chunk 26 out of 28 for doc_id: batch_jeff_skilling_mail_4\n",
      "    Processing chunk 27 out of 28 for doc_id: batch_jeff_skilling_mail_4\n",
      "    Processing chunk 28 out of 28 for doc_id: batch_jeff_skilling_mail_4\n",
      "Saved results for doc_id: batch_jeff_skilling_mail_4 to /Users/user/Documents/temp_datasets/author_verification/training/Enron/batch_jeff_skilling_mail_4.jsonl\n"
     ]
    }
   ],
   "source": [
    "process_and_save_by_doc_id(df, system_prompt, client, save_loc=temp_local_location, n=10, delay=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paraphrase_llm",
   "language": "python",
   "name": "paraphrase_llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
