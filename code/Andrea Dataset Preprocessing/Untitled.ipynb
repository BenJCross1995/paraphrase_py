{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "43f1ce36-d18f-4d77-8835-71a90e0202c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "eef4ccda-bf5c-4e8c-8e6b-96bfef555358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA version: 12.4\n",
      "GPU device: NVIDIA GeForce GTX 1660 Ti\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"GPU device:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b077958f-98af-4e96-bc82-faa7c9b8c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_base_loc = \"//bc_nas_storage/BCross/\"\n",
    "mac_base_loc = \"/Volumes/BCross/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "baf0c29e-34ca-47dc-8ca7-4a130869d79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Windows PC\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(windows_base_loc):\n",
    "    base_loc = windows_base_loc\n",
    "    print(\"Using Windows PC\")\n",
    "elif os.path.exists(mac_base_loc):\n",
    "    base_loc = mac_base_loc\n",
    "    print(\"Using Mac\")\n",
    "else:\n",
    "    print(\"Check location exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3131a6c0-2818-4dcf-88e6-1f8de4bc661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f\"{base_loc}models/Qwen 2.5/Qwen2.5-0.5B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3cce6f74-77c4-4aad-8315-f1721c3dbda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fdb5cb1-4a63-4a22-bd8d-7cf837162cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conditional_probabilities(text, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Given a text, model, and tokenizer, return a dictionary with:\n",
    "    - List of all conditional probabilities.\n",
    "    - A dictionary mapping each token to its conditional probability.\n",
    "    - A list of full probability distributions for each token.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text to analyze.\n",
    "        model (PreTrainedModel): The language model to use for predictions.\n",
    "        tokenizer (PreTrainedTokenizer): The tokenizer corresponding to the model.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing the conditional probabilities as a list,\n",
    "              a dictionary of token probabilities, and a list of full distributions.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Tokenize the input text\n",
    "    input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "\n",
    "    # Initialize the dictionary to store the results\n",
    "    conditional_probs = {\n",
    "        \"conditional_probabilities\": [],  # List of conditional probabilities\n",
    "        \"token_probabilities\": {},       # Dictionary of token-to-probability mappings\n",
    "        \"full_distributions\": []         # List of full probability distributions for each token\n",
    "    }\n",
    "\n",
    "    # Compute the probability for the first token\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Compute the probability of the first token given no prior context\n",
    "    first_token_prob = F.softmax(logits[:, 0, :], dim=-1).max().item()\n",
    "    \n",
    "    # Store the first token's probability (usually context-independent)\n",
    "    first_token = tokenizer.decode([input_ids[0, 0]])\n",
    "    conditional_probs[\"conditional_probabilities\"].append(first_token_prob)\n",
    "    conditional_probs[\"token_probabilities\"][first_token] = first_token_prob\n",
    "\n",
    "    # Store the full probability distribution for the first token\n",
    "    full_distribution_first_token = F.softmax(logits[:, 0, :], dim=-1).squeeze().cpu().numpy()\n",
    "    conditional_probs[\"full_distributions\"].append(full_distribution_first_token)\n",
    "\n",
    "    # Iterate through each token in the sequence starting from the second token\n",
    "    for i in range(1, input_ids.size(1)):\n",
    "        prefix = input_ids[:, :i]  # Context: all tokens before the current one\n",
    "        next_token_id = input_ids[0, i]  # Current token to predict\n",
    "\n",
    "        # Get logits for the context\n",
    "        with torch.no_grad():\n",
    "            outputs = model(prefix)\n",
    "            logits = outputs.logits\n",
    "\n",
    "        # Compute probabilities for the next token\n",
    "        log_probs = F.log_softmax(logits[:, -1, :], dim=-1)  # Log probs for last step\n",
    "        prob_distribution = log_probs.exp()  # Convert log probs to probabilities\n",
    "\n",
    "        # Extract the current token's probability\n",
    "        next_token_prob = prob_distribution[0, next_token_id].item()\n",
    "\n",
    "        # Decode the full distribution for readability\n",
    "        full_distribution = prob_distribution.squeeze().cpu().numpy()\n",
    "\n",
    "        # Store the conditional probability and the full distribution\n",
    "        token = tokenizer.decode([next_token_id])\n",
    "        conditional_probs[\"conditional_probabilities\"].append(next_token_prob)\n",
    "        conditional_probs[\"token_probabilities\"][token] = next_token_prob\n",
    "        conditional_probs[\"full_distributions\"].append(full_distribution)\n",
    "\n",
    "    # Return the dictionary with both the list and the dictionary of probabilities\n",
    "    return conditional_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e747a615-6121-4eae-82a3-eaba8a3b1d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conditional_probabilities(text, model, tokenizer, \n",
    "                                   include_conditional_probabilities=True,\n",
    "                                   include_token_probabilities=True,\n",
    "                                   include_full_distributions=True):\n",
    "    \"\"\"\n",
    "    Given a text, model, and tokenizer, return a dictionary with:\n",
    "    - List of all conditional probabilities (optional).\n",
    "    - A dictionary mapping each token to its conditional probability (optional).\n",
    "    - A list of full probability distributions for each token (optional).\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text to analyze.\n",
    "        model (PreTrainedModel): The language model to use for predictions.\n",
    "        tokenizer (PreTrainedTokenizer): The tokenizer corresponding to the model.\n",
    "        include_conditional_probabilities (bool): Whether to include the list of conditional probabilities.\n",
    "        include_token_probabilities (bool): Whether to include the dictionary of token probabilities.\n",
    "        include_full_distributions (bool): Whether to include the list of full probability distributions.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing the conditional probabilities, token-to-probability mappings,\n",
    "              and full distributions based on the flags provided.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Tokenize the input text\n",
    "    input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "\n",
    "    # Initialize the dictionary to store the results\n",
    "    conditional_probs = {}\n",
    "\n",
    "    # Compute the probability for the first token\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Compute the probability of the first token given no prior context\n",
    "    first_token_prob = F.softmax(logits[:, 0, :], dim=-1).max().item()\n",
    "    \n",
    "    # Store the first token's probability (usually context-independent)\n",
    "    first_token = tokenizer.decode([input_ids[0, 0]])\n",
    "\n",
    "    # Add components to the dictionary if requested\n",
    "    if include_conditional_probabilities:\n",
    "        conditional_probs[\"conditional_probabilities\"] = [first_token_prob]\n",
    "    \n",
    "    if include_token_probabilities:\n",
    "        conditional_probs[\"token_probabilities\"] = {first_token: first_token_prob}\n",
    "\n",
    "    if include_full_distributions:\n",
    "        full_distribution_first_token = F.softmax(logits[:, 0, :], dim=-1).squeeze().cpu().numpy()\n",
    "        conditional_probs[\"full_distributions\"] = [full_distribution_first_token]\n",
    "\n",
    "    # Iterate through each token in the sequence starting from the second token\n",
    "    for i in range(1, input_ids.size(1)):\n",
    "        prefix = input_ids[:, :i]  # Context: all tokens before the current one\n",
    "        next_token_id = input_ids[0, i]  # Current token to predict\n",
    "\n",
    "        # Get logits for the context\n",
    "        with torch.no_grad():\n",
    "            outputs = model(prefix)\n",
    "            logits = outputs.logits\n",
    "\n",
    "        # Compute probabilities for the next token\n",
    "        log_probs = F.log_softmax(logits[:, -1, :], dim=-1)  # Log probs for last step\n",
    "        prob_distribution = log_probs.exp()  # Convert log probs to probabilities\n",
    "\n",
    "        # Extract the current token's probability\n",
    "        next_token_prob = prob_distribution[0, next_token_id].item()\n",
    "\n",
    "        # Decode the full distribution for readability\n",
    "        full_distribution = prob_distribution.squeeze().cpu().numpy()\n",
    "\n",
    "        # Store the conditional probability and the full distribution if requested\n",
    "        token = tokenizer.decode([next_token_id])\n",
    "\n",
    "        if include_conditional_probabilities:\n",
    "            conditional_probs[\"conditional_probabilities\"].append(next_token_prob)\n",
    "        \n",
    "        if include_token_probabilities:\n",
    "            conditional_probs[\"token_probabilities\"][token] = next_token_prob\n",
    "        \n",
    "        if include_full_distributions:\n",
    "            conditional_probs[\"full_distributions\"].append(full_distribution)\n",
    "\n",
    "    # Return the dictionary with the requested components\n",
    "    return conditional_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b0dc5b86-9918-4eae-a2a6-5a7d0663f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "def get_conditional_probabilities(known_text, unknown_text=None, model=None, tokenizer=None, \n",
    "                                   include_conditional_probabilities=True,\n",
    "                                   include_token_probabilities=True,\n",
    "                                   include_full_distributions=True,\n",
    "                                   return_as_probs=False):\n",
    "    \"\"\"\n",
    "    Given a known text and an optional unknown text, return a dictionary with:\n",
    "    - List of all conditional probabilities or log probabilities (optional).\n",
    "    - A dictionary mapping each token to its conditional probability or log probability (optional).\n",
    "    - A list of full probability or log probability distributions for each token (optional).\n",
    "    \n",
    "    Args:\n",
    "        known_text (str): The known input text to analyze.\n",
    "        unknown_text (str, optional): The unknown text to concatenate with known_text. Defaults to None.\n",
    "        model (PreTrainedModel, optional): The language model to use for predictions. Defaults to None.\n",
    "        tokenizer (PreTrainedTokenizer, optional): The tokenizer corresponding to the model. Defaults to None.\n",
    "        include_conditional_probabilities (bool): Whether to include the list of probabilities/log-probs.\n",
    "        include_token_probabilities (bool): Whether to include the dictionary of token probabilities/log-probs.\n",
    "        include_full_distributions (bool): Whether to include the list of full distributions (probs/log-probs).\n",
    "        return_as_probs (bool): Whether to return probabilities (True) or log-probabilities (False). Defaults to False.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing the selected components based on the flags provided.\n",
    "    \"\"\"\n",
    "    # Check for GPU availability\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Move model to GPU\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Tokenize the input text and move to GPU\n",
    "    known_input_ids = tokenizer.encode(known_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Concatenate known and unknown text if provided\n",
    "    if unknown_text:\n",
    "        unknown_input_ids = tokenizer.encode(unknown_text, return_tensors=\"pt\").to(device)\n",
    "        input_ids = torch.cat([known_input_ids, unknown_input_ids], dim=1)\n",
    "    else:\n",
    "        input_ids = known_input_ids\n",
    "\n",
    "    # Calculate known and unknown token offsets\n",
    "    known_token_count = known_input_ids.size(1)\n",
    "    total_token_count = input_ids.size(1)\n",
    "\n",
    "    # Initialize the dictionary to store the results\n",
    "    conditional_probs = {}\n",
    "\n",
    "    if include_conditional_probabilities:\n",
    "        conditional_probs[\"conditional_probabilities\"] = []\n",
    "    if include_token_probabilities:\n",
    "        conditional_probs[\"token_probabilities\"] = {}\n",
    "    if include_full_distributions:\n",
    "        conditional_probs[\"full_distributions\"] = []\n",
    "\n",
    "    # Compute probabilities for all tokens\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "        log_probs = F.log_softmax(outputs.logits, dim=-1)  # Log probs for all tokens\n",
    "        if return_as_probs:\n",
    "            probs = log_probs.exp()\n",
    "\n",
    "    # If unknown_text is provided, process only its tokens\n",
    "    start_index = known_token_count if unknown_text else 0\n",
    "\n",
    "    for i in range(start_index, total_token_count):\n",
    "        next_token_id = input_ids[0, i]\n",
    "        next_token_value = (probs if return_as_probs else log_probs)[0, i, next_token_id].item()\n",
    "        token = tokenizer.decode([next_token_id])\n",
    "\n",
    "        if include_conditional_probabilities:\n",
    "            conditional_probs[\"conditional_probabilities\"].append(next_token_value)\n",
    "        \n",
    "        if include_token_probabilities:\n",
    "            conditional_probs[\"token_probabilities\"][token] = next_token_value\n",
    "        \n",
    "        if include_full_distributions:\n",
    "            full_distribution = (probs if return_as_probs else log_probs)[0, i].cpu().numpy()\n",
    "            conditional_probs[\"full_distributions\"].append(full_distribution)\n",
    "\n",
    "    # Return the dictionary with the requested components\n",
    "    return conditional_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ee9f0661-2c98-44cb-8ae3-40ba4b355bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # For progress bar\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "def get_conditional_probabilities(known_text, unknown_text=None, model=None, tokenizer=None, \n",
    "                                   include_conditional_probabilities=True,\n",
    "                                   include_token_probabilities=True,\n",
    "                                   include_full_distributions=True,\n",
    "                                   return_as_probs=False):\n",
    "    \"\"\"\n",
    "    Given a known text and an optional unknown text, return a dictionary with:\n",
    "    - List of all conditional probabilities or log probabilities (optional).\n",
    "    - A dictionary mapping each token to its conditional probability or log probability (optional).\n",
    "    - A list of full probability or log probability distributions for each token (optional).\n",
    "    \n",
    "    Args:\n",
    "        known_text (str): The known input text to analyze.\n",
    "        unknown_text (str, optional): The unknown text to concatenate with known_text. Defaults to None.\n",
    "        model (PreTrainedModel, optional): The language model to use for predictions. Defaults to None.\n",
    "        tokenizer (PreTrainedTokenizer, optional): The tokenizer corresponding to the model. Defaults to None.\n",
    "        include_conditional_probabilities (bool): Whether to include the list of probabilities/log-probs.\n",
    "        include_token_probabilities (bool): Whether to include the dictionary of token probabilities/log-probs.\n",
    "        include_full_distributions (bool): Whether to include the list of full distributions (probs/log-probs).\n",
    "        return_as_probs (bool): Whether to return probabilities (True) or log-probabilities (False). Defaults to False.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing the selected components based on the flags provided.\n",
    "    \"\"\"\n",
    "    # Check for GPU availability\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Move model to GPU\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Tokenize the input text and move to GPU\n",
    "    known_input_ids = tokenizer.encode(known_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Concatenate known and unknown text if provided\n",
    "    if unknown_text:\n",
    "        unknown_input_ids = tokenizer.encode(unknown_text, return_tensors=\"pt\").to(device)\n",
    "        input_ids = torch.cat([known_input_ids, unknown_input_ids], dim=1)\n",
    "    else:\n",
    "        input_ids = known_input_ids\n",
    "\n",
    "    # Calculate known and unknown token offsets\n",
    "    known_token_count = known_input_ids.size(1)\n",
    "    total_token_count = input_ids.size(1)\n",
    "\n",
    "    # Initialize the dictionary to store the results\n",
    "    conditional_probs = {}\n",
    "\n",
    "    if include_conditional_probabilities:\n",
    "        conditional_probs[\"conditional_probabilities\"] = []\n",
    "    if include_token_probabilities:\n",
    "        conditional_probs[\"token_probabilities\"] = {}\n",
    "    if include_full_distributions:\n",
    "        conditional_probs[\"full_distributions\"] = []\n",
    "\n",
    "    # Compute probabilities for all tokens\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "        log_probs = F.log_softmax(outputs.logits, dim=-1)  # Log probs for all tokens\n",
    "        if return_as_probs:\n",
    "            probs = log_probs.exp()\n",
    "\n",
    "    # If unknown_text is provided, process only its tokens\n",
    "    start_index = known_token_count if unknown_text else 0\n",
    "\n",
    "    for i in tqdm(range(start_index, total_token_count), desc=\"Processing tokens\"):\n",
    "        next_token_id = input_ids[0, i]\n",
    "        next_token_value = (probs if return_as_probs else log_probs)[0, i, next_token_id].item()\n",
    "        token = tokenizer.decode([next_token_id])\n",
    "\n",
    "        if include_conditional_probabilities:\n",
    "            conditional_probs[\"conditional_probabilities\"].append(next_token_value)\n",
    "        \n",
    "        if include_token_probabilities:\n",
    "            conditional_probs[\"token_probabilities\"][token] = next_token_value\n",
    "        \n",
    "        if include_full_distributions:\n",
    "            full_distribution = (probs if return_as_probs else log_probs)[0, i].cpu().numpy()\n",
    "            conditional_probs[\"full_distributions\"].append(full_distribution)\n",
    "\n",
    "    # Return the dictionary with the requested components\n",
    "    return conditional_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bccf3f6a-2f03-4db1-8508-24a7205d4623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Example input text\n",
    "text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "unknown_text = \"Then it jumps over your mum.\"\n",
    "\n",
    "# Call the function to get the conditional probabilities\n",
    "#conditional_probs = get_conditional_probabilities(text, unknown_text, model=model, tokenizer=tokenizer)\n",
    "conditional_probs = get_conditional_probabilities(text, model=model, tokenizer=tokenizer, return_as_probs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ab7b657c-5df8-4d22-bedb-c8bf5a4ca59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conditional_probabilities': [2.453970466831379e-07,\n",
       "  1.0851216103446859e-07,\n",
       "  1.7008306940624607e-07,\n",
       "  5.5850136959634256e-06,\n",
       "  1.0068577438460125e-07,\n",
       "  2.7807447622762993e-05,\n",
       "  3.0830833566142246e-05,\n",
       "  1.399473512719851e-05,\n",
       "  1.5797680816831416e-06,\n",
       "  4.125164210222465e-09],\n",
       " 'token_probabilities': {'The': 2.453970466831379e-07,\n",
       "  ' quick': 1.0851216103446859e-07,\n",
       "  ' brown': 1.7008306940624607e-07,\n",
       "  ' fox': 5.5850136959634256e-06,\n",
       "  ' jumps': 1.0068577438460125e-07,\n",
       "  ' over': 2.7807447622762993e-05,\n",
       "  ' the': 3.0830833566142246e-05,\n",
       "  ' lazy': 1.399473512719851e-05,\n",
       "  ' dog': 1.5797680816831416e-06,\n",
       "  '.': 4.125164210222465e-09},\n",
       " 'full_distributions': [array([4.2672150e-07, 7.7248828e-08, 2.3432511e-08, ..., 7.1411708e-09,\n",
       "         7.1398092e-09, 7.1412258e-09], dtype=float32),\n",
       "  array([1.1352657e-05, 3.8999551e-07, 2.3041113e-09, ..., 3.5843069e-12,\n",
       "         3.5850797e-12, 3.5849086e-12], dtype=float32),\n",
       "  array([1.8934730e-07, 9.8799694e-07, 3.2154337e-09, ..., 1.5735564e-12,\n",
       "         1.5738115e-12, 1.5734603e-12], dtype=float32),\n",
       "  array([2.1927974e-06, 1.7918035e-05, 4.5801625e-07, ..., 2.6662179e-12,\n",
       "         2.6664673e-12, 2.6662385e-12], dtype=float32),\n",
       "  array([1.6154608e-07, 6.7298834e-06, 5.4479807e-09, ..., 7.4969398e-13,\n",
       "         7.4938233e-13, 7.4955959e-13], dtype=float32),\n",
       "  array([1.0665901e-07, 1.0130572e-06, 7.7642409e-10, ..., 7.4636720e-12,\n",
       "         7.4684712e-12, 7.4633303e-12], dtype=float32),\n",
       "  array([3.7904147e-08, 1.2474364e-07, 4.2006709e-10, ..., 6.7296576e-12,\n",
       "         6.7318529e-12, 6.7306204e-12], dtype=float32),\n",
       "  array([3.5098910e-07, 1.6546634e-05, 1.5579131e-09, ..., 6.1255068e-12,\n",
       "         6.1215477e-12, 6.1251559e-12], dtype=float32),\n",
       "  array([7.7305696e-05, 3.7218037e-04, 1.7286012e-06, ..., 1.6246231e-10,\n",
       "         1.6256677e-10, 1.6247005e-10], dtype=float32),\n",
       "  array([8.7645326e-08, 6.3245037e-10, 7.8493017e-08, ..., 2.3437585e-10,\n",
       "         2.3441876e-10, 2.3438745e-10], dtype=float32)]}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b81ea524-290f-43c7-b46d-34114314046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(location, exact_name=None):\n",
    "    \"\"\"\n",
    "    Lists all files in the specified location, optionally filtering by file type.\n",
    "\n",
    "    Parameters:\n",
    "    - location (str): The directory to search in.\n",
    "    - file_type (str, optional): The file extension to filter by (e.g., \".jsonl\").\n",
    "\n",
    "    Returns:\n",
    "    - list: A list of full file paths that match the file type.\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store file paths\n",
    "    file_list = []\n",
    "    \n",
    "    # Walk through the directory\n",
    "    for root, dirs, files in os.walk(location):\n",
    "        for file_name in files:\n",
    "            # Match exact file name if specified\n",
    "            if exact_name and file_name == exact_name:\n",
    "                file_list.append(os.path.join(root, file_name))\n",
    "            # If no exact_name is provided, include all files\n",
    "            elif not exact_name:\n",
    "                file_list.append(os.path.join(root, file_name))\n",
    "    \n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b2f6721e-9817-40fb-83f7-8711eccf8b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl(file_path):\n",
    "    \"\"\"\n",
    "    Reads a JSONL file and converts it into a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: Path to the JSONL file to read.\n",
    "\n",
    "    Returns:\n",
    "    - A pandas DataFrame containing the data from the JSONL file.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Parse the line as JSON\n",
    "            parsed_line = json.loads(line)\n",
    "            # If the line is a single-element list, extract the first element\n",
    "            if isinstance(parsed_line, list) and len(parsed_line) == 1:\n",
    "                data.append(parsed_line[0])\n",
    "            else:\n",
    "                data.append(parsed_line)\n",
    "    \n",
    "    # Convert to a DataFrame\n",
    "    data = pd.DataFrame(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9d613170-7bdd-4a6f-8f66-ce3ad02d0686",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_base_loc = f\"{base_loc}datasets/author_verification\"\n",
    "\n",
    "test_or_training = \"test\"\n",
    "\n",
    "base_file_type_loc = f\"{dataset_base_loc}/{test_or_training}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2a3ab3e1-6cd1-46b2-9de0-907636ad8dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = list_files(base_file_type_loc, \"known_raw.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "14e0fcff-66e1-469d-a646-6191361a67d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['//bc_nas_storage/BCross/datasets/author_verification/test/ACL\\\\known_raw.jsonl',\n",
       " '//bc_nas_storage/BCross/datasets/author_verification/test/All-the-news\\\\known_raw.jsonl',\n",
       " '//bc_nas_storage/BCross/datasets/author_verification/test/Amazon\\\\known_raw.jsonl',\n",
       " '//bc_nas_storage/BCross/datasets/author_verification/test/Enron\\\\known_raw.jsonl',\n",
       " '//bc_nas_storage/BCross/datasets/author_verification/test/IMDB\\\\known_raw.jsonl',\n",
       " \"//bc_nas_storage/BCross/datasets/author_verification/test/Koppel's Blogs\\\\known_raw.jsonl\",\n",
       " '//bc_nas_storage/BCross/datasets/author_verification/test/Perverted Justice\\\\known_raw.jsonl',\n",
       " '//bc_nas_storage/BCross/datasets/author_verification/test/Reddit\\\\known_raw.jsonl',\n",
       " '//bc_nas_storage/BCross/datasets/author_verification/test/StackExchange\\\\known_raw.jsonl',\n",
       " '//bc_nas_storage/BCross/datasets/author_verification/test/The Apricity\\\\known_raw.jsonl',\n",
       " '//bc_nas_storage/BCross/datasets/author_verification/test/The Telegraph\\\\known_raw.jsonl',\n",
       " '//bc_nas_storage/BCross/datasets/author_verification/test/TripAdvisor\\\\known_raw.jsonl',\n",
       " '//bc_nas_storage/BCross/datasets/author_verification/test/Wiki\\\\known_raw.jsonl',\n",
       " '//bc_nas_storage/BCross/datasets/author_verification/test/Yelp\\\\known_raw.jsonl']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "66fbd3ec-3ce7-4114-83ee-e6e8eea4d316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'//bc_nas_storage/BCross/datasets/author_verification/test/IMDB\\\\known_raw.jsonl'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c32e8fab-605d-4a75-81c1-d3cdb78e993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_jsonl(file_list[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6bc0c0b1-e226-48ae-86d7-b590b1f2e760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>text</th>\n",
       "      <th>corpus</th>\n",
       "      <th>author</th>\n",
       "      <th>texttype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000497_known</td>\n",
       "      <td>I liked this movie. I did have a nitpick thoug...</td>\n",
       "      <td>IMDB</td>\n",
       "      <td>1000497</td>\n",
       "      <td>known</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10044932_known</td>\n",
       "      <td>That's the story, right? Going back to the day...</td>\n",
       "      <td>IMDB</td>\n",
       "      <td>10044932</td>\n",
       "      <td>known</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10074111_known</td>\n",
       "      <td>I was as excited as a young kid at Christmas w...</td>\n",
       "      <td>IMDB</td>\n",
       "      <td>10074111</td>\n",
       "      <td>known</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10118021_known</td>\n",
       "      <td>Picture it... it's a Saturday night, and there...</td>\n",
       "      <td>IMDB</td>\n",
       "      <td>10118021</td>\n",
       "      <td>known</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10125890_known</td>\n",
       "      <td>This film is a definite 10 for me. I have alwa...</td>\n",
       "      <td>IMDB</td>\n",
       "      <td>10125890</td>\n",
       "      <td>known</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>994570_known</td>\n",
       "      <td>What starts out as an art house experiment tur...</td>\n",
       "      <td>IMDB</td>\n",
       "      <td>994570</td>\n",
       "      <td>known</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>9945874_known</td>\n",
       "      <td>I would not spend 1 minute in a room with some...</td>\n",
       "      <td>IMDB</td>\n",
       "      <td>9945874</td>\n",
       "      <td>known</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>994939_known</td>\n",
       "      <td>This film is pretty bad even by Woody Allen's ...</td>\n",
       "      <td>IMDB</td>\n",
       "      <td>994939</td>\n",
       "      <td>known</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>9975201_known</td>\n",
       "      <td>As far as sports movie go this is a great one....</td>\n",
       "      <td>IMDB</td>\n",
       "      <td>9975201</td>\n",
       "      <td>known</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>998284_known</td>\n",
       "      <td>When I first watched this pilot episode back i...</td>\n",
       "      <td>IMDB</td>\n",
       "      <td>998284</td>\n",
       "      <td>known</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>955 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             doc_id                                               text corpus  \\\n",
       "0     1000497_known  I liked this movie. I did have a nitpick thoug...   IMDB   \n",
       "1    10044932_known  That's the story, right? Going back to the day...   IMDB   \n",
       "2    10074111_known  I was as excited as a young kid at Christmas w...   IMDB   \n",
       "3    10118021_known  Picture it... it's a Saturday night, and there...   IMDB   \n",
       "4    10125890_known  This film is a definite 10 for me. I have alwa...   IMDB   \n",
       "..              ...                                                ...    ...   \n",
       "950    994570_known  What starts out as an art house experiment tur...   IMDB   \n",
       "951   9945874_known  I would not spend 1 minute in a room with some...   IMDB   \n",
       "952    994939_known  This film is pretty bad even by Woody Allen's ...   IMDB   \n",
       "953   9975201_known  As far as sports movie go this is a great one....   IMDB   \n",
       "954    998284_known  When I first watched this pilot episode back i...   IMDB   \n",
       "\n",
       "       author texttype  \n",
       "0     1000497    known  \n",
       "1    10044932    known  \n",
       "2    10074111    known  \n",
       "3    10118021    known  \n",
       "4    10125890    known  \n",
       "..        ...      ...  \n",
       "950    994570    known  \n",
       "951   9945874    known  \n",
       "952    994939    known  \n",
       "953   9975201    known  \n",
       "954    998284    known  \n",
       "\n",
       "[955 rows x 5 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5bf8a1c0-d8ac-4b6a-a863-76ab6b011379",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "84a9118a-23d1-4ecc-b28e-6c222cc256f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I liked this movie. I did have a nitpick though, I don\\'t like nor see the need for the foolish russian accented english most of the actors used. Either speak Russian and subtitle it for me (not going to happen with a Hollywood movie) or speak just english. Adding a poorly done accent as if the characters spoke english with bad accents back in the day in the Motherland is not adding much in the way of atmosphere. I think the movies that have handled foreign settings best run it in the native tongue of the setting, then have a sort of magical transition into english as if the audience has just gained fluency in the language and now doesn\\'t notice that it\\'s listening to a movie in another language other than english. I think u571 handled the german that way. Over all the movie is fine, what big hearts those guys had who went into the reactor space to save their crew and their ship. Some gave all so that others may live, and that\\'s a tearjerker and heroism no matter what nation you\\'re from. Drugs are bad, but the war on drugs is bad too, rehab works better than prisons. Money corrupts. There I just saved you $7. 50 and about three hours. I was hoping that they would tie together all these great actors\\' performances into something fascinating, instead I got a lecture. Note to the director: We are not all stupid. We don\\'t need you to tell us this. Package this movie in a primer for incoming Congressmen, and leave the rest of America alone. The real victim in all this is Catherine Zeta-Jones-Douglas\\' unborn child, because after all he/ she didn\\'t get a choice to partake in such a poor film. If this wins an Oscar I\\'m moving to Europe for the next four years with Alec Baldwin. The bright spots in this film were the camera and lighting work. Bravo to those involved. Yeah I laughed out loud three times total. \"\\' Suicidal?\\',\\' Only in the mornings.\\' \"; \" Don\\'t turn up in Newport Beach trying to by a 100, 000 dollar car. \" And one other time, but I can\\'t remember when that was. The Newport Beach line is classic, a sly reference to the kidnapping a few years ago of the former Bellagio owner\\'s daughter, wherein they paid the ransom, but the kidnappers got caught in So. Cal., trying to buy a Ferrari for cash. This line flew way over the heads of the audience in the showing I saw. And damn we were in Reno, Nevada where the kidnapping made pretty big news. But then the audience was laughing and having a good ole time thoughout the rest of this movie. Both these facts lead me to believe that the audience was lobotomized. It\\'s amazing in a movie with so many actors having tremendous on-screen chemistry, that none of it shows here. The chemistry of this movie is nil, assign a number from 1-10 to whichever actor in this film, epitomizes charisma and chemistry for you, then divide that number by 11. That should give you an idea of how bland this film and it\\'s acting performances. If you like this movie, it\\'s my guess that you are incapable of long division and something as complex as dividing by eleven. Make your appointment with the brain surgeon and get your lobotomy done pronto. This movie is horrible. It\\'s just lame lame lame. I\\'ve never seen so many cliches in a movie before, it\\'s just plain dumb. And since the war movie revivial this movie can\\'t compete with the worst of them, I found The Thin Red Line a better movie than this POS. This movie would have been better off to just leave the bodyguards out of it, and been about the Navajo themselves. This movie is strictly must miss fare.'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2a988d42-334f-4e3a-aca1-74eec6bf3e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_text = df.iloc[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "edc1bb14-11bd-4703-8de9-26a133ff5ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'That\\'s the story, right? Going back to the days of \" China Town \" with Jack Nicholson chasing lead after lead, turning corners left and right, only to find more corners. Who\\'s duping who? We don\\'t know until the very end in this fast-paced, hipster lingo drenched wild revival of the classic Black and White Film Noir. Joseph Gordon-Levitt (yes, the kid from Third Rock) is a brilliant hero/ foil as Brendan, the bitingly dry, quick-witted, scrappy and yet reluctant detective trying to walk his way through a web of lies, more lies, murder and lots of missing drugs. His character is bright, he can read a situation like a psychic on crack, turn things to his favor in seconds and play people as deftly as he is ultimately played himself.... And he can take a punch. The plot turns this way, then that, keeping you constantly guessing as to where it will take you next. As soon as you think you know what\\'s going on, you don\\'t. Nora Zehetner is a beautiful and beguiling femme fatale. \" The Brian \" (Matt O\\'Leary), who is constantly feeding Brendan his facts and keeping him on track, knows his stuff but never let\\'s you know how. Rian Johnson has written an amazing script and directed it into a whirlwind experience of near misses, painful betrayal and love/ love lost. The lingo takes a second to catch. I\\'m reminded of Swingers, had it been as thrilling as it was funny. The words fall into place and give the film a slick, quick delivery like the best exchanges between Bogart and Bergman, Alan Ladd and Veronica Lake. Take all that and drop it into a dark, starkly brutal modern world... In a high school, of all places. There\\'s even some quirky humor thrown in, though most of the laughs from the audience were really nervous release from all the tension built into the story. A must see. Sorry folks, but the film just does not live up to expectations. Perhaps a more appropriate title would have been \" Superman Comes Back, Kinda. \" While Brandon Routh is a great new Superman (taking more than a few queues from Christopher Reeve) Kate Bosworth is awful. I don\\'t care for her Lois Lane at all, she\\'s lost the edgy, strong mindedness that Margot Kidder gave Lois nearly 20 yrs ago. Some is due to her bad acting, but some can be blamed on a bad character in a lack-luster script. At one point, Lois has to ask her husband and child (yes, Lois is now domesticated) how she will get into a highly secured area. HUH? Why would Lois Lane ask anyone? She would just do it! Bosworth and Routh have the chemistry of a wet sponge sitting on a half-filled colostomy bag. And sadly, although Routh has aptly captured both the nerdy goof in Clark Kent and the Man of Steel in Superman, he has the fewest lines in the entire film! Both Lois (unfortunately) and Lex have more lines. Now that I think about it, perhaps the title should have been: \" Lois Lame and Lex Luther in Superman Comes Back, Kinda. \" The early special effects are rubbery (think the first Spiderman movie), the plot slows to a stand-still an hour and 15 minutes in, and the story is just plain lame. Kevin Spacey and Parker Posey are good, but seeing James Marsden (Cyclops from X-Men) playing Lois\\' husband is too distracting. I kept thinking, when is Cyclops going to join in and help fight evil? Two hours into this 150 minute pile of crap I was clawing to get out of the theater. The end is lame, all the new tricks Superman has are silly, the worst part being that somehow Kryptonite doesn\\'t even seem to affect Superman anymore. Well, it does, but completely randomly. One minute Superman is devastated by it, the next he saves the entire world with a chunk of it stuck INSIDE him! WTF?!? Also, much of the film revolves around the magic crystals that traveled with Superman from his home planet, but the dialogue surrounding them is so hokey, I feel like any moment some Gypsy medium will pop out of nowhere to start reading fortunes. It\\'s\\' Crystal this\\' and \" Crystal that\\' the entire film. Ugh... Mimicking a problem common to nearly all blockbusters today, Superman Returns is too long. The first hour is OK. It starts slow, but gives a good amount of action early on. The last hour and a half could have been condensed into 45 minutes, and the film wouldn\\'t have been quite so unbearable. Don\\'t even get me started on Superman and Lois\\' romantic \" Can you read my mind \" flight around Metropolis. I wanted to puke the entire ten minutes they were on screen together. SPOILER WARNING: I don\\'t give away too much, but some plot info will follow... Other problems in the film: Again, the meteorite that Lex uses to extract Kryptonite from lands in Addis Ababa just as it did in the 1978 film, which is weird and stupid. Superman has been away for five years (I think, though exactly how long is not quite clear) at the opening of the film to visit the ruins of Krypton, but we never hear more than two lines about his time there. Plus, he returns to Earth in another star-probe and lands in the same field he originally did as a child AND is found by his mom. Again, this makes no sense. Why did he need a probe? How did he reach the remains of Krypton in deep space? It took him 2. 5 years (doing the math) to get there (and he can fly near the speed of light according to this movie), so wouldn\\'t he need a space-ship to go so far? After all, if he traveled too far from Earth\\'s yellow sun, wouldn\\'t he lose his powers and die? Towards the end, Superman is put in a coma, but seems to wake from it randomly. Neither a kiss from Lois nor their son (yes, he had a semi-super-son with her) wakes him, but the obvious cure would have been to have the sun hit his skin. Earlier, the movie made a point of showing Superman \" charging up \" with sunlight, so why didn\\'t the script use that same device to wake him from a coma. And of course, Superman and Lois\\' son has (unpredictable) super powers, but how could he have conceived a child? As argued in many nerd groups and pulp comedies, wouldn\\'t his super sperm have killed Lois? And if their child was conceived while he was a mortal man (supposing the crystal chamber in Superman II removed his powers first), why does the kid have powers at all? And if Superman has only been gone 5 years, how is this kid somewhere around the age of 6 or 7? Nine months of pregnancy would put his age at four at the most. Finally, the whole movie borrows too much from the 1978 version with Christopher Reeve. Lex is again trying to create a devastating real-estate deal that kills billions of people until Kitty (Parker Posey) again finds love in Superman and partially foils his plot. Add in the Addis Ababa meteor, the star-probe, Superman\\'s mom and you\\'ve got a film that wants to be the 1978 classic, but falls woefully short. Don\\'t waste your time. Get this on DVD. This film is of the worst types of Hollywood films, historical enactments that trivialize tragic events by glossing over the human element while barely paying lip-service to the dead and loosely tying together history and hearsay with clichÃ©d dialog and the worn-out conventions of cheap action-thrillers. It\\'s no wonder MGM tried to burn-off this stinker at the end of the summer movie season, long before the more vital Holiday box office. I saw this in limited release in LA... at $12, it was a rip-off. Terrence Howard is mediocre at best. He lacks both the charisma and power to carry this film, which is awkwardly patched together with his clumsy and lifeless narration. Jesse Eisenberg is awful. It\\'s clear he either got this role by pulling a fortune from a Cracker Jack box or by being the nephew of an important Hollywood producer. This possibility is only more pathetic considering his character is exactly that: a greenhorn thrust into the action by an overbearing father high-up in the network he works for. His incessant blinking, acting through his eyes and pour delivery made me want to laugh. Richard Gere\\'s performance is uneven and his character never appears quite as conflicted as the script would have you believe. Which brings us to the heart of this piece of Hollywood clap, the pathetic excuse for a script by Richard Shepard, whose most notable work before this was directing for Ugly Betty and Criminal Minds. The pacing is awful. The film doesn\\'t truly start for over an hour, yet the most climatic scene of the whole film is setup and over in 45 seconds. No build-up, no tension. Throughout the painfully slow first 60 minutes there are numerous clunky scenes of ugly exposition that are forced down the viewer\\'s throat like so many pieces of un-masticated, Americanized, overcooked and soggy hot dog. I was almost sickened as the clichÃ©s rolled in one after another... Bar scenes where buddies pour drinks of the local liquor that is said (more than once, by the SAME character) to bring the Devil himself to the table... Dark characters in clandestine meetings striking a match to light a cigarette and illuminate their distrustful visage... Evil faces emerging from behind dirty plastic sheets hanging in dank basements... Triumphant characters telling bad guys, \" You\\'re going down, mother-fer! \"... CIA characters being more than happy to offer lectures about the \" gray areas \" their organization is forced to work in... Car chases on dark rainy nights... Long shots of foreboding looks from local villagers... Flashback after flashback of the same scenes of lust and libations with lost loves. Easily the worst of these unnecessary flashbacks was a single line of dialog that was spoken by a character barely 20 minutes before. I literally asked the film- out loud- \" Do you really think I\\'m so stupid that I needed to hear that line again? \" It\\'s sad to see such a good idea for a compelling story completely destroyed by an inexperienced, untalented writer/ director with too much power. Even if you can ignore all the cheap Hollywood tactics used to manufacture conflict, the script is riddled with so many other problems, it\\'s impossible to become engaged long enough to enjoy anything... Long exposition scenes that could have been summarized in one line... Horribly out-of-character dialog... Completely superfluous girlfriend characters vacationing in Greece... Manipulative scenes that are so convenient in the placement of characters and timing that they are completely unbelievable. Add in a musical score filled with sappy, over-sympathetic violin melodies that destroy every mood that the movie was so careful to ALMOST construct, and it seems as though the film\\'s intent is to dare you to become engaged. The worst part is that The Hunting Party tells a story of a tragic conflict and genocide that NEEDS to be heard by every American, but the film is so bad at conveying its message, it betrays the memory of those lives lost. This film will not reach the audience it should, it will not touch the hearts that need changing, it will not come close to opening enough minds to possibly prevent another genocide in the future. Even in its last moments, the film tries too hard to draw parallels and lay shame upon the inactive parties of the U. N. and the world\\'s indifference to atrocities... While flashing \" Where Are They Now? \" title cards of the various characters in the last shots of the movie, Richard Shepard (with great and smarmy righteousness), goes above and beyond any notion of responsible storytelling by adding the idea that the U. N. and other related countries were unable to find the masterminds of the genocide in Bosnia because they were perhaps too busy trying to find Osama Bin Laden. This suggestion is so ridiculous, it smacks the face of every life destroyed by this war. I cannot believe there are actually people out there who like this film. They are either completely delusional or rabid Jarmusch fans who are too enamored with him to be honest. Remember IMDb people, we\\'re rating the FILM here, not the director! Speaking of which... Broken Flowers wreaks of a self-absorbed \" artsy fartsy \" director determined to put EVERY LAST PIECE of film used into the final cut, whether the scene was needed or not. What results is an unbalanced, herky-jerky story of jumbled occurrences (with no arc or emotional build-up) and dozens of shots held waaaaay tooooooo looooonnngg.... I\\'m not exaggerating! I timed shots of unnecessary driving/ road footage that lasted for five minutes. There\\'s nearly a dozen three-minute shots of Bill Murray alone on screen (often referred to as \" reaction \" shots) that simply take way too long. Even if Bill Murray could convey enough emotion to engage me (he falls short the entire film), I would still get the point after thirty seconds. Add in dozens of unnecessary shots of Bill walking, staring into the rain or literally DOING NOTHING, and you can barely resist the urge to watch in 2x fast forward! Forget the imagery, forget the symbolism. NO amount of \" hidden meanings \" or symbols in this film can save it. \" Pink \" as a theme? You\\'ve got to be kidding! The girl in the flower shop and the last bouquet are supposed to mean something? I DON\\'T CARE- THE FILM IS GAWD AWFUL!!! Jim Jarmusch truly shows his inability to create an interesting, driven narrative that keeps the audience engaged. The story, while compelling, is thin at best, the characters are poorly developed and difficult to care about, and the overall pacing and dialogue are way off. There is no real resolution to the film, leaving the viewer to decide what happened after the credits roll on their own, only adding to the feeling of being cheated. The non-ending is intended to further the indie appeal of the piece, but simply strikes a sour note... \" I watched nearly two hours of movie for that?!? \" This entire film could have been condensed into an interesting 30 minute short, but unfortunately, there\\'s an entire hour and 40 minutes of long boring shots, poor dialogue and uninteresting characters. AVOID this film for your own good.'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d2792ca5-ab41-4bac-b657-822e67982451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "results = get_conditional_probabilities(text, model=model, tokenizer=tokenizer,\n",
    "                                        include_conditional_probabilities=False,\n",
    "                                        include_token_probabilities=True,\n",
    "                                        include_full_distributions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1048936e-4619-4349-a718-74b6db01a540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_probabilities': {'I': -15.330498695373535,\n",
       "  ' liked': -15.648114204406738,\n",
       "  ' this': -8.485764503479004,\n",
       "  ' movie': -9.267634391784668,\n",
       "  '.': -19.569072723388672,\n",
       "  ' I': -9.42391300201416,\n",
       "  ' did': -12.262917518615723,\n",
       "  ' have': -8.230719566345215,\n",
       "  ' a': -7.582947731018066,\n",
       "  ' nit': -9.63819408416748,\n",
       "  'pick': -15.85287857055664,\n",
       "  ' though': -8.325688362121582,\n",
       "  ',': -15.26042652130127,\n",
       "  ' don': -15.284036636352539,\n",
       "  \"'t\": -10.718945503234863,\n",
       "  ' like': -8.241666793823242,\n",
       "  ' nor': -7.776481628417969,\n",
       "  ' see': -10.934805870056152,\n",
       "  ' the': -7.041484832763672,\n",
       "  ' need': -10.339701652526855,\n",
       "  ' for': -11.636407852172852,\n",
       "  ' foolish': -8.614945411682129,\n",
       "  ' russian': -10.137657165527344,\n",
       "  ' acc': -14.771279335021973,\n",
       "  'ented': -20.407821655273438,\n",
       "  ' english': -11.122166633605957,\n",
       "  ' most': -7.9602179527282715,\n",
       "  ' of': -11.434659004211426,\n",
       "  ' actors': -9.97344970703125,\n",
       "  ' used': -8.000399589538574,\n",
       "  ' Either': -13.542048454284668,\n",
       "  ' speak': -9.355525970458984,\n",
       "  ' Russian': -9.901548385620117,\n",
       "  ' and': -9.267067909240723,\n",
       "  ' subtitle': -11.816842079162598,\n",
       "  ' it': -8.420504570007324,\n",
       "  ' me': -11.552865982055664,\n",
       "  ' (': -12.469255447387695,\n",
       "  'not': -17.512081146240234,\n",
       "  ' going': -12.089385986328125,\n",
       "  ' to': -9.580938339233398,\n",
       "  ' happen': -10.55321979522705,\n",
       "  ' with': -6.100633144378662,\n",
       "  ' Hollywood': -6.058262825012207,\n",
       "  ')': -18.616788864135742,\n",
       "  ' or': -9.432304382324219,\n",
       "  ' just': -6.927046298980713,\n",
       "  ' Adding': -17.218042373657227,\n",
       "  ' poorly': -11.905820846557617,\n",
       "  ' done': -9.44282341003418,\n",
       "  ' accent': -7.759871959686279,\n",
       "  ' as': -10.71447467803955,\n",
       "  ' if': -8.35526180267334,\n",
       "  ' characters': -8.822318077087402,\n",
       "  ' spoke': -9.810752868652344,\n",
       "  ' bad': -8.85759449005127,\n",
       "  ' accents': -11.836193084716797,\n",
       "  ' back': -7.75007438659668,\n",
       "  ' in': -8.866419792175293,\n",
       "  ' day': -13.074609756469727,\n",
       "  ' Mother': -7.069425582885742,\n",
       "  'land': -9.362630844116211,\n",
       "  ' is': -9.123339653015137,\n",
       "  ' not': -8.104520797729492,\n",
       "  ' adding': -11.690183639526367,\n",
       "  ' much': -7.691769599914551,\n",
       "  ' way': -7.064314365386963,\n",
       "  ' atmosphere': -12.17548942565918,\n",
       "  ' think': -10.959904670715332,\n",
       "  ' movies': -7.059975624084473,\n",
       "  ' that': -6.297030925750732,\n",
       "  ' handled': -13.477365493774414,\n",
       "  ' foreign': -7.867594242095947,\n",
       "  ' settings': -10.563407897949219,\n",
       "  ' best': -9.66894817352295,\n",
       "  ' run': -9.715717315673828,\n",
       "  ' native': -7.042148113250732,\n",
       "  ' tongue': -10.969528198242188,\n",
       "  ' setting': -8.587730407714844,\n",
       "  ' then': -8.358168601989746,\n",
       "  ' sort': -12.773176193237305,\n",
       "  ' magical': -8.390894889831543,\n",
       "  ' transition': -10.100028038024902,\n",
       "  ' into': -10.54775619506836,\n",
       "  ' audience': -7.601889610290527,\n",
       "  ' has': -12.018250465393066,\n",
       "  ' gained': -11.14518928527832,\n",
       "  ' flu': -11.411887168884277,\n",
       "  'ency': -16.220224380493164,\n",
       "  ' language': -9.540918350219727,\n",
       "  ' now': -9.533222198486328,\n",
       "  ' doesn': -14.651068687438965,\n",
       "  ' notice': -13.30095100402832,\n",
       "  \"'s\": -12.60587215423584,\n",
       "  ' listening': -13.05159854888916,\n",
       "  ' another': -10.545960426330566,\n",
       "  ' other': -6.578404426574707,\n",
       "  ' than': -10.305400848388672,\n",
       "  ' u': -9.668661117553711,\n",
       "  '5': -4.896471977233887,\n",
       "  '7': -3.3221750259399414,\n",
       "  '1': -6.630278587341309,\n",
       "  ' german': -4.353916645050049,\n",
       "  ' Over': -15.008376121520996,\n",
       "  ' all': -8.390176773071289,\n",
       "  ' fine': -11.456430435180664,\n",
       "  ' what': -7.692314147949219,\n",
       "  ' big': -9.936185836791992,\n",
       "  ' hearts': -9.321649551391602,\n",
       "  ' those': -7.851260662078857,\n",
       "  ' guys': -10.363810539245605,\n",
       "  ' had': -5.925432205200195,\n",
       "  ' who': -8.429095268249512,\n",
       "  ' went': -10.610611915588379,\n",
       "  ' reactor': -6.463802814483643,\n",
       "  ' space': -11.335536003112793,\n",
       "  ' save': -9.787393569946289,\n",
       "  ' their': -9.15169906616211,\n",
       "  ' crew': -8.721210479736328,\n",
       "  ' ship': -9.313936233520508,\n",
       "  ' Some': -15.574016571044922,\n",
       "  ' gave': -12.174966812133789,\n",
       "  ' so': -11.093549728393555,\n",
       "  ' others': -10.50812816619873,\n",
       "  ' may': -8.722028732299805,\n",
       "  ' live': -9.450706481933594,\n",
       "  ' tear': -8.407180786132812,\n",
       "  'jer': -16.360008239746094,\n",
       "  'ker': -18.625228881835938,\n",
       "  ' hero': -6.79802131652832,\n",
       "  'ism': -11.457589149475098,\n",
       "  ' no': -7.481428146362305,\n",
       "  ' matter': -16.351221084594727,\n",
       "  ' nation': -8.65424633026123,\n",
       "  ' you': -8.979005813598633,\n",
       "  \"'re\": -13.93489933013916,\n",
       "  ' from': -10.83641242980957,\n",
       "  ' Drugs': -14.203505516052246,\n",
       "  ' are': -8.641146659851074,\n",
       "  ' but': -9.895821571350098,\n",
       "  ' war': -10.77194595336914,\n",
       "  ' on': -8.402281761169434,\n",
       "  ' drugs': -9.934391021728516,\n",
       "  ' too': -6.911778450012207,\n",
       "  ' rehab': -7.172094345092773,\n",
       "  ' works': -10.965231895446777,\n",
       "  ' better': -9.633480072021484,\n",
       "  ' prisons': -8.298074722290039,\n",
       "  ' Money': -12.184844017028809,\n",
       "  ' corrupt': -7.806047439575195,\n",
       "  's': -11.846630096435547,\n",
       "  ' There': -15.84765338897705,\n",
       "  ' saved': -11.057698249816895,\n",
       "  ' $': -7.502547264099121,\n",
       "  ' ': -10.403192520141602,\n",
       "  '0': -2.3394980430603027,\n",
       "  ' about': -7.6124114990234375,\n",
       "  ' three': -12.165820121765137,\n",
       "  ' hours': -10.119322776794434,\n",
       "  ' was': -9.581700325012207,\n",
       "  ' hoping': -13.051373481750488,\n",
       "  ' they': -9.282085418701172,\n",
       "  ' would': -9.697443008422852,\n",
       "  ' tie': -10.959770202636719,\n",
       "  ' together': -8.260961532592773,\n",
       "  ' these': -10.032296180725098,\n",
       "  ' great': -9.041351318359375,\n",
       "  \"'\": -10.209638595581055,\n",
       "  ' performances': -12.843307495117188,\n",
       "  ' something': -7.064205169677734,\n",
       "  ' fascinating': -13.694194793701172,\n",
       "  ' instead': -8.925129890441895,\n",
       "  ' got': -10.84278678894043,\n",
       "  ' lecture': -7.505257606506348,\n",
       "  ' Note': -13.20075511932373,\n",
       "  ' director': -11.162057876586914,\n",
       "  ':': -12.914140701293945,\n",
       "  ' We': -14.942049026489258,\n",
       "  ' stupid': -7.949404239654541,\n",
       "  ' tell': -13.120125770568848,\n",
       "  ' us': -7.85026216506958,\n",
       "  ' Package': -11.913761138916016,\n",
       "  ' primer': -10.507654190063477,\n",
       "  ' incoming': -8.64517593383789,\n",
       "  ' Congress': -9.31732177734375,\n",
       "  'men': -13.356669425964355,\n",
       "  ' leave': -12.285848617553711,\n",
       "  ' rest': -15.61575984954834,\n",
       "  ' America': -9.958114624023438,\n",
       "  ' alone': -10.183995246887207,\n",
       "  ' The': -9.78700065612793,\n",
       "  ' real': -6.443232536315918,\n",
       "  ' victim': -10.265310287475586,\n",
       "  ' Catherine': -8.751237869262695,\n",
       "  ' Z': -16.490367889404297,\n",
       "  'eta': -21.13017463684082,\n",
       "  '-J': -17.473583221435547,\n",
       "  'ones': -15.768925666809082,\n",
       "  '-D': -10.344154357910156,\n",
       "  'ou': -15.473642349243164,\n",
       "  'glas': -15.74342155456543,\n",
       "  ' unborn': -5.614668846130371,\n",
       "  ' child': -8.720621109008789,\n",
       "  ' because': -8.026165008544922,\n",
       "  ' after': -9.759323120117188,\n",
       "  ' he': -5.418688774108887,\n",
       "  '/': -16.752107620239258,\n",
       "  ' she': -8.292424201965332,\n",
       "  ' didn': -15.469598770141602,\n",
       "  ' get': -10.304459571838379,\n",
       "  ' choice': -10.838006973266602,\n",
       "  ' part': -9.299720764160156,\n",
       "  'ake': -16.734952926635742,\n",
       "  ' such': -8.776798248291016,\n",
       "  ' poor': -7.762450218200684,\n",
       "  ' film': -8.889176368713379,\n",
       "  ' If': -12.992528915405273,\n",
       "  ' wins': -10.533854484558105,\n",
       "  ' an': -9.264185905456543,\n",
       "  ' Oscar': -7.781072616577148,\n",
       "  \"'m\": -13.789667129516602,\n",
       "  ' moving': -12.997849464416504,\n",
       "  ' Europe': -9.083730697631836,\n",
       "  ' next': -9.085240364074707,\n",
       "  ' four': -12.768930435180664,\n",
       "  ' years': -11.741007804870605,\n",
       "  ' Alec': -16.07722282409668,\n",
       "  ' Baldwin': -11.850475311279297,\n",
       "  ' bright': -7.570711612701416,\n",
       "  ' spots': -14.978139877319336,\n",
       "  ' were': -7.94371223449707,\n",
       "  ' camera': -8.944125175476074,\n",
       "  ' lighting': -8.18128490447998,\n",
       "  ' work': -11.923040390014648,\n",
       "  ' Bravo': -7.008067607879639,\n",
       "  ' involved': -10.383115768432617,\n",
       "  ' Yeah': -9.207587242126465,\n",
       "  ' laughed': -13.048445701599121,\n",
       "  ' out': -9.248504638671875,\n",
       "  ' loud': -10.093981742858887,\n",
       "  ' times': -12.427647590637207,\n",
       "  ' total': -11.044774055480957,\n",
       "  ' \"\\'': -10.550636291503906,\n",
       "  ' Su': -7.094512462615967,\n",
       "  'ic': -12.90833854675293,\n",
       "  'idal': -11.162245750427246,\n",
       "  '?': -10.061687469482422,\n",
       "  \"','\": -11.244084358215332,\n",
       "  ' Only': -11.758039474487305,\n",
       "  ' mornings': -12.691152572631836,\n",
       "  \".'\": -6.4512176513671875,\n",
       "  ' \";': -9.0081148147583,\n",
       "  ' \"': -2.203223466873169,\n",
       "  ' Don': -8.649073600769043,\n",
       "  ' turn': -9.595868110656738,\n",
       "  ' up': -8.727753639221191,\n",
       "  ' Newport': -10.996635437011719,\n",
       "  ' Beach': -8.846444129943848,\n",
       "  ' trying': -10.735045433044434,\n",
       "  ' by': -11.472443580627441,\n",
       "  ' dollar': -5.93903923034668,\n",
       "  ' car': -9.230240821838379,\n",
       "  ' And': -12.199440956115723,\n",
       "  ' one': -9.455297470092773,\n",
       "  ' time': -10.722298622131348,\n",
       "  ' can': -9.73874568939209,\n",
       "  ' remember': -10.380387306213379,\n",
       "  ' when': -7.870604991912842,\n",
       "  ' line': -7.936906337738037,\n",
       "  ' classic': -8.171799659729004,\n",
       "  ' s': -8.842220306396484,\n",
       "  'ly': -2.096867561340332,\n",
       "  ' reference': -12.885162353515625,\n",
       "  ' kidnapping': -10.04886245727539,\n",
       "  ' few': -10.868949890136719,\n",
       "  ' ago': -13.173758506774902,\n",
       "  ' former': -6.813880920410156,\n",
       "  ' Bell': -7.659248352050781,\n",
       "  'ag': -14.151519775390625,\n",
       "  'io': -15.505189895629883,\n",
       "  ' owner': -8.712577819824219,\n",
       "  ' daughter': -8.768774032592773,\n",
       "  ' wherein': -16.38146209716797,\n",
       "  ' paid': -11.17222785949707,\n",
       "  ' ransom': -7.896406650543213,\n",
       "  ' kidn': -14.688258171081543,\n",
       "  'appers': -19.540647506713867,\n",
       "  ' caught': -11.54884147644043,\n",
       "  ' So': -10.880770683288574,\n",
       "  ' Cal': -13.622539520263672,\n",
       "  '.,': -13.340982437133789,\n",
       "  ' buy': -11.23024845123291,\n",
       "  ' Ferrari': -6.957568168640137,\n",
       "  ' cash': -8.738183975219727,\n",
       "  ' This': -13.439337730407715,\n",
       "  ' flew': -12.378369331359863,\n",
       "  ' over': -9.169425964355469,\n",
       "  ' heads': -14.004488945007324,\n",
       "  ' showing': -9.129530906677246,\n",
       "  ' saw': -12.279572486877441,\n",
       "  ' damn': -6.896038055419922,\n",
       "  ' we': -8.838435173034668,\n",
       "  ' Reno': -7.050388336181641,\n",
       "  ' Nevada': -10.117409706115723,\n",
       "  ' where': -8.681666374206543,\n",
       "  ' made': -12.670378684997559,\n",
       "  ' pretty': -8.149246215820312,\n",
       "  ' news': -7.819888591766357,\n",
       "  ' But': -12.820321083068848,\n",
       "  ' laughing': -10.060791969299316,\n",
       "  ' having': -10.154861450195312,\n",
       "  ' good': -6.060617923736572,\n",
       "  ' ole': -9.000186920166016,\n",
       "  'out': -11.052534103393555,\n",
       "  ' Both': -14.763344764709473,\n",
       "  ' facts': -11.57295036315918,\n",
       "  ' lead': -11.250417709350586,\n",
       "  ' believe': -12.621133804321289,\n",
       "  ' lob': -18.583166122436523,\n",
       "  'ot': -14.579933166503906,\n",
       "  'om': -14.138825416564941,\n",
       "  'ized': -13.910001754760742,\n",
       "  ' It': -15.472039222717285,\n",
       "  ' amazing': -13.538990020751953,\n",
       "  ' many': -11.088774681091309,\n",
       "  ' tremendous': -11.525914192199707,\n",
       "  '-screen': -13.119396209716797,\n",
       "  ' chemistry': -12.563066482543945,\n",
       "  ' none': -14.195642471313477,\n",
       "  ' shows': -10.640629768371582,\n",
       "  ' here': -8.98040771484375,\n",
       "  ' nil': -11.396167755126953,\n",
       "  ' assign': -10.962350845336914,\n",
       "  ' number': -9.517755508422852,\n",
       "  '-': -14.909701347351074,\n",
       "  ' whichever': -12.74070930480957,\n",
       "  ' actor': -9.755049705505371,\n",
       "  ' epit': -14.641180992126465,\n",
       "  'izes': -18.417320251464844,\n",
       "  ' charisma': -10.049379348754883,\n",
       "  ' divide': -10.006348609924316,\n",
       "  ' That': -18.060611724853516,\n",
       "  ' should': -10.540133476257324,\n",
       "  ' give': -10.881989479064941,\n",
       "  ' idea': -13.274380683898926,\n",
       "  ' how': -8.90878677368164,\n",
       "  ' bland': -10.959211349487305,\n",
       "  ' acting': -10.394716262817383,\n",
       "  ' my': -10.918018341064453,\n",
       "  ' guess': -11.254537582397461,\n",
       "  ' incapable': -14.988863945007324,\n",
       "  ' long': -13.78004264831543,\n",
       "  ' division': -9.250381469726562,\n",
       "  ' complex': -9.422468185424805,\n",
       "  ' dividing': -6.761192798614502,\n",
       "  ' eleven': -13.2207612991333,\n",
       "  ' Make': -15.228885650634766,\n",
       "  ' your': -9.285466194152832,\n",
       "  ' appointment': -9.572858810424805,\n",
       "  ' brain': -10.849291801452637,\n",
       "  ' surgeon': -12.15705394744873,\n",
       "  'otomy': -14.510302543640137,\n",
       "  ' pronto': -12.50483512878418,\n",
       "  ' horrible': -9.835700988769531,\n",
       "  ' lame': -1.3772006034851074,\n",
       "  \"'ve\": -10.880744934082031,\n",
       "  ' never': -10.52119255065918,\n",
       "  ' seen': -12.060751914978027,\n",
       "  ' clich': -14.113431930541992,\n",
       "  'es': -13.928383827209473,\n",
       "  ' before': -7.61492919921875,\n",
       "  ' plain': -6.763014793395996,\n",
       "  ' dumb': -6.058465480804443,\n",
       "  ' since': -10.5309476852417,\n",
       "  ' rev': -8.208270072937012,\n",
       "  'ivial': -15.297420501708984,\n",
       "  ' compete': -14.346552848815918,\n",
       "  ' worst': -7.715625762939453,\n",
       "  ' them': -11.347110748291016,\n",
       "  ' found': -13.62734317779541,\n",
       "  ' Thin': -10.52991008758545,\n",
       "  ' Red': -18.922693252563477,\n",
       "  ' Line': -15.29858112335205,\n",
       "  ' POS': -10.571186065673828,\n",
       "  ' been': -9.856300354003906,\n",
       "  ' off': -6.15531063079834,\n",
       "  ' body': -8.893972396850586,\n",
       "  'guards': -14.817562103271484,\n",
       "  ' Nav': -15.347747802734375,\n",
       "  'ajo': -12.764993667602539,\n",
       "  ' themselves': -9.293806076049805,\n",
       "  ' strictly': -11.781805992126465,\n",
       "  ' must': -7.518303871154785,\n",
       "  ' miss': -12.25953483581543,\n",
       "  ' fare': -9.503056526184082}}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "018808df-a0f7-498d-b152-f01849ab4a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "395"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results['token_probabilities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "129cf9fd-0905-46d5-b6d7-b9f27863d18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "results_2 = get_conditional_probabilities(text, unknown_text, model=model, tokenizer=tokenizer,\n",
    "                                        include_conditional_probabilities=True,\n",
    "                                        include_token_probabilities=True,\n",
    "                                        include_full_distributions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "93fe74bf-d56a-4a48-924b-dd63a29b514a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_probabilities': {'That': -17.56633758544922,\n",
       "  \"'s\": -14.153806686401367,\n",
       "  ' the': -10.219949722290039,\n",
       "  ' story': -9.122652053833008,\n",
       "  ',': -14.240501403808594,\n",
       "  ' right': -7.857714653015137,\n",
       "  '?': -6.398604869842529,\n",
       "  ' Going': -14.081364631652832,\n",
       "  ' back': -11.48012924194336,\n",
       "  ' to': -9.663529396057129,\n",
       "  ' days': -12.426008224487305,\n",
       "  ' of': -8.246127128601074,\n",
       "  ' \"': -3.1023805141448975,\n",
       "  ' China': -5.821417808532715,\n",
       "  ' Town': -10.677091598510742,\n",
       "  ' with': -10.919380187988281,\n",
       "  ' Jack': -9.254035949707031,\n",
       "  ' Nicholson': -14.363350868225098,\n",
       "  ' chasing': -10.012381553649902,\n",
       "  ' lead': -9.91736125946045,\n",
       "  ' after': -8.573844909667969,\n",
       "  ' turning': -11.355340957641602,\n",
       "  ' corners': -11.955739974975586,\n",
       "  ' left': -5.499736785888672,\n",
       "  ' and': -9.112051010131836,\n",
       "  ' only': -8.981474876403809,\n",
       "  ' find': -11.782228469848633,\n",
       "  ' more': -9.090285301208496,\n",
       "  '.': -18.431865692138672,\n",
       "  ' Who': -12.350269317626953,\n",
       "  ' dup': -14.02192497253418,\n",
       "  'ing': -16.22037696838379,\n",
       "  ' who': -10.29234790802002,\n",
       "  ' We': -12.534172058105469,\n",
       "  ' don': -14.543317794799805,\n",
       "  \"'t\": -14.29920482635498,\n",
       "  ' know': -10.809048652648926,\n",
       "  ' until': -10.458922386169434,\n",
       "  ' very': -7.355847358703613,\n",
       "  ' end': -11.659868240356445,\n",
       "  ' in': -10.32282543182373,\n",
       "  ' this': -8.92773723602295,\n",
       "  ' fast': -10.150285720825195,\n",
       "  '-paced': -8.727466583251953,\n",
       "  ' hip': -4.322943687438965,\n",
       "  'ster': -10.246642112731934,\n",
       "  ' l': -8.186993598937988,\n",
       "  'ingo': -18.91886329650879,\n",
       "  ' d': -8.588260650634766,\n",
       "  'renched': -19.218353271484375,\n",
       "  ' wild': -4.541121959686279,\n",
       "  ' revival': -9.834126472473145,\n",
       "  ' classic': -9.298340797424316,\n",
       "  ' Black': -15.486292839050293,\n",
       "  ' White': -9.31469440460205,\n",
       "  ' Film': -9.217617988586426,\n",
       "  ' Noir': -6.906427383422852,\n",
       "  ' Joseph': -10.041786193847656,\n",
       "  ' Gordon': -18.897377014160156,\n",
       "  '-Le': -20.823345184326172,\n",
       "  'v': -17.43389892578125,\n",
       "  'itt': -17.168190002441406,\n",
       "  ' (': -13.613934516906738,\n",
       "  'yes': -11.540046691894531,\n",
       "  ' kid': -9.70569133758545,\n",
       "  ' from': -8.355712890625,\n",
       "  ' Third': -10.559553146362305,\n",
       "  ' Rock': -14.23066520690918,\n",
       "  ')': -19.397428512573242,\n",
       "  ' is': -9.069053649902344,\n",
       "  ' a': -10.74483871459961,\n",
       "  ' brilliant': -8.890071868896484,\n",
       "  ' hero': -7.461279392242432,\n",
       "  '/': -13.674816131591797,\n",
       "  ' foil': -7.292120933532715,\n",
       "  ' as': -9.235909461975098,\n",
       "  ' Brendan': -10.872939109802246,\n",
       "  ' bit': -10.687853813171387,\n",
       "  'ingly': -12.855131149291992,\n",
       "  ' dry': -7.692526340484619,\n",
       "  ' quick': -8.991965293884277,\n",
       "  '-w': -18.879281997680664,\n",
       "  'itted': -21.16269302368164,\n",
       "  ' scr': -18.932024002075195,\n",
       "  'appy': -14.240241050720215,\n",
       "  ' yet': -8.555296897888184,\n",
       "  ' reluctant': -7.530369281768799,\n",
       "  ' detective': -6.96449613571167,\n",
       "  ' trying': -12.05787181854248,\n",
       "  ' walk': -11.235721588134766,\n",
       "  ' his': -9.945497512817383,\n",
       "  ' way': -4.918291091918945,\n",
       "  ' through': -9.49560546875,\n",
       "  ' web': -8.519311904907227,\n",
       "  ' lies': -10.778287887573242,\n",
       "  ' murder': -8.149435043334961,\n",
       "  ' lots': -9.979317665100098,\n",
       "  ' missing': -7.930756092071533,\n",
       "  ' drugs': -9.14161491394043,\n",
       "  ' His': -16.763965606689453,\n",
       "  ' character': -6.418722629547119,\n",
       "  ' bright': -9.04440689086914,\n",
       "  ' he': -8.135961532592773,\n",
       "  ' can': -11.135370254516602,\n",
       "  ' read': -13.231200218200684,\n",
       "  ' situation': -5.801424980163574,\n",
       "  ' like': -8.980587005615234,\n",
       "  ' psychic': -8.640923500061035,\n",
       "  ' on': -9.82579231262207,\n",
       "  ' crack': -6.5552592277526855,\n",
       "  ' turn': -9.775652885437012,\n",
       "  ' things': -9.215331077575684,\n",
       "  ' favor': -12.135079383850098,\n",
       "  ' seconds': -12.092556953430176,\n",
       "  ' play': -9.589187622070312,\n",
       "  ' people': -10.886272430419922,\n",
       "  ' def': -12.36409854888916,\n",
       "  't': -20.415559768676758,\n",
       "  'ly': -14.275518417358398,\n",
       "  ' ultimately': -9.806050300598145,\n",
       "  ' played': -11.70669174194336,\n",
       "  ' himself': -7.008056640625,\n",
       "  '....': -8.14712142944336,\n",
       "  ' And': -11.571109771728516,\n",
       "  ' take': -9.064859390258789,\n",
       "  ' punch': -9.070812225341797,\n",
       "  ' The': -8.782047271728516,\n",
       "  ' plot': -9.669981002807617,\n",
       "  ' turns': -9.568351745605469,\n",
       "  ' then': -3.8853602409362793,\n",
       "  ' that': -8.740224838256836,\n",
       "  ' keeping': -10.583721160888672,\n",
       "  ' you': -11.436600685119629,\n",
       "  ' constantly': -8.813223838806152,\n",
       "  ' guessing': -12.09050464630127,\n",
       "  ' where': -10.953804016113281,\n",
       "  ' it': -10.799690246582031,\n",
       "  ' will': -9.453622817993164,\n",
       "  ' next': -8.979931831359863,\n",
       "  ' As': -11.102947235107422,\n",
       "  ' soon': -13.918011665344238,\n",
       "  ' think': -11.782136917114258,\n",
       "  ' what': -10.167160987854004,\n",
       "  ' going': -11.639481544494629,\n",
       "  ' Nora': -12.02407455444336,\n",
       "  ' Z': -12.871840476989746,\n",
       "  'eh': -12.112510681152344,\n",
       "  'et': -13.958478927612305,\n",
       "  'ner': -12.77092170715332,\n",
       "  ' beautiful': -6.341958999633789,\n",
       "  ' beg': -14.406100273132324,\n",
       "  'u': -20.410446166992188,\n",
       "  'iling': -20.7728271484375,\n",
       "  ' femme': -10.380270957946777,\n",
       "  ' f': -9.798542022705078,\n",
       "  'ata': -25.26265525817871,\n",
       "  'le': -18.228713989257812,\n",
       "  ' Brian': -6.672846794128418,\n",
       "  'Matt': -16.640579223632812,\n",
       "  ' O': -17.323217391967773,\n",
       "  \"'\": -11.79001522064209,\n",
       "  'Le': -17.66240882873535,\n",
       "  'ary': -16.911048889160156,\n",
       "  '),': -18.14133071899414,\n",
       "  ' feeding': -12.634241104125977,\n",
       "  ' facts': -11.330973625183105,\n",
       "  ' him': -13.465349197387695,\n",
       "  ' track': -12.266144752502441,\n",
       "  ' knows': -11.547569274902344,\n",
       "  ' stuff': -10.658044815063477,\n",
       "  ' but': -11.527576446533203,\n",
       "  ' never': -13.584104537963867,\n",
       "  ' let': -15.145174980163574,\n",
       "  ' how': -9.44404125213623,\n",
       "  ' R': -15.172070503234863,\n",
       "  'ian': -17.58817481994629,\n",
       "  ' Johnson': -12.817075729370117,\n",
       "  ' has': -10.470730781555176,\n",
       "  ' written': -11.145853042602539,\n",
       "  ' an': -6.430949687957764,\n",
       "  ' amazing': -11.030972480773926,\n",
       "  ' script': -10.380457878112793,\n",
       "  ' directed': -9.54163932800293,\n",
       "  ' into': -11.921191215515137,\n",
       "  ' whirl': -11.5031099319458,\n",
       "  'wind': -15.335891723632812,\n",
       "  ' experience': -7.346967697143555,\n",
       "  ' near': -5.32874059677124,\n",
       "  ' misses': -13.393054962158203,\n",
       "  ' painful': -8.674118995666504,\n",
       "  ' betrayal': -11.187779426574707,\n",
       "  ' love': -11.787576675415039,\n",
       "  ' lost': -11.185394287109375,\n",
       "  ' takes': -10.074451446533203,\n",
       "  ' second': -6.056153297424316,\n",
       "  ' catch': -10.669538497924805,\n",
       "  ' I': -8.6657075881958,\n",
       "  \"'m\": -12.731157302856445,\n",
       "  ' reminded': -12.899103164672852,\n",
       "  ' Sw': -14.349096298217773,\n",
       "  'ingers': -13.238201141357422,\n",
       "  ' had': -7.227935314178467,\n",
       "  ' been': -8.277671813964844,\n",
       "  ' thrilling': -12.977035522460938,\n",
       "  ' was': -9.316560745239258,\n",
       "  ' funny': -11.818746566772461,\n",
       "  ' words': -11.693100929260254,\n",
       "  ' fall': -10.201946258544922,\n",
       "  ' place': -10.705524444580078,\n",
       "  ' give': -9.703832626342773,\n",
       "  ' film': -13.073790550231934,\n",
       "  ' slick': -4.865921974182129,\n",
       "  ' delivery': -9.146810531616211,\n",
       "  ' best': -13.276883125305176,\n",
       "  ' exchanges': -11.02019214630127,\n",
       "  ' between': -9.44970989227295,\n",
       "  ' Bog': -12.240982055664062,\n",
       "  'art': -18.49547004699707,\n",
       "  ' Berg': -15.86065673828125,\n",
       "  'man': -11.833584785461426,\n",
       "  ' Alan': -6.085860729217529,\n",
       "  ' L': -13.311761856079102,\n",
       "  'add': -19.13986587524414,\n",
       "  ' Veronica': -16.22557830810547,\n",
       "  ' Lake': -12.784170150756836,\n",
       "  ' Take': -12.244574546813965,\n",
       "  ' all': -9.961078643798828,\n",
       "  ' drop': -11.731244087219238,\n",
       "  ' dark': -6.2591142654418945,\n",
       "  ' stark': -8.843735694885254,\n",
       "  ' brutal': -10.306659698486328,\n",
       "  ' modern': -7.872219562530518,\n",
       "  ' world': -9.623641967773438,\n",
       "  '...': -8.887435913085938,\n",
       "  ' In': -11.250977516174316,\n",
       "  ' high': -11.566047668457031,\n",
       "  ' school': -4.765942573547363,\n",
       "  ' places': -12.715710639953613,\n",
       "  ' There': -14.818592071533203,\n",
       "  ' even': -8.66946792602539,\n",
       "  ' some': -9.802631378173828,\n",
       "  ' quirky': -8.14365005493164,\n",
       "  ' humor': -10.21915054321289,\n",
       "  ' thrown': -11.749507904052734,\n",
       "  ' though': -11.589532852172852,\n",
       "  ' most': -9.562793731689453,\n",
       "  ' laughs': -15.282302856445312,\n",
       "  ' audience': -12.797930717468262,\n",
       "  ' were': -9.935136795043945,\n",
       "  ' really': -6.547985076904297,\n",
       "  ' nervous': -8.138657569885254,\n",
       "  ' release': -8.562424659729004,\n",
       "  ' tension': -10.345614433288574,\n",
       "  ' built': -12.915642738342285,\n",
       "  ' A': -9.096681594848633,\n",
       "  ' must': -6.672300338745117,\n",
       "  ' see': -11.172334671020508,\n",
       "  ' Sorry': -11.585844993591309,\n",
       "  ' folks': -9.851197242736816,\n",
       "  ' just': -9.132026672363281,\n",
       "  ' does': -11.152617454528809,\n",
       "  ' not': -10.539329528808594,\n",
       "  ' live': -12.43859577178955,\n",
       "  ' up': -8.166086196899414,\n",
       "  ' expectations': -9.4120512008667,\n",
       "  ' Perhaps': -13.880233764648438,\n",
       "  ' appropriate': -11.102109909057617,\n",
       "  ' title': -10.204407691955566,\n",
       "  ' would': -9.205028533935547,\n",
       "  ' have': -7.310333728790283,\n",
       "  ' Superman': -10.131193161010742,\n",
       "  ' Comes': -11.656310081481934,\n",
       "  ' Back': -9.918000221252441,\n",
       "  ' Kind': -14.471586227416992,\n",
       "  'a': -13.125297546386719,\n",
       "  ' While': -13.161272048950195,\n",
       "  ' Brandon': -10.76378059387207,\n",
       "  'outh': -18.326969146728516,\n",
       "  ' great': -7.7846808433532715,\n",
       "  ' new': -8.689044952392578,\n",
       "  'taking': -19.253978729248047,\n",
       "  ' than': -11.502301216125488,\n",
       "  ' few': -5.946506500244141,\n",
       "  ' queues': -12.343972206115723,\n",
       "  ' Christopher': -10.000250816345215,\n",
       "  ' Ree': -22.300891876220703,\n",
       "  've': -17.59186553955078,\n",
       "  ' Kate': -8.372467994689941,\n",
       "  ' Bos': -19.840686798095703,\n",
       "  'worth': -14.783793449401855,\n",
       "  ' awful': -12.556293487548828,\n",
       "  ' care': -16.59181022644043,\n",
       "  ' for': -12.098484992980957,\n",
       "  ' her': -11.860306739807129,\n",
       "  ' Lois': -9.746420860290527,\n",
       "  ' Lane': -12.531164169311523,\n",
       "  ' at': -8.174873352050781,\n",
       "  ' she': -9.208611488342285,\n",
       "  ' ed': -17.0941219329834,\n",
       "  'gy': -16.483034133911133,\n",
       "  ' strong': -9.275805473327637,\n",
       "  ' minded': -12.881856918334961,\n",
       "  'ness': -9.093582153320312,\n",
       "  ' Marg': -14.490470886230469,\n",
       "  'ot': -14.72478199005127,\n",
       "  ' Kid': -21.06939697265625,\n",
       "  'der': -16.78923225402832,\n",
       "  ' gave': -12.128704071044922,\n",
       "  ' nearly': -11.674580574035645,\n",
       "  ' ': -8.934383392333984,\n",
       "  '2': -5.541601181030273,\n",
       "  '0': -9.376508712768555,\n",
       "  ' yrs': -14.39980411529541,\n",
       "  ' ago': -13.973755836486816,\n",
       "  ' Some': -14.44189739227295,\n",
       "  ' due': -7.545462608337402,\n",
       "  ' bad': -10.042481422424316,\n",
       "  ' acting': -7.162323951721191,\n",
       "  ' be': -10.056646347045898,\n",
       "  ' blamed': -15.839364051818848,\n",
       "  ' lack': -12.32469367980957,\n",
       "  '-l': -11.66840648651123,\n",
       "  'uster': -18.21088981628418,\n",
       "  ' At': -13.450082778930664,\n",
       "  ' one': -8.1963529586792,\n",
       "  ' point': -9.888766288757324,\n",
       "  ' ask': -10.32239818572998,\n",
       "  ' husband': -13.406482696533203,\n",
       "  ' child': -10.667988777160645,\n",
       "  ' now': -6.659368515014648,\n",
       "  ' domestic': -9.028894424438477,\n",
       "  'ated': -14.466611862182617,\n",
       "  ' get': -12.036336898803711,\n",
       "  ' highly': -9.882387161254883,\n",
       "  ' secured': -9.988953590393066,\n",
       "  ' area': -9.022974014282227,\n",
       "  ' H': -8.237283706665039,\n",
       "  'U': -4.207658767700195,\n",
       "  'H': -6.651017189025879,\n",
       "  ' Why': -12.907658576965332,\n",
       "  ' anyone': -10.29312515258789,\n",
       "  ' She': -14.791375160217285,\n",
       "  ' do': -10.525227546691895,\n",
       "  '!': -9.092070579528809,\n",
       "  ' chemistry': -12.119135856628418,\n",
       "  ' wet': -4.5503435134887695,\n",
       "  ' sponge': -5.747898101806641,\n",
       "  ' sitting': -11.27053451538086,\n",
       "  ' half': -11.24422836303711,\n",
       "  '-filled': -13.284175872802734,\n",
       "  ' col': -16.096920013427734,\n",
       "  'ost': -14.278862953186035,\n",
       "  'omy': -15.295709609985352,\n",
       "  ' bag': -13.170793533325195,\n",
       "  ' sadly': -11.831449508666992,\n",
       "  ' although': -11.411397933959961,\n",
       "  ' apt': -10.979562759399414,\n",
       "  ' captured': -14.354206085205078,\n",
       "  ' both': -8.431879043579102,\n",
       "  ' ner': -15.967977523803711,\n",
       "  'dy': -16.329544067382812,\n",
       "  ' goof': -12.704841613769531,\n",
       "  ' Clark': -7.142799377441406,\n",
       "  ' Kent': -10.063692092895508,\n",
       "  ' Man': -6.27164363861084,\n",
       "  ' Steel': -10.416014671325684,\n",
       "  'est': -10.720683097839355,\n",
       "  ' lines': -14.789422988891602,\n",
       "  ' entire': -6.88868522644043,\n",
       "  ' Both': -14.946678161621094,\n",
       "  'un': -11.733142852783203,\n",
       "  'fortunately': -17.78826904296875,\n",
       "  ' Lex': -8.268691062927246,\n",
       "  ' Now': -8.2543363571167,\n",
       "  ' about': -10.740511894226074,\n",
       "  ' perhaps': -10.67033863067627,\n",
       "  ' should': -7.758083820343018,\n",
       "  ':': -15.680290222167969,\n",
       "  'ame': -10.943046569824219,\n",
       "  ' Luther': -11.240453720092773,\n",
       "  ' early': -11.913399696350098,\n",
       "  ' special': -10.73696231842041,\n",
       "  ' effects': -5.916098594665527,\n",
       "  ' are': -8.229852676391602,\n",
       "  ' rubber': -9.251204490661621,\n",
       "  'y': -9.744821548461914,\n",
       "  'think': -14.66826057434082,\n",
       "  ' first': -12.303096771240234,\n",
       "  ' Spider': -11.353479385375977,\n",
       "  ' movie': -9.17057991027832,\n",
       "  ' slows': -14.384912490844727,\n",
       "  ' stand': -18.498659133911133,\n",
       "  '-st': -17.894180297851562,\n",
       "  'ill': -21.057226181030273,\n",
       "  ' hour': -10.441521644592285,\n",
       "  '1': -2.7464816570281982,\n",
       "  '5': -9.210770606994629,\n",
       "  ' minutes': -11.811863899230957,\n",
       "  ' plain': -6.942934036254883,\n",
       "  ' lame': -5.07968807220459,\n",
       "  ' Kevin': -12.16741943359375,\n",
       "  ' Space': -23.503704071044922,\n",
       "  ' Parker': -9.27835464477539,\n",
       "  ' Pose': -23.345962524414062,\n",
       "  ' good': -10.074800491333008,\n",
       "  ' seeing': -9.939804077148438,\n",
       "  ' James': -9.124380111694336,\n",
       "  ' Mars': -18.685020446777344,\n",
       "  'den': -17.958328247070312,\n",
       "  'C': -15.959844589233398,\n",
       "  'yc': -11.674373626708984,\n",
       "  'lops': -20.45328140258789,\n",
       "  ' X': -11.504548072814941,\n",
       "  '-Men': -13.359881401062012,\n",
       "  ' playing': -11.868391990661621,\n",
       "  ' too': -8.910639762878418,\n",
       "  ' distracting': -11.194344520568848,\n",
       "  ' kept': -13.429588317871094,\n",
       "  ' thinking': -12.489809036254883,\n",
       "  ' when': -8.46757698059082,\n",
       "  ' Cyc': -15.75003719329834,\n",
       "  ' join': -12.89455795288086,\n",
       "  ' help': -7.355833053588867,\n",
       "  ' fight': -11.735213279724121,\n",
       "  ' evil': -8.427637100219727,\n",
       "  ' Two': -13.451925277709961,\n",
       "  ' hours': -11.77021598815918,\n",
       "  ' minute': -9.649358749389648,\n",
       "  ' pile': -9.789170265197754,\n",
       "  ' crap': -10.15623950958252,\n",
       "  ' claw': -13.286026000976562,\n",
       "  ' out': -14.782553672790527,\n",
       "  ' theater': -9.604004859924316,\n",
       "  ' tricks': -9.255728721618652,\n",
       "  ' silly': -7.531881809234619,\n",
       "  ' worst': -8.949868202209473,\n",
       "  ' part': -10.391883850097656,\n",
       "  ' being': -10.41006851196289,\n",
       "  ' somehow': -6.8626790046691895,\n",
       "  ' K': -16.326862335205078,\n",
       "  'rypton': -15.338663101196289,\n",
       "  'ite': -15.433935165405273,\n",
       "  ' doesn': -17.406204223632812,\n",
       "  ' seem': -12.426660537719727,\n",
       "  ' affect': -13.635445594787598,\n",
       "  ' anymore': -7.785525798797607,\n",
       "  ' Well': -11.87604808807373,\n",
       "  ' completely': -7.814082622528076,\n",
       "  ' randomly': -9.420744895935059,\n",
       "  ' One': -15.209928512573242,\n",
       "  ' devastated': -12.585027694702148,\n",
       "  ' by': -12.562456130981445,\n",
       "  ' saves': -14.793731689453125,\n",
       "  ' chunk': -9.32681655883789,\n",
       "  ' stuck': -7.178149223327637,\n",
       "  ' INS': -15.7795991897583,\n",
       "  'IDE': -17.781455993652344,\n",
       "  ' WTF': -9.147957801818848,\n",
       "  '?!': -1.7789926528930664,\n",
       "  ' Also': -15.420031547546387,\n",
       "  ' much': -10.434502601623535,\n",
       "  ' revolves': -12.413335800170898,\n",
       "  ' around': -7.651096820831299,\n",
       "  ' magic': -8.05595588684082,\n",
       "  ' crystals': -9.271411895751953,\n",
       "  ' traveled': -12.613910675048828,\n",
       "  ' home': -7.505890846252441,\n",
       "  ' planet': -7.823071002960205,\n",
       "  ' dialogue': -8.25184154510498,\n",
       "  ' surrounding': -14.456074714660645,\n",
       "  ' them': -13.275032043457031,\n",
       "  ' so': -6.861854553222656,\n",
       "  ' ho': -7.27512788772583,\n",
       "  'key': -16.774520874023438,\n",
       "  ' feel': -14.261951446533203,\n",
       "  ' any': -9.462102890014648,\n",
       "  ' moment': -10.72150993347168,\n",
       "  ' G': -12.661164283752441,\n",
       "  'ypsy': -10.741575241088867,\n",
       "  ' medium': -12.319490432739258,\n",
       "  ' pop': -11.616241455078125,\n",
       "  ' nowhere': -16.756376266479492,\n",
       "  ' start': -16.163026809692383,\n",
       "  ' reading': -10.4346923828125,\n",
       "  ' fortunes': -12.779022216796875,\n",
       "  ' It': -14.824067115783691,\n",
       "  ' Crystal': -8.028319358825684,\n",
       "  ' U': -14.932981491088867,\n",
       "  'gh': -6.2669148445129395,\n",
       "  ' Mim': -12.861976623535156,\n",
       "  'icking': -21.13529396057129,\n",
       "  ' problem': -9.862546920776367,\n",
       "  ' common': -10.257522583007812,\n",
       "  ' block': -13.235544204711914,\n",
       "  'busters': -15.865095138549805,\n",
       "  ' today': -8.868119239807129,\n",
       "  ' Returns': -8.364931106567383,\n",
       "  ' long': -9.801115036010742,\n",
       "  ' OK': -11.402841567993164,\n",
       "  ' starts': -14.235260963439941,\n",
       "  ' slow': -6.35410213470459,\n",
       "  ' gives': -11.458824157714844,\n",
       "  ' amount': -11.8628511428833,\n",
       "  ' action': -9.166091918945312,\n",
       "  ' last': -9.144487380981445,\n",
       "  ' could': -10.060873985290527,\n",
       "  ' condensed': -13.012441635131836,\n",
       "  '4': -4.967104434967041,\n",
       "  ' wouldn': -12.680216789245605,\n",
       "  ' quite': -7.067566394805908,\n",
       "  ' unbearable': -15.548699378967285,\n",
       "  ' Don': -12.677356719970703,\n",
       "  ' me': -12.628236770629883,\n",
       "  ' started': -14.979365348815918,\n",
       "  ' romantic': -8.270009994506836,\n",
       "  ' Can': -8.597784042358398,\n",
       "  ' my': -10.199542045593262,\n",
       "  ' mind': -11.561835289001465,\n",
       "  ' flight': -8.84933853149414,\n",
       "  ' Met': -16.92008399963379,\n",
       "  'ropolis': -10.720878601074219,\n",
       "  ' wanted': -13.497817993164062,\n",
       "  ' p': -11.598923683166504,\n",
       "  'uke': -18.492706298828125,\n",
       "  ' ten': -8.535327911376953,\n",
       "  ' they': -8.981912612915039,\n",
       "  ' screen': -12.025115013122559,\n",
       "  ' together': -6.140066146850586,\n",
       "  ' S': -8.606761932373047,\n",
       "  'PO': -13.90527629852295,\n",
       "  'ILER': -16.077917098999023,\n",
       "  ' WARNING': -6.045217037200928,\n",
       "  ' away': -9.85381031036377,\n",
       "  ' info': -11.141138076782227,\n",
       "  ' follow': -12.918882369995117,\n",
       "  ' Other': -13.784189224243164,\n",
       "  ' problems': -11.598499298095703,\n",
       "  ' Again': -16.05274772644043,\n",
       "  ' meteor': -10.408623695373535,\n",
       "  ' uses': -12.081575393676758,\n",
       "  ' extract': -15.058941841125488,\n",
       "  ' lands': -12.455648422241211,\n",
       "  ' Add': -13.671161651611328,\n",
       "  'is': -18.70161247253418,\n",
       "  ' Ab': -12.21346378326416,\n",
       "  'aba': -19.293407440185547,\n",
       "  ' did': -11.472528457641602,\n",
       "  '9': -2.423574686050415,\n",
       "  '7': -4.484610557556152,\n",
       "  '8': -13.652381896972656,\n",
       "  ' which': -12.068371772766113,\n",
       "  ' weird': -10.539252281188965,\n",
       "  ' stupid': -10.481904029846191,\n",
       "  ' five': -10.0657958984375,\n",
       "  ' years': -11.194311141967773,\n",
       "  'I': -14.301730155944824,\n",
       "  ' exactly': -8.008149147033691,\n",
       "  ' clear': -15.458439826965332,\n",
       "  ' opening': -10.564018249511719,\n",
       "  ' visit': -10.0701322555542,\n",
       "  ' ruins': -11.660470008850098,\n",
       "  ' we': -10.577420234680176,\n",
       "  ' hear': -11.877218246459961,\n",
       "  ' two': -11.457549095153809,\n",
       "  ' time': -13.171599388122559,\n",
       "  ' there': -9.4038724899292,\n",
       "  ' Plus': -12.294816017150879,\n",
       "  ' returns': -13.258859634399414,\n",
       "  ' Earth': -8.34891414642334,\n",
       "  ' another': -10.530339241027832,\n",
       "  ' star': -7.060057640075684,\n",
       "  '-pro': -17.69172477722168,\n",
       "  'be': -15.356181144714355,\n",
       "  ' same': -6.901224613189697,\n",
       "  ' field': -9.959702491760254,\n",
       "  ' originally': -10.066154479980469,\n",
       "  ' AND': -7.694338321685791,\n",
       "  ' found': -9.540692329406738,\n",
       "  ' mom': -11.4295654296875,\n",
       "  ' makes': -10.741256713867188,\n",
       "  ' no': -10.958664894104004,\n",
       "  ' sense': -11.439866065979004,\n",
       "  ' need': -10.81319808959961,\n",
       "  ' probe': -7.431390762329102,\n",
       "  ' How': -14.125624656677246,\n",
       "  ' reach': -12.361576080322266,\n",
       "  ' remains': -13.543910026550293,\n",
       "  ' deep': -8.40079116821289,\n",
       "  ' space': -11.01771354675293,\n",
       "  ' took': -14.843910217285156,\n",
       "  'doing': -18.225929260253906,\n",
       "  ' math': -9.808489799499512,\n",
       "  'and': -16.626375198364258,\n",
       "  ' fly': -10.856922149658203,\n",
       "  ' speed': -11.911109924316406,\n",
       "  ' light': -9.322656631469727,\n",
       "  ' according': -12.577112197875977,\n",
       "  '-': -8.217382431030273,\n",
       "  'ship': -14.661092758178711,\n",
       "  ' go': -8.433883666992188,\n",
       "  ' far': -7.440685749053955,\n",
       "  ' After': -13.99243450164795,\n",
       "  ' if': -9.134639739990234,\n",
       "  ' yellow': -10.14673137664795,\n",
       "  ' sun': -8.55152702331543,\n",
       "  ' lose': -10.941933631896973,\n",
       "  ' powers': -12.270068168640137,\n",
       "  ' die': -15.100377082824707,\n",
       "  ' Towards': -14.435909271240234,\n",
       "  ' put': -10.141559600830078,\n",
       "  ' coma': -13.116982460021973,\n",
       "  ' seems': -10.738704681396484,\n",
       "  ' wake': -12.751888275146484,\n",
       "  ' Neither': -15.713807106018066,\n",
       "  ' kiss': -6.462224960327148,\n",
       "  ' nor': -9.794625282287598,\n",
       "  ' their': -11.97485065460205,\n",
       "  ' son': -8.807174682617188,\n",
       "  ' semi': -10.373373985290527,\n",
       "  '-s': -14.140570640563965,\n",
       "  'uper': -14.6187162399292,\n",
       "  'son': -9.902931213378906,\n",
       "  ' wakes': -14.660269737243652,\n",
       "  ' obvious': -6.951755523681641,\n",
       "  ' cure': -9.53635025024414,\n",
       "  ' hit': -11.556672096252441,\n",
       "  ' skin': -11.205647468566895,\n",
       "  ' Earlier': -14.197059631347656,\n",
       "  ' made': -14.129158020019531,\n",
       "  ' showing': -10.260177612304688,\n",
       "  ' charging': -12.235711097717285,\n",
       "  ' sunlight': -10.732794761657715,\n",
       "  ' why': -8.67452621459961,\n",
       "  ' didn': -16.852340698242188,\n",
       "  ' use': -11.896305084228516,\n",
       "  ' device': -13.868827819824219,\n",
       "  ' course': -15.937882423400879,\n",
       "  'predict': -22.112754821777344,\n",
       "  'able': -13.516791343688965,\n",
       "  ' super': -12.7296724319458,\n",
       "  ' conceived': -11.235544204711914,\n",
       "  ' argued': -12.32735824584961,\n",
       "  ' many': -10.137829780578613,\n",
       "  ' nerd': -6.7959699630737305,\n",
       "  ' groups': -7.130619525909424,\n",
       "  ' pulp': -5.328767776489258,\n",
       "  ' comed': -18.693275451660156,\n",
       "  'ies': -15.905613899230957,\n",
       "  ' sperm': -7.163074016571045,\n",
       "  ' killed': -12.998676300048828,\n",
       "  ' while': -9.953853607177734,\n",
       "  ' mortal': -4.596801280975342,\n",
       "  ' man': -12.706914901733398,\n",
       "  'sup': -18.81326675415039,\n",
       "  'posing': -18.791370391845703,\n",
       "  ' crystal': -7.286692142486572,\n",
       "  ' chamber': -8.679037094116211,\n",
       "  ' II': -7.884905815124512,\n",
       "  ' removed': -13.511488914489746,\n",
       "  ' gone': -12.202559471130371,\n",
       "  ' somewhere': -7.78446626663208,\n",
       "  ' age': -9.111795425415039,\n",
       "  '6': -5.5564985275268555,\n",
       "  ' or': -9.72134780883789,\n",
       "  ' Nine': -12.074399948120117,\n",
       "  ' months': -10.138046264648438,\n",
       "  ' pregnancy': -10.770483016967773,\n",
       "  ' four': -10.286046981811523,\n",
       "  ' Finally': -17.39855194091797,\n",
       "  ' whole': -9.297892570495605,\n",
       "  ' bor': -25.365690231323242,\n",
       "  'rows': -18.6862735748291,\n",
       "  ' version': -10.699034690856934,\n",
       "  ' again': -8.007676124572754,\n",
       "  ' create': -12.386422157287598,\n",
       "  ' devastating': -10.462113380432129,\n",
       "  ' real': -7.661331653594971,\n",
       "  'estate': -14.863587379455566,\n",
       "  ' deal': -7.889764308929443,\n",
       "  ' kills': -14.074676513671875,\n",
       "  ' billions': -10.060028076171875,\n",
       "  ' Kitty': -7.149412631988525,\n",
       "  'P': -19.530460357666016,\n",
       "  'arker': -20.227527618408203,\n",
       "  ' finds': -11.606245994567871,\n",
       "  ' partially': -10.665287971496582,\n",
       "  ' fo': -16.081989288330078,\n",
       "  'ils': -23.215604782104492,\n",
       "  \"'ve\": -8.355610847473145,\n",
       "  ' got': -9.077868461608887,\n",
       "  ' wants': -13.628693580627441,\n",
       "  ' falls': -10.299712181091309,\n",
       "  ' wo': -17.047273635864258,\n",
       "  'efully': -19.171384811401367,\n",
       "  ' short': -8.831648826599121,\n",
       "  ' waste': -14.600383758544922,\n",
       "  ' your': -11.918573379516602,\n",
       "  ' Get': -13.059783935546875,\n",
       "  ' DVD': -8.513701438903809,\n",
       "  ' This': -13.620478630065918,\n",
       "  ' types': -13.377874374389648,\n",
       "  ' Hollywood': -6.081729412078857,\n",
       "  ' films': -10.929283142089844,\n",
       "  ' historical': -8.3510160446167,\n",
       "  ' enact': -17.398059844970703,\n",
       "  'ments': -15.490795135498047,\n",
       "  ' trivial': -15.845833778381348,\n",
       "  'ize': -14.790270805358887,\n",
       "  ' tragic': -5.707185745239258,\n",
       "  ' events': -12.024618148803711,\n",
       "  ' gloss': -16.778059005737305,\n",
       "  ' over': -12.769259452819824,\n",
       "  ' human': -7.4748616218566895,\n",
       "  ' element': -13.310054779052734,\n",
       "  ' barely': -8.812931060791016,\n",
       "  ' paying': -10.348074913024902,\n",
       "  ' lip': -12.856647491455078,\n",
       "  '-service': -18.678184509277344,\n",
       "  ' dead': -7.691408157348633,\n",
       "  ' loosely': -6.769675254821777,\n",
       "  ' tying': -12.10236930847168,\n",
       "  ' history': -11.349282264709473,\n",
       "  ' hears': -18.593996047973633,\n",
       "  'ay': -11.343100547790527,\n",
       "  ' clich': -12.803240776062012,\n",
       "  'Ã': -7.803011894226074,\n",
       "  '©': -15.206390380859375,\n",
       "  'd': -14.806435585021973,\n",
       "  ' dialog': -8.986372947692871,\n",
       "  ' worn': -9.768282890319824,\n",
       "  '-out': -11.086816787719727,\n",
       "  ' conventions': -12.104095458984375,\n",
       "  ' cheap': -6.9003801345825195,\n",
       "  '-th': -13.357515335083008,\n",
       "  'r': -22.783674240112305,\n",
       "  'ers': -17.584867477416992,\n",
       "  ' wonder': -12.4493408203125,\n",
       "  ' MGM': -9.274652481079102,\n",
       "  ' tried': -13.45022964477539,\n",
       "  ' burn': -13.5246000289917,\n",
       "  '-off': -10.015995025634766,\n",
       "  ' st': -15.08166217803955,\n",
       "  'inker': -15.751585960388184,\n",
       "  ' summer': -8.25200366973877,\n",
       "  ' season': -9.613975524902344,\n",
       "  ' before': -7.633328914642334,\n",
       "  ' vital': -13.250627517700195,\n",
       "  ' Holiday': -6.712028980255127,\n",
       "  ' box': -9.331180572509766,\n",
       "  ' office': -11.155430793762207,\n",
       "  ' saw': -13.046514511108398,\n",
       "  ' limited': -8.650609016418457,\n",
       "  ' LA': -10.63768196105957,\n",
       "  ' $': -8.214944839477539,\n",
       "  ' rip': -12.068050384521484,\n",
       "  ' Ter': -15.00466537475586,\n",
       "  'rence': -16.57532501220703,\n",
       "  ' Howard': -13.337457656860352,\n",
       "  ' mediocre': -9.652688980102539,\n",
       "  ' He': -15.8251314163208,\n",
       "  ' lacks': -15.033913612365723,\n",
       "  ' charisma': -11.129375457763672,\n",
       "  ' power': -14.464741706848145,\n",
       "  ' carry': -14.280890464782715,\n",
       "  ' awkward': -9.214073181152344,\n",
       "  ' patched': -14.048094749450684,\n",
       "  ' clumsy': -7.645992279052734,\n",
       "  ' life': -12.392121315002441,\n",
       "  'less': -14.301277160644531,\n",
       "  ' narration': -9.232562065124512,\n",
       "  ' Jesse': -11.147035598754883,\n",
       "  ' Eisen': -19.954805374145508,\n",
       "  'berg': -15.007394790649414,\n",
       "  ' either': -4.407746315002441,\n",
       "  ' role': -9.68290901184082,\n",
       "  ' pulling': -9.102816581726074,\n",
       "  ' fortune': -15.550305366516113,\n",
       "  ' Cr': -10.776081085205078,\n",
       "  'acker': -15.498313903808594,\n",
       "  ' nephew': -9.916838645935059,\n",
       "  ' important': -8.765634536743164,\n",
       "  ' producer': -11.479432106018066,\n",
       "  ' possibility': -13.527994155883789,\n",
       "  ' pathetic': -6.810680389404297,\n",
       "  ' considering': -10.915552139282227,\n",
       "  ' green': -9.710254669189453,\n",
       "  'horn': -14.725062370300293,\n",
       "  ' thrust': -9.46400260925293,\n",
       "  'bearing': -14.614777565002441,\n",
       "  ' father': -8.371783256530762,\n",
       "  '-up': -12.580368041992188,\n",
       "  ' network': -8.672001838684082,\n",
       "  ' works': -15.840822219848633,\n",
       "  ' incess': -19.820369720458984,\n",
       "  'ant': -15.538622856140137,\n",
       "  ' blinking': -7.533148765563965,\n",
       "  ' eyes': -11.734099388122559,\n",
       "  ' pour': -9.446834564208984,\n",
       "  ' want': -12.438004493713379,\n",
       "  ' laugh': -9.969934463500977,\n",
       "  ' Richard': -9.310395240783691,\n",
       "  'ere': -19.452442169189453,\n",
       "  ' performance': -12.86230182647705,\n",
       "  ' uneven': -13.467289924621582,\n",
       "  ' appears': -16.23703384399414,\n",
       "  ' conflic': -26.445514678955078,\n",
       "  'ted': -16.97170066833496,\n",
       "  ' believe': -14.13897705078125,\n",
       "  ' Which': -15.918041229248047,\n",
       "  ' brings': -13.524349212646484,\n",
       "  ' us': -10.306195259094238,\n",
       "  ' heart': -13.441187858581543,\n",
       "  ' piece': -13.19279670715332,\n",
       "  ' clap': -10.167346954345703,\n",
       "  ' excuse': -10.354008674621582,\n",
       "  ' Shepard': -15.597756385803223,\n",
       "  ' whose': -13.728731155395508,\n",
       "  ' notable': -7.869592189788818,\n",
       "  ' work': -14.226174354553223,\n",
       "  ' directing': -10.996672630310059,\n",
       "  'gly': -12.087783813476562,\n",
       "  ' Betty': -15.171370506286621,\n",
       "  ' Criminal': -10.257463455200195,\n",
       "  ' Minds': -19.096513748168945,\n",
       "  ' pacing': -12.534419059753418,\n",
       "  ' truly': -8.340981483459473,\n",
       "  ' clim': -27.883819580078125,\n",
       "  'atic': -19.511598587036133,\n",
       "  ' scene': -8.384668350219727,\n",
       "  ' setup': -11.701709747314453,\n",
       "  ' No': -12.199058532714844,\n",
       "  ' build': -11.695796966552734,\n",
       "  ' Throughout': -14.618208885192871,\n",
       "  ' painfully': -8.038267135620117,\n",
       "  ' numerous': -8.15070629119873,\n",
       "  ' cl': -14.09139633178711,\n",
       "  'unky': -16.70476531982422,\n",
       "  ' scenes': -11.27440357208252,\n",
       "  ' ugly': -7.8573079109191895,\n",
       "  ' exposition': -9.987497329711914,\n",
       "  ' forced': -12.656351089477539,\n",
       "  ' down': -6.80747127532959,\n",
       "  ' viewer': -12.687166213989258,\n",
       "  ' throat': -11.931573867797852,\n",
       "  ' pieces': -10.111550331115723,\n",
       "  ' un': -17.342304229736328,\n",
       "  '-m': -14.087396621704102,\n",
       "  'astic': -15.355311393737793,\n",
       "  ' American': -5.866717338562012,\n",
       "  'ized': -10.83979606628418,\n",
       "  'cooked': -12.533748626708984,\n",
       "  ' sog': -15.260926246643066,\n",
       "  ' hot': -9.793920516967773,\n",
       "  ' dog': -9.350783348083496,\n",
       "  ' almost': -8.025880813598633,\n",
       "  ' sick': -11.869487762451172,\n",
       "  'ened': -15.284171104431152,\n",
       "  's': -15.898384094238281,\n",
       "  ' rolled': -11.931601524353027,\n",
       "  ' Bar': -11.542951583862305,\n",
       "  ' buddies': -11.330341339111328,\n",
       "  ' drinks': -10.069953918457031,\n",
       "  ' local': -8.675615310668945,\n",
       "  ' liquor': -11.422338485717773,\n",
       "  ' said': -13.797327041625977,\n",
       "  'more': -14.794270515441895,\n",
       "  ' once': -10.225323677062988,\n",
       "  ' SAME': -8.080047607421875,\n",
       "  ' bring': -11.557909965515137,\n",
       "  ' Devil': -9.073098182678223,\n",
       "  ' table': -12.630627632141113,\n",
       "  ' Dark': -11.63406753540039,\n",
       "  ' characters': -10.289924621582031,\n",
       "  ' clandest': -22.379825592041016,\n",
       "  'ine': -16.938064575195312,\n",
       "  ' meetings': -9.849583625793457,\n",
       "  ' striking': -7.5679802894592285,\n",
       "  ' match': -8.875782012939453,\n",
       "  ' cigarette': -7.829693794250488,\n",
       "  ' illuminate': -12.508190155029297,\n",
       "  ' distrust': -13.617818832397461,\n",
       "  'ful': -14.671809196472168,\n",
       "  ' vis': -13.689560890197754,\n",
       "  'age': -16.948200225830078,\n",
       "  ' Evil': -9.841437339782715,\n",
       "  ' faces': -9.189743041992188,\n",
       "  ' emerging': -12.207106590270996,\n",
       "  ' behind': -7.621768474578857,\n",
       "  ' dirty': -7.272141933441162,\n",
       "  ' plastic': -5.836564540863037,\n",
       "  ' sheets': -11.033488273620605,\n",
       "  ' hanging': -8.734758377075195,\n",
       "  ' dank': -5.055189609527588,\n",
       "  ' bas': -23.508577346801758,\n",
       "  'ements': -19.828937530517578,\n",
       "  ' Tri': -12.875470161437988,\n",
       "  'um': -18.292804718017578,\n",
       "  'phant': -15.343506813049316,\n",
       "  ' telling': -10.817533493041992,\n",
       "  ' guys': -10.723834991455078,\n",
       "  ' You': -13.329490661621094,\n",
       "  \"'re\": -12.844244003295898,\n",
       "  ' mother': -10.221858024597168,\n",
       "  'fer': -11.936375617980957,\n",
       "  ' \"...': -8.036208152770996,\n",
       "  ' CIA': -7.939265251159668,\n",
       "  ' happy': -13.13183879852295,\n",
       "  ' offer': -11.031909942626953,\n",
       "  ' lectures': -10.864514350891113,\n",
       "  ' gray': -8.74854850769043,\n",
       "  ' areas': -11.865434646606445,\n",
       "  ' organization': -16.133739471435547,\n",
       "  ' Car': -11.897811889648438,\n",
       "  ' ch': -18.869352340698242,\n",
       "  'ases': -19.793352127075195,\n",
       "  ' rainy': -5.831566333770752,\n",
       "  ' nights': -12.071953773498535,\n",
       "  ' Long': -12.430234909057617,\n",
       "  ' shots': -12.084733963012695,\n",
       "  ' fore': -11.405014991760254,\n",
       "  'b': -18.93683433532715,\n",
       "  'oding': -18.274520874023438,\n",
       "  ' looks': -11.546586036682129,\n",
       "  ' villagers': -12.332120895385742,\n",
       "  ' Flash': -10.663249015808105,\n",
       "  'back': -14.535198211669922,\n",
       "  ' flashback': -7.524320125579834,\n",
       "  ' lust': -9.150060653686523,\n",
       "  ' lib': -12.47266960144043,\n",
       "  'ations': -15.84152603149414,\n",
       "  ' loves': -12.285512924194336,\n",
       "  ' Easily': -15.118767738342285,\n",
       "  ' these': -10.589174270629883,\n",
       "  ' unnecessary': -7.559628486633301,\n",
       "  ' flash': -12.434281349182129,\n",
       "  'backs': -18.1208553314209,\n",
       "  ' single': -7.610145092010498,\n",
       "  ' line': -12.128889083862305,\n",
       "  ' spoken': -11.638983726501465,\n",
       "  ' literally': -8.235824584960938,\n",
       "  ' asked': -10.546683311462402,\n",
       "  ' loud': -11.249212265014648,\n",
       "  ' Do': -12.962632179260254,\n",
       "  ' needed': -11.165692329406738,\n",
       "  ' sad': -11.090279579162598,\n",
       "  ' such': -8.023441314697266,\n",
       "  ' idea': -12.564377784729004,\n",
       "  ' compelling': -14.051628112792969,\n",
       "  ' destroyed': -13.575493812561035,\n",
       "  ' inexperienced': -7.183826446533203,\n",
       "  ' unt': -25.002965927124023,\n",
       "  'al': -14.537932395935059,\n",
       "  'ented': -22.029430389404297,\n",
       "  ' writer': -10.571602821350098,\n",
       "  ' director': -9.747711181640625,\n",
       "  ' Even': -14.08353042602539,\n",
       "  ' ignore': -14.350138664245605,\n",
       "  ' tactics': -11.2339506149292,\n",
       "  ' used': -9.601704597473145,\n",
       "  ' manufacture': -14.79069709777832,\n",
       "  ' conflict': -11.68327522277832,\n",
       "  ' r': -14.235464096069336,\n",
       "  'iddled': -20.665363311767578,\n",
       "  ' other': -6.57982063293457,\n",
       "  ' impossible': -12.983253479003906,\n",
       "  ' become': -10.208130836486816,\n",
       "  ' engaged': -11.438713073730469,\n",
       "  ' enough': -10.702485084533691,\n",
       "  ' enjoy': -14.669607162475586,\n",
       "  ' anything': -8.614725112915039,\n",
       "  ' summarized': -15.147058486938477,\n",
       "  ' Hor': -20.204965591430664,\n",
       "  'ribly': -17.076885223388672,\n",
       "  '-of': -8.162215232849121,\n",
       "  '-character': -10.126724243164062,\n",
       "  ' Completely': -18.33100128173828,\n",
       "  'fl': -24.37896156311035,\n",
       "  'uous': -17.292510986328125,\n",
       "  ' girlfriend': -10.023241996765137,\n",
       "  ' vacation': -9.908077239990234,\n",
       "  ' Greece': -14.717239379882812,\n",
       "  ' Manip': -16.958553314208984,\n",
       "  'ulative': -15.223390579223633,\n",
       "  ' convenient': -13.493049621582031,\n",
       "  ' placement': -11.279939651489258,\n",
       "  ' timing': -11.972834587097168,\n",
       "  ' unbelievable': -12.364447593688965,\n",
       "  ' musical': -8.445730209350586,\n",
       "  ' score': -8.586531639099121,\n",
       "  ' filled': -11.724797248840332,\n",
       "  ' s': -10.590466499328613,\n",
       "  'mp': -17.582216262817383,\n",
       "  'ath': -16.23986053466797,\n",
       "  'etic': -17.90618133544922,\n",
       "  ' violin': -6.4212822914123535,\n",
       "  ' melodies': -12.519661903381348,\n",
       "  ' destroy': -16.895145416259766,\n",
       "  ' every': -10.96335220336914,\n",
       "  ' mood': -8.233173370361328,\n",
       "  ' careful': -14.698991775512695,\n",
       "  ...}}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c8cae108-4e23-4183-8108-39f89bf9ba0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3086"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_2['conditional_probabilities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72cb2f3-925e-4ed0-b518-6b97a5affd05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
