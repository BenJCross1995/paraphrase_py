{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3135a43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/user/Documents/GitHub/paraphrase_py/code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/Documents/GitHub/Video-from-Script/youtube_env/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "# 1) Set the location\n",
    "%cd ../../code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ac5a9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) import the helpers\n",
    "# from open_source_paraphrase_df_postprocessing import process_records\n",
    "from postprocessing import process_records, print_summary\n",
    "from read_and_write_docs import read_jsonl, write_jsonl\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30dbf3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) set file paths\n",
    "input_dir  = \"/Volumes/BCross/temp_datasets/author_verification/training/Wiki/Qwen2.5_1.5B_Test_Generation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fba5fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_jsonl(dir_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads all .jsonl files in the given directory, uses read_jsonl() to turn each\n",
    "    into a DataFrame, and concatenates them into one DataFrame.\n",
    "    \"\"\"\n",
    "    base = Path(dir_path)\n",
    "    # find all files ending with .jsonl\n",
    "    jsonl_files = base.glob(\"*.jsonl\")\n",
    "\n",
    "    dfs = []\n",
    "    for file in jsonl_files:\n",
    "        try:\n",
    "            # your existing function\n",
    "            df = read_jsonl(str(file))\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: failed to read {file}: {e}\")\n",
    "\n",
    "    if dfs:\n",
    "        # concatenate all dataframes (ignore_index to re-index 0..N-1)\n",
    "        return pd.concat(dfs, ignore_index=True)\n",
    "    else:\n",
    "        # no files found or all failed\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84968012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) read, process, and write\n",
    "df = read_all_jsonl(input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baab82ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = process_records(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "378a98f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 1690 total rows, 1690 are cleaned (100.00%).\n",
      "\n",
      "Out of 1690 cleaned rows, clean_stage breakdown:\n",
      "  Stage fix_salvage_quotes: 782 rows (46.27%)\n",
      "  Stage original_ok: 366 rows (21.66%)\n",
      "  Stage wrap_plain_text: 217 rows (12.84%)\n",
      "  Stage fix_pythonic: 193 rows (11.42%)\n",
      "  Stage fix_markdown: 128 rows (7.57%)\n",
      "  Stage fix_outer_brace: 4 rows (0.24%)\n"
     ]
    }
   ],
   "source": [
    "total_rows = len(processed_df)\n",
    "pct_cleaned = processed_df['text_cleaned'].mean() * 100\n",
    "\n",
    "cleaned = processed_df[processed_df['text_cleaned'] == 1]\n",
    "total_cleaned = len(cleaned)\n",
    "\n",
    "print(f\"Out of {total_rows} total rows, {total_cleaned} are cleaned ({pct_cleaned:.2f}%).\")\n",
    "\n",
    "stage_counts = cleaned['clean_stage'].value_counts()\n",
    "\n",
    "print(f\"\\nOut of {total_cleaned} cleaned rows, clean_stage breakdown:\")\n",
    "for stage, count in stage_counts.items():\n",
    "    pct_of_cleaned = (count / total_cleaned) * 100\n",
    "    print(f\"  Stage {stage}: {count} rows ({pct_of_cleaned:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a9f733b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Out of 1,690 total rows, 1,690 are cleaned (100.00%).\n",
      "\n",
      "Out of 1,690 cleaned rows, clean_stage breakdown:\n",
      "  Stage original_ok: 366 rows (21.66%)\n",
      "  Stage fix_markdown: 128 rows (7.57%)\n",
      "  Stage fix_outer_brace: 4 rows (0.24%)\n",
      "  Stage fix_pythonic: 193 rows (11.42%)\n",
      "  Stage wrap_plain_text: 217 rows (12.84%)\n",
      "  Stage fix_salvage_quotes: 782 rows (46.27%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_summary(processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f154f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>orig_doc_id</th>\n",
       "      <th>corpus</th>\n",
       "      <th>author</th>\n",
       "      <th>texttype</th>\n",
       "      <th>text</th>\n",
       "      <th>generated_text</th>\n",
       "      <th>time_sec</th>\n",
       "      <th>tokens_per_sec</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>clean_stage</th>\n",
       "      <th>parsing_errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142_196_88_228_text_1</td>\n",
       "      <td>known [142.196.88.228 - Text-1].txt</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>142.196.88.228</td>\n",
       "      <td>known</td>\n",
       "      <td>The article that is being referred to via the ...</td>\n",
       "      <td>{\"new_document\": \"A paper linked through the b...</td>\n",
       "      <td>24.778169</td>\n",
       "      <td>46.169674</td>\n",
       "      <td>A paper linked through the broken URL posits t...</td>\n",
       "      <td>1</td>\n",
       "      <td>original_ok</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142_196_88_228_text_1</td>\n",
       "      <td>known [142.196.88.228 - Text-1].txt</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>142.196.88.228</td>\n",
       "      <td>known</td>\n",
       "      <td>The article that is being referred to via the ...</td>\n",
       "      <td>```json\\n{\\n  \"new_document\": \"The article lin...</td>\n",
       "      <td>31.469207</td>\n",
       "      <td>39.276490</td>\n",
       "      <td>The article linked through this broken connect...</td>\n",
       "      <td>1</td>\n",
       "      <td>fix_salvage_quotes</td>\n",
       "      <td>[original: Expecting value: line 1 column 1 (c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  doc_id                          orig_doc_id corpus  \\\n",
       "0  142_196_88_228_text_1  known [142.196.88.228 - Text-1].txt   Wiki   \n",
       "1  142_196_88_228_text_1  known [142.196.88.228 - Text-1].txt   Wiki   \n",
       "\n",
       "           author texttype                                               text  \\\n",
       "0  142.196.88.228    known  The article that is being referred to via the ...   \n",
       "1  142.196.88.228    known  The article that is being referred to via the ...   \n",
       "\n",
       "                                      generated_text   time_sec  \\\n",
       "0  {\"new_document\": \"A paper linked through the b...  24.778169   \n",
       "1  ```json\\n{\\n  \"new_document\": \"The article lin...  31.469207   \n",
       "\n",
       "   tokens_per_sec                                         clean_text  \\\n",
       "0       46.169674  A paper linked through the broken URL posits t...   \n",
       "1       39.276490  The article linked through this broken connect...   \n",
       "\n",
       "   text_cleaned         clean_stage  \\\n",
       "0             1         original_ok   \n",
       "1             1  fix_salvage_quotes   \n",
       "\n",
       "                                      parsing_errors  \n",
       "0                                                 []  \n",
       "1  [original: Expecting value: line 1 column 1 (c...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa0d9479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>orig_doc_id</th>\n",
       "      <th>corpus</th>\n",
       "      <th>author</th>\n",
       "      <th>texttype</th>\n",
       "      <th>text</th>\n",
       "      <th>generated_text</th>\n",
       "      <th>time_sec</th>\n",
       "      <th>tokens_per_sec</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>clean_stage</th>\n",
       "      <th>parsing_errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142_196_88_228_text_1</td>\n",
       "      <td>known [142.196.88.228 - Text-1].txt</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>142.196.88.228</td>\n",
       "      <td>known</td>\n",
       "      <td>The article that is being referred to via the ...</td>\n",
       "      <td>{\"new_document\": \"A paper linked through the b...</td>\n",
       "      <td>24.778169</td>\n",
       "      <td>46.169674</td>\n",
       "      <td>A paper linked through the broken URL posits t...</td>\n",
       "      <td>1</td>\n",
       "      <td>original_ok</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142_196_88_228_text_1</td>\n",
       "      <td>known [142.196.88.228 - Text-1].txt</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>142.196.88.228</td>\n",
       "      <td>known</td>\n",
       "      <td>The article that is being referred to via the ...</td>\n",
       "      <td>```json\\n{\\n  \"new_document\": \"The article lin...</td>\n",
       "      <td>31.469207</td>\n",
       "      <td>39.276490</td>\n",
       "      <td>The article linked through this broken connect...</td>\n",
       "      <td>1</td>\n",
       "      <td>fix_salvage_quotes</td>\n",
       "      <td>[original: Expecting value: line 1 column 1 (c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>142_196_88_228_text_1</td>\n",
       "      <td>known [142.196.88.228 - Text-1].txt</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>142.196.88.228</td>\n",
       "      <td>known</td>\n",
       "      <td>The article that is being referred to via the ...</td>\n",
       "      <td>```json\\n{\\n  \"new_document\": \"The article men...</td>\n",
       "      <td>26.324054</td>\n",
       "      <td>44.522018</td>\n",
       "      <td>The article mentioned through the faulty link ...</td>\n",
       "      <td>1</td>\n",
       "      <td>fix_markdown</td>\n",
       "      <td>[original: Expecting value: line 1 column 1 (c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142_196_88_228_text_1</td>\n",
       "      <td>known [142.196.88.228 - Text-1].txt</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>142.196.88.228</td>\n",
       "      <td>known</td>\n",
       "      <td>The article that is being referred to via the ...</td>\n",
       "      <td>{\\n  \"new_document\": \"A paper linked through a...</td>\n",
       "      <td>35.171929</td>\n",
       "      <td>36.392658</td>\n",
       "      <td>A paper linked through a broken URL posits tha...</td>\n",
       "      <td>1</td>\n",
       "      <td>original_ok</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142_196_88_228_text_1</td>\n",
       "      <td>known [142.196.88.228 - Text-1].txt</td>\n",
       "      <td>Wiki</td>\n",
       "      <td>142.196.88.228</td>\n",
       "      <td>known</td>\n",
       "      <td>The article that is being referred to via the ...</td>\n",
       "      <td>```json\\n{\\n  \"new_document\": \"A report linked...</td>\n",
       "      <td>21.483025</td>\n",
       "      <td>51.342863</td>\n",
       "      <td>A report linked through a damaged URL suggests...</td>\n",
       "      <td>1</td>\n",
       "      <td>fix_markdown</td>\n",
       "      <td>[original: Expecting value: line 1 column 1 (c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  doc_id                          orig_doc_id corpus  \\\n",
       "0  142_196_88_228_text_1  known [142.196.88.228 - Text-1].txt   Wiki   \n",
       "1  142_196_88_228_text_1  known [142.196.88.228 - Text-1].txt   Wiki   \n",
       "2  142_196_88_228_text_1  known [142.196.88.228 - Text-1].txt   Wiki   \n",
       "3  142_196_88_228_text_1  known [142.196.88.228 - Text-1].txt   Wiki   \n",
       "4  142_196_88_228_text_1  known [142.196.88.228 - Text-1].txt   Wiki   \n",
       "\n",
       "           author texttype                                               text  \\\n",
       "0  142.196.88.228    known  The article that is being referred to via the ...   \n",
       "1  142.196.88.228    known  The article that is being referred to via the ...   \n",
       "2  142.196.88.228    known  The article that is being referred to via the ...   \n",
       "3  142.196.88.228    known  The article that is being referred to via the ...   \n",
       "4  142.196.88.228    known  The article that is being referred to via the ...   \n",
       "\n",
       "                                      generated_text   time_sec  \\\n",
       "0  {\"new_document\": \"A paper linked through the b...  24.778169   \n",
       "1  ```json\\n{\\n  \"new_document\": \"The article lin...  31.469207   \n",
       "2  ```json\\n{\\n  \"new_document\": \"The article men...  26.324054   \n",
       "3  {\\n  \"new_document\": \"A paper linked through a...  35.171929   \n",
       "4  ```json\\n{\\n  \"new_document\": \"A report linked...  21.483025   \n",
       "\n",
       "   tokens_per_sec                                         clean_text  \\\n",
       "0       46.169674  A paper linked through the broken URL posits t...   \n",
       "1       39.276490  The article linked through this broken connect...   \n",
       "2       44.522018  The article mentioned through the faulty link ...   \n",
       "3       36.392658  A paper linked through a broken URL posits tha...   \n",
       "4       51.342863  A report linked through a damaged URL suggests...   \n",
       "\n",
       "   text_cleaned         clean_stage  \\\n",
       "0             1         original_ok   \n",
       "1             1  fix_salvage_quotes   \n",
       "2             1        fix_markdown   \n",
       "3             1         original_ok   \n",
       "4             1        fix_markdown   \n",
       "\n",
       "                                      parsing_errors  \n",
       "0                                                 []  \n",
       "1  [original: Expecting value: line 1 column 1 (c...  \n",
       "2  [original: Expecting value: line 1 column 1 (c...  \n",
       "3                                                 []  \n",
       "4  [original: Expecting value: line 1 column 1 (c...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79f4ca2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>orig_doc_id</th>\n",
       "      <th>corpus</th>\n",
       "      <th>author</th>\n",
       "      <th>texttype</th>\n",
       "      <th>text</th>\n",
       "      <th>generated_text</th>\n",
       "      <th>time_sec</th>\n",
       "      <th>tokens_per_sec</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>clean_stage</th>\n",
       "      <th>parsing_errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [doc_id, orig_doc_id, corpus, author, texttype, text, generated_text, time_sec, tokens_per_sec, clean_text, text_cleaned, clean_stage, parsing_errors]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned[cleaned['clean_stage']=='check_no_json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82309804",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "52",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/GitHub/Video-from-Script/youtube_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 52",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcleaned\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcleaned\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclean_stage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcheck_no_json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m52\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/Video-from-Script/youtube_env/lib/python3.11/site-packages/pandas/core/indexing.py:1183\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1181\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(com\u001b[38;5;241m.\u001b[39mapply_if_callable(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m-> 1183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1186\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/Video-from-Script/youtube_env/lib/python3.11/site-packages/pandas/core/frame.py:4221\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   4215\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_engine\n\u001b[1;32m   4217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n\u001b[1;32m   4218\u001b[0m     \u001b[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[1;32m   4219\u001b[0m     \u001b[38;5;66;03m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[1;32m   4220\u001b[0m     \u001b[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n\u001b[0;32m-> 4221\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m series\u001b[38;5;241m.\u001b[39m_values[row]\n\u001b[1;32m   4224\u001b[0m \u001b[38;5;66;03m# For MultiIndex going through engine effectively restricts us to\u001b[39;00m\n\u001b[1;32m   4225\u001b[0m \u001b[38;5;66;03m#  same-length tuples; see test_get_set_value_no_partial_indexing\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/Video-from-Script/youtube_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 52"
     ]
    }
   ],
   "source": [
    "cleaned[cleaned['clean_stage']=='check_no_json'].loc[52,'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf108ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned[cleaned['clean_stage']=='check_no_json'].loc[52,'generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c901684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned.loc[30, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d62c040",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned.loc[30, 'generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98b99bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned.loc[30, 'clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b717c4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = processed_df[processed_df['text_cleaned'] == 0].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4002abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17125ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed.loc[0, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37631af",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed.loc[0, 'generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38672a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed.loc[0, 'clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d8a4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed.loc[0, 'parsing_errors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f7b1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“YouTube_Environment”",
   "language": "python",
   "name": "youtube_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
