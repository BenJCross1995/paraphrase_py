{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ade2e9e5-832e-4466-b531-367c888c98e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "35664dd6-0c26-4460-87ff-2cfca9f265d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../read_and_write_docs.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d00072ce-aa16-41cb-9e51-4abe4aa28f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_loc = \"../../../../datasets/PAN/PAN 21/\"\n",
    "known_preprocessed = f\"{base_loc}pan21-known-preprocessed.jsonl\"\n",
    "unknown_preprocessed = f\"{base_loc}pan21-unknown-preprocessed.jsonl\"\n",
    "reference_loc = f\"{base_loc}pan21-reference.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c260639a-78b1-47f4-af1c-42650565e902",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_df = read_jsonl_file(known_preprocessed)\n",
    "unknown_df = read_jsonl_file(unknown_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "db20d985-e90e-41c5-8091-0a33ace61b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_deduplicate_filter_and_sample(known_df, unknown_df, sample_size=3):\n",
    "    # Step 1: Check the number of rows before appending\n",
    "    print(\"Number of rows in known_df:\", known_df.shape[0])\n",
    "    print(\"Number of rows in unknown_df:\", unknown_df.shape[0])\n",
    "    \n",
    "    # Step 2: Append the datasets\n",
    "    combined_df = pd.concat([known_df, unknown_df], ignore_index=True)\n",
    "    \n",
    "    # Step 3: Check the number of rows before dropping duplicates\n",
    "    print(\"Number of rows after appending:\", combined_df.shape[0])\n",
    "    \n",
    "    # Step 4: Drop duplicates based on 'author', 'fandom', and 'text' columns\n",
    "    deduplicated_df = combined_df.drop_duplicates(subset=['author', 'fandom', 'text'])\n",
    "    \n",
    "    # Step 5: Check the number of rows after dropping duplicates\n",
    "    print(\"Number of rows after dropping duplicates:\", deduplicated_df.shape[0])\n",
    "    \n",
    "    # Step 6: Drop any documents for authors with fewer than 3 rows\n",
    "    authors_less_than_3 = deduplicated_df.groupby('author').filter(lambda x: len(x) < 3)\n",
    "    filtered_df = deduplicated_df.groupby('author').filter(lambda x: len(x) >= 3)\n",
    "    \n",
    "    # Step 7: Check the number of rows after filtering\n",
    "    print(\"Number of rows after filtering authors with less than 3 documents:\", filtered_df.shape[0])\n",
    "    \n",
    "    # Step 8: For each author, keep a random sample of 3 rows\n",
    "    sampled_df = filtered_df.groupby('author').apply(lambda x: x.sample(n=sample_size, random_state=1), include_groups=True)\n",
    "    \n",
    "    # Step 9: Reset index to avoid hierarchical indexing from groupby\n",
    "    sampled_df = sampled_df.reset_index(drop=True)\n",
    "    \n",
    "    # Step 10: Check the number of rows after sampling\n",
    "    print(\"Number of rows after sampling:\", sampled_df.shape[0])\n",
    "    \n",
    "    # Return the final DataFrame\n",
    "    return sampled_df, authors_less_than_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f6fc1348-ea77-470c-afe2-2e025db8f182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in known_df: 19999\n",
      "Number of rows in unknown_df: 19999\n",
      "Number of rows after appending: 39998\n",
      "Number of rows after dropping duplicates: 38949\n",
      "Number of rows after filtering authors with less than 3 documents: 5739\n",
      "Number of rows after sampling: 3027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/hy496x3x5sn4hy9gy1fk19lw0000gp/T/ipykernel_77612/1225025089.py:26: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = filtered_df.groupby('author').apply(lambda x: x.sample(n=sample_size, random_state=1), include_groups=True)\n"
     ]
    }
   ],
   "source": [
    "combined_df, potential_impostors = combine_deduplicate_filter_and_sample(known_df, unknown_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2f944cf6-4ba7-4f41-9200-e6bf6b7a3247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>fandom</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9ebf6a04-0207-58fd-b13f-0adaf8d71045</td>\n",
       "      <td>1000199</td>\n",
       "      <td>Soul Eater</td>\n",
       "      <td>Dampness permeated everything - her skin , her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bcf8cf45-ed0c-52b6-8044-81180b7c067f</td>\n",
       "      <td>1000199</td>\n",
       "      <td>Full Moon wo Sagashite</td>\n",
       "      <td>Thanks so much to everyone who's reviewed so f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31e114ab-ad16-5618-a2d2-77e341b1833f</td>\n",
       "      <td>1000199</td>\n",
       "      <td>Full Moon wo Sagashite</td>\n",
       "      <td>'She's doing well . If you're wondering . Your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>778ba107-2595-5245-8894-09fb9897ed48</td>\n",
       "      <td>1003238</td>\n",
       "      <td>Yu Yu Hakusho</td>\n",
       "      <td>'Don't you hello Koto me' She growled on the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>778ba107-2595-5245-8894-09fb9897ed48</td>\n",
       "      <td>1003238</td>\n",
       "      <td>Karin</td>\n",
       "      <td>'Ok . Tomorow are you going to help Oni - chan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3022</th>\n",
       "      <td>cb04d325-b5d5-5bb2-9f69-062213397e3e</td>\n",
       "      <td>997768</td>\n",
       "      <td>Saving Private Ryan</td>\n",
       "      <td>7 June 1944 Dear Bonnie , Hey there , little s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3023</th>\n",
       "      <td>cb04d325-b5d5-5bb2-9f69-062213397e3e</td>\n",
       "      <td>997768</td>\n",
       "      <td>Troy</td>\n",
       "      <td>me . Where are Hector and Andromache ? And Sca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3024</th>\n",
       "      <td>598d77fe-d337-505a-b969-8d1d27ac7934</td>\n",
       "      <td>9991</td>\n",
       "      <td>Spider-Man</td>\n",
       "      <td>'Oh , that's Mary - Jane .' 'Is she your girlf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3025</th>\n",
       "      <td>235a6dc1-f2d0-55ca-866a-2c1180066563</td>\n",
       "      <td>9991</td>\n",
       "      <td>Spider-Man</td>\n",
       "      <td>never wanted to see hurt . Peter Parker seemed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3026</th>\n",
       "      <td>235a6dc1-f2d0-55ca-866a-2c1180066563</td>\n",
       "      <td>9991</td>\n",
       "      <td>Gundam UC</td>\n",
       "      <td>Kiki grumbled a bit loudly driving her bike do...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3027 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        id   author                  fandom  \\\n",
       "0     9ebf6a04-0207-58fd-b13f-0adaf8d71045  1000199              Soul Eater   \n",
       "1     bcf8cf45-ed0c-52b6-8044-81180b7c067f  1000199  Full Moon wo Sagashite   \n",
       "2     31e114ab-ad16-5618-a2d2-77e341b1833f  1000199  Full Moon wo Sagashite   \n",
       "3     778ba107-2595-5245-8894-09fb9897ed48  1003238           Yu Yu Hakusho   \n",
       "4     778ba107-2595-5245-8894-09fb9897ed48  1003238                   Karin   \n",
       "...                                    ...      ...                     ...   \n",
       "3022  cb04d325-b5d5-5bb2-9f69-062213397e3e   997768     Saving Private Ryan   \n",
       "3023  cb04d325-b5d5-5bb2-9f69-062213397e3e   997768                    Troy   \n",
       "3024  598d77fe-d337-505a-b969-8d1d27ac7934     9991              Spider-Man   \n",
       "3025  235a6dc1-f2d0-55ca-866a-2c1180066563     9991              Spider-Man   \n",
       "3026  235a6dc1-f2d0-55ca-866a-2c1180066563     9991               Gundam UC   \n",
       "\n",
       "                                                   text  \n",
       "0     Dampness permeated everything - her skin , her...  \n",
       "1     Thanks so much to everyone who's reviewed so f...  \n",
       "2     'She's doing well . If you're wondering . Your...  \n",
       "3     'Don't you hello Koto me' She growled on the o...  \n",
       "4     'Ok . Tomorow are you going to help Oni - chan...  \n",
       "...                                                 ...  \n",
       "3022  7 June 1944 Dear Bonnie , Hey there , little s...  \n",
       "3023  me . Where are Hector and Andromache ? And Sca...  \n",
       "3024  'Oh , that's Mary - Jane .' 'Is she your girlf...  \n",
       "3025  never wanted to see hurt . Peter Parker seemed...  \n",
       "3026  Kiki grumbled a bit loudly driving her bike do...  \n",
       "\n",
       "[3027 rows x 4 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6d8ad243-ebd5-4d90-9fd1-a94e556b78b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_authors_evenly(combined_df, train_prop=0.6):\n",
    "    # Step 1: Get a unique list of authors\n",
    "    authors = combined_df['author'].unique()\n",
    "    \n",
    "    # Step 2: Calculate the number of authors for the training set\n",
    "    total_authors = len(authors)\n",
    "    train_size = total_authors * train_prop\n",
    "    test_size = total_authors - train_size\n",
    "    \n",
    "    # Step 3: Round the train_size\n",
    "    rounded_train_size = round(train_size)\n",
    "    rounded_test_size = round(test_size)\n",
    "\n",
    "    # Step 4: Adjust train_size to be even if necessary\n",
    "    if rounded_train_size < train_size and rounded_train_size % 2 != 0:\n",
    "        rounded_train_size -= 1\n",
    "    elif rounded_train_size > train_size and rounded_train_size % 2 != 0:\n",
    "        rounded_train_size += 1\n",
    "\n",
    "    if rounded_test_size < test_size and rounded_test_size % 2 != 0:\n",
    "        rounded_test_size -= 1\n",
    "    elif rounded_test_size > test_size and rounded_test_size % 2 != 0:\n",
    "        rounded_test_size += 1\n",
    "\n",
    "    if(rounded_train_size + rounded_test_size) > total_authors:\n",
    "        rounded_train_size -= 2\n",
    "        rounded_test_size -= 2\n",
    "\n",
    "    print(f\"\"\"Total Authors: {total_authors}\\nTrain Authors: {rounded_train_size}\\nTest Authors: {rounded_test_size}\\nTotal Sample: {rounded_train_size + rounded_test_size}\"\"\")\n",
    "\n",
    "    # Step 5: Shuffle the authors\n",
    "    np.random.seed(1)  # For reproducibility\n",
    "    np.random.shuffle(authors)\n",
    "    \n",
    "    # Step 6: Split the authors into training and testing sets\n",
    "    train_authors = authors[:rounded_train_size]\n",
    "    test_authors = authors[rounded_train_size:rounded_train_size + rounded_test_size]\n",
    "\n",
    "    # Step 7: Create two DataFrames based on the training and testing authors\n",
    "    train_df = combined_df[combined_df['author'].isin(train_authors)].reset_index(drop=True)\n",
    "    test_df = combined_df[combined_df['author'].isin(test_authors)].reset_index(drop=True)\n",
    "    \n",
    "    # Print the number of rows in each DataFrame\n",
    "    print(\"Number of rows in training DataFrame:\", train_df.shape[0])\n",
    "    print(\"Number of rows in testing DataFrame:\", test_df.shape[0])\n",
    "    \n",
    "    # Return the training and testing DataFrames\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "258b37e8-da26-41c1-b865-30e6e7665eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Authors: 1009\n",
      "Train Authors: 604\n",
      "Test Authors: 404\n",
      "Total Sample: 1008\n",
      "Number of rows in training DataFrame: 1812\n",
      "Number of rows in testing DataFrame: 1212\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = split_authors_evenly(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "dd429444-3fb4-4bbe-8dbf-b2b349f50a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>fandom</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9ebf6a04-0207-58fd-b13f-0adaf8d71045</td>\n",
       "      <td>1000199</td>\n",
       "      <td>Soul Eater</td>\n",
       "      <td>Dampness permeated everything - her skin , her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bcf8cf45-ed0c-52b6-8044-81180b7c067f</td>\n",
       "      <td>1000199</td>\n",
       "      <td>Full Moon wo Sagashite</td>\n",
       "      <td>Thanks so much to everyone who's reviewed so f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31e114ab-ad16-5618-a2d2-77e341b1833f</td>\n",
       "      <td>1000199</td>\n",
       "      <td>Full Moon wo Sagashite</td>\n",
       "      <td>'She's doing well . If you're wondering . Your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2db8a01a-0f42-5445-87b7-cf68bdb3b2b8</td>\n",
       "      <td>1003327</td>\n",
       "      <td>Nightwalker</td>\n",
       "      <td>Yayoi had hurriedly pushed them into a conceal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7980ca32-6762-5352-90f1-051bf7833fcb</td>\n",
       "      <td>1003327</td>\n",
       "      <td>Carpathian Series</td>\n",
       "      <td>His feral visitor gripped his empty glass tigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1807</th>\n",
       "      <td>41e1f416-4998-55d3-8b14-396fa1ec960a</td>\n",
       "      <td>995163</td>\n",
       "      <td>Zoey 101</td>\n",
       "      <td>and gave her a deep , passionate kiss . James ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>41e1f416-4998-55d3-8b14-396fa1ec960a</td>\n",
       "      <td>995163</td>\n",
       "      <td>Sonny with a Chance</td>\n",
       "      <td>3:18 a . m ., ' a doctor mumbled walking away ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>9d06d94f-1c69-54e6-bad0-aaac0ad126e4</td>\n",
       "      <td>996460</td>\n",
       "      <td>Sonny with a Chance</td>\n",
       "      <td>'mam .' As soon as Ms . Monroe's footsteps cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>7e87eeea-ed1f-58dd-b9b7-1a15db8e7f25</td>\n",
       "      <td>996460</td>\n",
       "      <td>High School Musical</td>\n",
       "      <td>happiness depended on it . First , let's back ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1811</th>\n",
       "      <td>6e8fabb3-db39-56b0-a1c7-6ee4e0554d12</td>\n",
       "      <td>996460</td>\n",
       "      <td>Big Time Rush</td>\n",
       "      <td>'A - A - A week ?' Logan's jaw dropped . 'Oh ,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1812 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        id   author                  fandom  \\\n",
       "0     9ebf6a04-0207-58fd-b13f-0adaf8d71045  1000199              Soul Eater   \n",
       "1     bcf8cf45-ed0c-52b6-8044-81180b7c067f  1000199  Full Moon wo Sagashite   \n",
       "2     31e114ab-ad16-5618-a2d2-77e341b1833f  1000199  Full Moon wo Sagashite   \n",
       "3     2db8a01a-0f42-5445-87b7-cf68bdb3b2b8  1003327             Nightwalker   \n",
       "4     7980ca32-6762-5352-90f1-051bf7833fcb  1003327       Carpathian Series   \n",
       "...                                    ...      ...                     ...   \n",
       "1807  41e1f416-4998-55d3-8b14-396fa1ec960a   995163                Zoey 101   \n",
       "1808  41e1f416-4998-55d3-8b14-396fa1ec960a   995163     Sonny with a Chance   \n",
       "1809  9d06d94f-1c69-54e6-bad0-aaac0ad126e4   996460     Sonny with a Chance   \n",
       "1810  7e87eeea-ed1f-58dd-b9b7-1a15db8e7f25   996460     High School Musical   \n",
       "1811  6e8fabb3-db39-56b0-a1c7-6ee4e0554d12   996460           Big Time Rush   \n",
       "\n",
       "                                                   text  \n",
       "0     Dampness permeated everything - her skin , her...  \n",
       "1     Thanks so much to everyone who's reviewed so f...  \n",
       "2     'She's doing well . If you're wondering . Your...  \n",
       "3     Yayoi had hurriedly pushed them into a conceal...  \n",
       "4     His feral visitor gripped his empty glass tigh...  \n",
       "...                                                 ...  \n",
       "1807  and gave her a deep , passionate kiss . James ...  \n",
       "1808  3:18 a . m ., ' a doctor mumbled walking away ...  \n",
       "1809  'mam .' As soon as Ms . Monroe's footsteps cou...  \n",
       "1810  happiness depended on it . First , let's back ...  \n",
       "1811  'A - A - A week ?' Logan's jaw dropped . 'Oh ,...  \n",
       "\n",
       "[1812 rows x 4 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "54504074-8ff7-4ad0-b665-1a8e3d763d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df_for_same_and_different_authors(df):\n",
    "    # Ensure reproducibility\n",
    "    np.random.seed(1)\n",
    "    \n",
    "    # Initialize DataFrames for the results\n",
    "    df_x = pd.DataFrame()\n",
    "    df_y = pd.DataFrame()\n",
    "    \n",
    "    # Track remaining rows\n",
    "    remaining_rows = []\n",
    "    \n",
    "    # Group by author and process each group\n",
    "    for author, group in df.groupby('author'):\n",
    "        if len(group) != 3:\n",
    "            raise ValueError(f\"Each author should have exactly 3 rows. Found {len(group)} rows for author {author}.\")\n",
    "        \n",
    "        # Select two rows with matching sample_id for df_x and df_y\n",
    "        matching_rows = group.sample(2)\n",
    "        remaining_row = group[~group.index.isin(matching_rows.index)]\n",
    "        \n",
    "        # Assign one row to df_x and one to df_y\n",
    "        df_x = pd.concat([df_x, matching_rows.iloc[0:1]])\n",
    "        df_y = pd.concat([df_y, matching_rows.iloc[1:2]])\n",
    "        \n",
    "        # Add the remaining row to the pool\n",
    "        remaining_rows.append(remaining_row.iloc[0])\n",
    "    \n",
    "    # Convert the pool of remaining rows to DataFrame\n",
    "    remaining_df = pd.DataFrame(remaining_rows)\n",
    "    \n",
    "    # Shuffle remaining rows and split evenly between df_x and df_y\n",
    "    remaining_df = remaining_df.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "    half_remaining = len(remaining_df) // 2\n",
    "    \n",
    "    # Split the remaining rows\n",
    "    x = pd.concat([df_x, remaining_df.iloc[:half_remaining]], ignore_index=True)\n",
    "    y = pd.concat([df_y, remaining_df.iloc[half_remaining:]], ignore_index=True)\n",
    "\n",
    "    # Add sample_id columns\n",
    "    x = x.reset_index(drop=True)\n",
    "    y = y.reset_index(drop=True)\n",
    "    \n",
    "    x.insert(0, 'sample_id', x.index + 1)\n",
    "    y.insert(0, 'sample_id', y.index + 1)\n",
    "    \n",
    "    # Print the number of rows in each resulting DataFrame\n",
    "    print(\"Number of rows in DataFrame X:\", x.shape[0])\n",
    "    print(\"Number of rows in DataFrame Y:\", y.shape[0])\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ca50a85e-8365-4687-ac13-dd541d85839b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in DataFrame X: 906\n",
      "Number of rows in DataFrame Y: 906\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = split_df_for_same_and_different_authors(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9a021ce0-ccc5-4cc0-83e2-87a29d8c7839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in DataFrame X: 606\n",
      "Number of rows in DataFrame Y: 606\n"
     ]
    }
   ],
   "source": [
    "test_x, test_y = split_df_for_same_and_different_authors(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f95426c0-c86d-456f-86ae-158101a52ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_as_jsonl(train_x, f\"{base_loc}pan21-train_x.jsonl\")\n",
    "save_as_jsonl(train_y, f\"{base_loc}pan21-train_y.jsonl\")\n",
    "save_as_jsonl(test_x, f\"{base_loc}pan21-test_x.jsonl\")\n",
    "save_as_jsonl(test_y, f\"{base_loc}pan21-test_y.jsonl\")\n",
    "save_as_jsonl(potential_impostors, f\"{base_loc}pan21-potential_impostors.jsonl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paraphrase_llm",
   "language": "python",
   "name": "paraphrase_llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
